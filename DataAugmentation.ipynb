{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.6.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.6/site-packages (from nltk) (2021.11.10)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import torch\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "\n",
    "# from transformers import AdamW\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "from nltk.corpus import wordnet\n",
    "import config\n",
    "# from transformers import XLMRobertaForTokenClassification, XLMRobertaConfig ,BertModel, XLMRobertaTokenizer, XLMRobertaModel, BertForTokenClassification\n",
    "from data_utils import loadDatafromFile,createTokenizedDf,CompDataset,createkfoldData,createDataloaders\n",
    "from seqeval.metrics import accuracy_score, classification_report\n",
    "import engine\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAugmentation:\n",
    "    def __init__(self):\n",
    "        self.stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', \n",
    "    'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "    'himself', 'she', 'her', 'hers', 'herself', \n",
    "    'it', 'its', 'itself', 'they', 'them', 'their', \n",
    "    'theirs', 'themselves', 'what', 'which', 'who', \n",
    "    'whom', 'this', 'that', 'these', 'those', 'am', \n",
    "    'is', 'are', 'was', 'were', 'be', 'been', 'being', \n",
    "    'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
    "    'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n",
    "    'because', 'as', 'until', 'while', 'of', 'at', \n",
    "    'by', 'for', 'with', 'about', 'against', 'between',\n",
    "    'into', 'through', 'during', 'before', 'after', \n",
    "    'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
    "    'out', 'on', 'off', 'over', 'under', 'again', \n",
    "    'further', 'then', 'once', 'here', 'there', 'when', \n",
    "    'where', 'why', 'how', 'all', 'any', 'both', 'each', \n",
    "    'few', 'more', 'most', 'other', 'some', 'such', 'no', \n",
    "    'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', \n",
    "    'very', 's', 't', 'can', 'will', 'just', 'don', \n",
    "    'should', 'now', '']\n",
    "    #DataAugmentation methods\n",
    "    \n",
    "    def swap_word(self,new_words,labels_src):\n",
    "        '''Helper function for random swap.''' \n",
    "\n",
    "        random_idx_1 = random.randint(0, len(new_words)-1)\n",
    "        random_idx_2 = random_idx_1\n",
    "        counter = 0\n",
    "        while random_idx_2 == random_idx_1:\n",
    "            random_idx_2 = random.randint(0, len(new_words)-1)\n",
    "            counter += 1\n",
    "            if counter > 3:\n",
    "                return (new_words,labels_src)\n",
    "        new_words[random_idx_1], new_words[random_idx_2] = new_words[random_idx_2], new_words[random_idx_1]\n",
    "        labels_src[random_idx_1], labels_src[random_idx_2] = labels_src[random_idx_2], labels_src[random_idx_1]\n",
    "        return (new_words, labels_src)\n",
    "\n",
    "    \n",
    "    def random_swap(self,dataframe,n): # n is number of times to swap randomly 2 words\n",
    "\n",
    "        '''Takes in input the initial dataframe read from the files and returns \n",
    "        modefied/increased dataframe with swapped word fro each source sentence and its corresponding token wise labels '''\n",
    "        \n",
    "        source_sentences  = list(dataframe.source)\n",
    "        target_sentences = list(dataframe.target)\n",
    "        labels_src = list(dataframe.src_tokens)\n",
    "        labels_tar = list(dataframe.tar_tokens)\n",
    "        source_sentences_temp =[]\n",
    "        labels_sec_temp=[]\n",
    "        i=0\n",
    "\n",
    "        for sentences, labels in zip(source_sentences,labels_src):\n",
    "\n",
    "            sentences = sentences.split()\n",
    "            labels = labels.split()\n",
    "            for _ in range(n):\n",
    "                sentences, labels = self.swap_word(sentences,labels)\n",
    "\n",
    "            sentences_str = ' '.join(sentences)\n",
    "            labels_str = ' '.join(labels)\n",
    "            target_sentences.append(target_sentences[i])\n",
    "            labels_tar.append(labels_tar[i])\n",
    "            source_sentences_temp.append(sentences_str)\n",
    "            labels_sec_temp.append(labels_str)\n",
    "    #         break\n",
    "            i+=1\n",
    "\n",
    "        source_sentences.extend(source_sentences_temp)\n",
    "        labels_src.extend(labels_sec_temp)\n",
    "\n",
    "        column_names = [\"source\",\"target\",\"src_tokens\",\"tar_tokens\"]\n",
    "        df = pd.DataFrame(columns=column_names,dtype=object)\n",
    "        df = df.assign(source=source_sentences)\n",
    "        df = df.assign(target = target_sentences)\n",
    "        df = df.assign(src_tokens = labels_src)\n",
    "        df = df.assign(tar_tokens = labels_tar)\n",
    "\n",
    "        return df\n",
    "\n",
    "\n",
    "    \n",
    "    def random_deletion(self,dataframe, p):\n",
    "        \n",
    "        '''Takes input dataframe created after reading data files and the probabaility for deletion of random tokens in the\n",
    "        source sentences and returns increased dataframe with combined orignal sentences and noisy sentences '''\n",
    "    \n",
    "        source_sentences  = list(dataframe.source)\n",
    "        target_sentences = list(dataframe.target)\n",
    "        labels_src = list(dataframe.src_tokens)\n",
    "        labels_tar = list(dataframe.tar_tokens)\n",
    "        senetences_temp=[]\n",
    "        labels_temp= []\n",
    "        #randomly delete words with probability p\n",
    "        i=0\n",
    "        for sentences, labels in zip(source_sentences,labels_src):\n",
    "            sentences = sentences.split()\n",
    "            labels = labels.split() \n",
    "            source_sentences_temp=[]\n",
    "            labels_sec_temp=[]\n",
    "            if len(sentences) == 1:\n",
    "                pass\n",
    "            for word,label in zip(sentences,labels):\n",
    "                r = random.uniform(0, 1)\n",
    "                if r > p:\n",
    "                    source_sentences_temp.append(word)\n",
    "                    labels_sec_temp.append(label)\n",
    "            if len(source_sentences_temp) == 0: #if you end up deleting all words, just return a random word\n",
    "                rand_int = random.randint(0, len(source_sentences_temp)-1)\n",
    "                source_sentences_temp.append(sentences[rand_int])\n",
    "                labels_sec_temp.append(labels[rand_int])\n",
    "\n",
    "            sentences_str = ' '.join(source_sentences_temp)\n",
    "            labels_str = ' '.join(labels_sec_temp)\n",
    "            senetences_temp.append(sentences_str)\n",
    "            labels_temp.append(labels_str)\n",
    "            target_sentences.append(target_sentences[i])\n",
    "            labels_tar.append(labels_tar[i])\n",
    "    #         break\n",
    "            i+=1\n",
    "        source_sentences.extend(senetences_temp)\n",
    "        labels_src.extend(labels_temp)    \n",
    "        column_names = [\"source\",\"target\",\"src_tokens\",\"tar_tokens\"]\n",
    "        df = pd.DataFrame(columns=column_names,dtype=object)\n",
    "        df = df.assign(source=source_sentences)\n",
    "        df = df.assign(target = target_sentences)\n",
    "        df = df.assign(src_tokens = labels_src)\n",
    "        df = df.assign(tar_tokens = labels_tar)  \n",
    "\n",
    "\n",
    "        return df\n",
    "    \n",
    "\n",
    "    def get_synonyms(self,word):\n",
    "        \n",
    "        '''Helper function for synonym replacement '''\n",
    "        \n",
    "        synonyms = set()\n",
    "        for syn in wordnet.synsets(word): \n",
    "            for l in syn.lemmas(): \n",
    "                synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "                synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "                synonyms.add(synonym) \n",
    "        if word in synonyms:\n",
    "            synonyms.remove(word)\n",
    "        return list(synonyms)\n",
    "    \n",
    "    \n",
    "    def synonym_replacement(self,dataframe, n):\n",
    "    #     new_words = words.copy()\n",
    "        source_sentences  = list(dataframe.source)\n",
    "        target_sentences = list(dataframe.target)\n",
    "        labels_src = list(dataframe.src_tokens)\n",
    "        labels_tar = list(dataframe.tar_tokens)\n",
    "        senetences_temp=[]\n",
    "        labels_temp= []\n",
    "        k=0\n",
    "        for sentences,labels in zip(source_sentences,labels_src):\n",
    "            dict={}\n",
    "            sentences = sentences.split() # ['tarun', 'are', 'bad', 'for','health']\n",
    "            labels = labels.split()#['OK','BAD','OK','OK','OK']\n",
    "            for i, words in enumerate(sentences) :\n",
    "                dict[words] = i                      # {tarun:0, is : 1 , bad: 3 , for : 4, health : 5}\n",
    "            random_word_list = list(set([word for word in sentences if word not in self.stop_words]))\n",
    "            random.shuffle(random_word_list) # ['bad', 'are'...]\n",
    "            num_replaced = 0\n",
    "            for random_word in random_word_list: # ['bad', 'are'...]\n",
    "                synonyms = get_synonyms(random_word)\n",
    "                if len(synonyms) >= 1:\n",
    "                    synonym = random.choice(list(synonyms)) # bad -- > not good\n",
    "                    sentences = [synonym if word == random_word else word for word in sentences] # ['tarun', 'are', 'not good', 'for','health']\n",
    "                    synonym_len = len(synonym.split()) # 2 \n",
    "                    index_random_word = dict[random_word] # 2\n",
    "                    flag=0\n",
    "                    for key,values in dict.items():\n",
    "                        if key == random_word: # {tarun:0, is : 1 , bad: 2 , for : 3, health : 4}\n",
    "                            flag+=1\n",
    "                        if flag ==1:\n",
    "                            dict[key] = values+synonym_len-1 # {tarun:0, is : 1 , bad: 3 , for : 4, health : 5}\n",
    "                    label_synonym = labels[index_random_word] # 2 --> OK\n",
    "                    labels_append_synonym = [label_synonym] * synonym_len # ['OK','OK']\n",
    "                    labels_1 = labels[:index_random_word] # ['OK','BAD']\n",
    "                    labels_2 = labels[index_random_word+1:]#['OK','OK']\n",
    "                    labels_1.extend(labels_append_synonym)# ['OK','BAD','OK','OK']\n",
    "                    labels_1.extend(labels_2)# ['OK','BAD','OK','OK','OK','OK']\n",
    "                    labels = labels_1\n",
    "                    num_replaced += 1\n",
    "\n",
    "                if num_replaced >= n: #only replace up to n words\n",
    "                    break\n",
    "            sentence = ' '.join(sentences)\n",
    "            labels_splt = ' '.join(labels)\n",
    "            senetences_temp.append(sentence)\n",
    "            labels_temp.append(labels_splt)\n",
    "            target_sentences.append(target_sentences[k])\n",
    "            labels_tar.append(labels_tar[k])\n",
    "    #         break\n",
    "            k+=1 \n",
    "\n",
    "        source_sentences.extend(senetences_temp)\n",
    "        labels_src.extend(labels_temp)\n",
    "        column_names = [\"source\",\"target\",\"src_tokens\",\"tar_tokens\"]\n",
    "        df = pd.DataFrame(columns=column_names,dtype=object)\n",
    "        df = df.assign(source=source_sentences)\n",
    "        df = df.assign(target = target_sentences)\n",
    "        df = df.assign(src_tokens = labels_src)\n",
    "        df = df.assign(tar_tokens = labels_tar)\n",
    "\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', \n",
    "    'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "    'himself', 'she', 'her', 'hers', 'herself', \n",
    "    'it', 'its', 'itself', 'they', 'them', 'their', \n",
    "    'theirs', 'themselves', 'what', 'which', 'who', \n",
    "    'whom', 'this', 'that', 'these', 'those', 'am', \n",
    "    'is', 'are', 'was', 'were', 'be', 'been', 'being', \n",
    "    'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
    "    'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n",
    "    'because', 'as', 'until', 'while', 'of', 'at', \n",
    "    'by', 'for', 'with', 'about', 'against', 'between',\n",
    "    'into', 'through', 'during', 'before', 'after', \n",
    "    'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
    "    'out', 'on', 'off', 'over', 'under', 'again', \n",
    "    'further', 'then', 'once', 'here', 'there', 'when', \n",
    "    'where', 'why', 'how', 'all', 'any', 'both', 'each', \n",
    "    'few', 'more', 'most', 'other', 'some', 'such', 'no', \n",
    "    'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', \n",
    "    'very', 's', 't', 'can', 'will', 'just', 'don', \n",
    "    'should', 'now', '']\n",
    "def synonym_replacement(dataframe, n):\n",
    "#     new_words = words.copy()\n",
    "    source_sentences  = list(dataframe.source)\n",
    "    target_sentences = list(dataframe.target)\n",
    "    labels_src = list(dataframe.src_tokens)\n",
    "    labels_tar = list(dataframe.tar_tokens)\n",
    "    senetences_temp=[]\n",
    "    labels_temp= []\n",
    "    k=0\n",
    "    for sentences,labels in zip(source_sentences,labels_src):\n",
    "        dict={}\n",
    "        sentences = sentences.split()\n",
    "        labels_src = labels.split()\n",
    "#         for i, words in enumerate(sentences) :\n",
    "#             dict[words] = i\n",
    "#         print(dict)\n",
    "        random_word_list = list(set([word for word in sentences if word not in stop_words]))\n",
    "        random.shuffle(random_word_list)\n",
    "        print(random_word_list)\n",
    "        num_replaced = 0\n",
    "        for random_word in random_word_list:\n",
    "#             print(random_word)\n",
    "            synonyms = get_synonyms(random_word)\n",
    "#             print(synonyms)\n",
    "            if len(synonyms) >= 1:\n",
    "                synonym = random.choice(list(synonyms))\n",
    "#                 print(synonym)\n",
    "                sentences = [synonym if word == random_word else word for word in sentences]\n",
    "                #print(\"replaced\", random_word, \"with\", synonym)\n",
    "#                 print(labels_src)\n",
    "                synonym_len = len(synonym.split())\n",
    "                \n",
    "                index_replaced_word = [i for i,item in enumerate(sentences)]\n",
    "                \n",
    "#                 index_random_word = dict[random_word]\n",
    "#                 print(index_random_word)\n",
    "                labels_replaced_word = [labes_src[i] for i in index_replaced_word]\n",
    "            \n",
    "                label_synonym = labels_src[index_random_word]\n",
    "#                 print(label_synonym)\n",
    "                labels_append_synonym = [label_synonym] * synonym_len\n",
    "#                 print(labels_append_synonym)\n",
    "                labels_1 = labels_src[:index_random_word]\n",
    "#                 print(labels_1)\n",
    "                labels_2 = labels_src[index_random_word+1:]\n",
    "#                 print(labels_2)\n",
    "                labels_1.extend(labels_append_synonym)\n",
    "#                 print(labels_1)\n",
    "                labels_1.extend(labels_2)\n",
    "#                 print(labels_1)\n",
    "                \n",
    "                num_replaced += 1\n",
    "  \n",
    "            if num_replaced >= n: #only replace up to n words\n",
    "                break\n",
    "        sentence = ' '.join(sentences)\n",
    "        labels_splt = ' '.join(labels_1)\n",
    "        senetences_temp.append(sentence)\n",
    "        labels_temp.append(labels_splt)\n",
    "        target_sentences.append(target_sentences[k])\n",
    "        labels_tar.append(labels_tar[k])\n",
    "        k+=1     \n",
    "#         sentence = ' '.join(sentences)\n",
    "#     print(sentence)\n",
    "#         new_words = sentence.split(' ')\n",
    "\n",
    "    return new_words\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "            synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "            synonyms.add(synonym) \n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    return list(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tar_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
       "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However , a disappointing ninth in China meant...</td>\n",
       "      <td>Eine enttäuschende Neunte in China bedeutete j...</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...</td>\n",
       "      <td>OK BAD OK BAD OK BAD OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his diary , Chase wrote that the release of...</td>\n",
       "      <td>In seinem Tagebuch , Chase schrieb , dass die ...</td>\n",
       "      <td>OK OK OK OK BAD BAD OK OK OK OK OK OK OK OK BA...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>OK BAD BAD OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK BAD BAD OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once North Pacific salmon die off after spawni...</td>\n",
       "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>OK OK OK OK BAD OK OK OK OK OK BAD OK BAD OK O...</td>\n",
       "      <td>OK OK OK BAD OK OK OK BAD OK OK OK OK OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>Some may also discourage or disallow unsanitar...</td>\n",
       "      <td>Einige können auch unhygienische Praktiken wie...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>In the late 1860s , the crinolines disappeared...</td>\n",
       "      <td>In den späten 1860er Jahren verschwanden die K...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK BAD BAD OK OK OK...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>Disco was criticized as mindless , consumerist...</td>\n",
       "      <td>Disco wurde als geistlos , konsumistisch , übe...</td>\n",
       "      <td>OK OK OK OK BAD OK BAD OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>Planters would then fill large hogsheads with ...</td>\n",
       "      <td>Die Pflanzer würden dann große Heuschrecken mi...</td>\n",
       "      <td>OK OK OK BAD OK BAD OK OK BAD BAD OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>He slew Krishna 's most dangerous enemy , Jara...</td>\n",
       "      <td>Er tötete Krishnas gefährlichsten Feind Jarasa...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK BAD OK OK ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "0     José Ortega y Gasset visited Husserl at Freibu...   \n",
       "1     However , a disappointing ninth in China meant...   \n",
       "2     In his diary , Chase wrote that the release of...   \n",
       "3     Heavy arquebuses mounted on wagons were called...   \n",
       "4     Once North Pacific salmon die off after spawni...   \n",
       "...                                                 ...   \n",
       "6995  Some may also discourage or disallow unsanitar...   \n",
       "6996  In the late 1860s , the crinolines disappeared...   \n",
       "6997  Disco was criticized as mindless , consumerist...   \n",
       "6998  Planters would then fill large hogsheads with ...   \n",
       "6999  He slew Krishna 's most dangerous enemy , Jara...   \n",
       "\n",
       "                                                 target  \\\n",
       "0     1934 besuchte José Ortega y Gasset Husserl in ...   \n",
       "1     Eine enttäuschende Neunte in China bedeutete j...   \n",
       "2     In seinem Tagebuch , Chase schrieb , dass die ...   \n",
       "3     Schwere Arquebuses auf Waggons montiert wurden...   \n",
       "4     Sobald der nordpazifische Lachs nach dem Laich...   \n",
       "...                                                 ...   \n",
       "6995  Einige können auch unhygienische Praktiken wie...   \n",
       "6996  In den späten 1860er Jahren verschwanden die K...   \n",
       "6997  Disco wurde als geistlos , konsumistisch , übe...   \n",
       "6998  Die Pflanzer würden dann große Heuschrecken mi...   \n",
       "6999  Er tötete Krishnas gefährlichsten Feind Jarasa...   \n",
       "\n",
       "                                             src_tokens  \\\n",
       "0                      OK OK OK OK OK OK OK OK OK OK OK   \n",
       "1     OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...   \n",
       "2     OK OK OK OK BAD BAD OK OK OK OK OK OK OK OK BA...   \n",
       "3                    OK BAD BAD OK OK OK OK OK OK OK OK   \n",
       "4     OK OK OK OK BAD OK OK OK OK OK BAD OK BAD OK O...   \n",
       "...                                                 ...   \n",
       "6995  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...   \n",
       "6996  OK OK OK OK OK OK OK OK OK OK BAD BAD OK OK OK...   \n",
       "6997              OK OK OK OK BAD OK BAD OK OK OK OK OK   \n",
       "6998   OK OK OK BAD OK BAD OK OK BAD BAD OK OK OK OK OK   \n",
       "6999  OK OK OK OK OK OK OK OK OK OK OK OK BAD OK OK ...   \n",
       "\n",
       "                                             tar_tokens  \n",
       "0     OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1     OK BAD OK BAD OK BAD OK OK OK OK OK OK OK OK O...  \n",
       "2     OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...  \n",
       "3     OK OK OK BAD OK OK OK OK BAD BAD OK OK OK OK O...  \n",
       "4     OK OK OK BAD OK OK OK BAD OK OK OK OK OK OK OK...  \n",
       "...                                                 ...  \n",
       "6995  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "6996  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "6997  OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...  \n",
       "6998  OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...  \n",
       "6999  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "\n",
       "[7000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataObj = loadDatafromFile(config.filePath_src,config.filePath_tar, config.filePath_srcTags,config.filePath_tarTags)\n",
    "df= dataObj.createDf() \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def synonym_replacement(dataframe, n):\n",
    "# #     new_words = words.copy()\n",
    "#     source_sentences  = list(dataframe.source)\n",
    "#     target_sentences = list(dataframe.target)\n",
    "#     labels_src = list(dataframe.src_tokens)\n",
    "#     labels_tar = list(dataframe.tar_tokens)\n",
    "#     senetences_temp=[]\n",
    "#     labels_temp= []\n",
    "#     k=0\n",
    "#     for sentences,labels in zip(source_sentences,labels_src):\n",
    "#         dict={}\n",
    "#         sentences = sentences.split() # ['tarun', 'are', 'bad', 'for','health']\n",
    "#         labels = labels.split()#['OK','BAD','OK','OK','OK']\n",
    "#         for i, words in enumerate(sentences) :\n",
    "#             dict[words] = i                      # {tarun:0, is : 1 , bad: 3 , for : 4, health : 5}\n",
    "#         random_word_list = list(set([word for word in sentences if word not in config.stop_words]))\n",
    "#         random.shuffle(random_word_list) # ['bad', 'are'...]\n",
    "#         num_replaced = 0\n",
    "#         for random_word in random_word_list: # ['bad', 'are'...]\n",
    "#             synonyms = get_synonyms(random_word)\n",
    "#             if len(synonyms) >= 1:\n",
    "#                 synonym = random.choice(list(synonyms)) # bad -- > not good\n",
    "#                 sentences = [synonym if word == random_word else word for word in sentences] # ['tarun', 'are', 'not good', 'for','health']\n",
    "#                 synonym_len = len(synonym.split()) # 2 \n",
    "#                 index_random_word = dict[random_word] # 2\n",
    "#                 flag=0\n",
    "#                 for key,values in dict.items():\n",
    "#                     if key == random_word: # {tarun:0, is : 1 , bad: 2 , for : 3, health : 4}\n",
    "#                         flag+=1\n",
    "#                     if flag ==1:\n",
    "#                         dict[key] = values+synonym_len-1 # {tarun:0, is : 1 , bad: 3 , for : 4, health : 5}\n",
    "#                 label_synonym = labels[index_random_word] # 2 --> OK\n",
    "#                 labels_append_synonym = [label_synonym] * synonym_len # ['OK','OK']\n",
    "#                 labels_1 = labels[:index_random_word] # ['OK','BAD']\n",
    "#                 labels_2 = labels[index_random_word+1:]#['OK','OK']\n",
    "#                 labels_1.extend(labels_append_synonym)# ['OK','BAD','OK','OK']\n",
    "#                 labels_1.extend(labels_2)# ['OK','BAD','OK','OK','OK','OK']\n",
    "#                 labels = labels_1\n",
    "#                 num_replaced += 1\n",
    "  \n",
    "#             if num_replaced >= n: #only replace up to n words\n",
    "#                 break\n",
    "#         sentence = ' '.join(sentences)\n",
    "#         labels_splt = ' '.join(labels)\n",
    "#         senetences_temp.append(sentence)\n",
    "#         labels_temp.append(labels_splt)\n",
    "#         target_sentences.append(target_sentences[k])\n",
    "#         labels_tar.append(labels_tar[k])\n",
    "# #         break\n",
    "#         k+=1 \n",
    "         \n",
    "#     source_sentences.extend(senetences_temp)\n",
    "#     labels_src.extend(labels_temp)\n",
    "#     column_names = [\"source\",\"target\",\"src_tokens\",\"tar_tokens\"]\n",
    "#     df = pd.DataFrame(columns=column_names,dtype=object)\n",
    "#     df = df.assign(source=source_sentences)\n",
    "#     df = df.assign(target = target_sentences)\n",
    "#     df = df.assign(src_tokens = labels_src)\n",
    "#     df = df.assign(tar_tokens = labels_tar)\n",
    "\n",
    "#     return df\n",
    "\n",
    "\n",
    "# def get_synonyms(word):\n",
    "#     synonyms = set()\n",
    "#     for syn in wordnet.synsets(word): \n",
    "#         for l in syn.lemmas(): \n",
    "#             synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "#             synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "#             synonyms.add(synonym) \n",
    "#     if word in synonyms:\n",
    "#         synonyms.remove(word)\n",
    "#     return list(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tar_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
       "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
       "      <td>OK OK OK OK BAD OK OK OK BAD BAD OK</td>\n",
       "      <td>OK BAD OK BAD OK OK OK OK OK OK OK OK BAD OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>however , a disappointing ninth in China meant...</td>\n",
       "      <td>eine enttäuschende Neunte in China bedeutete j...</td>\n",
       "      <td>OK BAD BAD BAD BAD OK OK OK OK OK OK OK OK OK ...</td>\n",
       "      <td>BAD BAD OK BAD OK BAD OK OK OK OK OK OK OK OK ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in his diary , Chase wrote that the release of...</td>\n",
       "      <td>in seinem Tagebuch , Chase schrieb , dass die ...</td>\n",
       "      <td>OK OK OK OK OK BAD OK OK BAD OK OK BAD OK BAD ...</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>BAD BAD OK OK BAD BAD BAD OK OK OK OK</td>\n",
       "      <td>OK OK BAD BAD OK OK OK BAD OK OK BAD OK BAD OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>once North Pacific salmon die off after spawni...</td>\n",
       "      <td>sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK BAD BAD BAD BAD OK...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>some may too discourage or disallow insanitary...</td>\n",
       "      <td>einige können auch unhygienische Praktiken wie...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>in the late 1860s , the crinolines disappeared...</td>\n",
       "      <td>in den späten 1860er Jahren verschwanden die K...</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK BAD BAD BAD OK OK ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>disco was knock as mindless , consumerist , ov...</td>\n",
       "      <td>Disco wurde als geistlos , konsumistisch , übe...</td>\n",
       "      <td>OK OK OK OK BAD BAD OK OK OK BAD OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>planters would then satisfy large hogsheads wi...</td>\n",
       "      <td>die Pflanzer würden dann große Heuschrecken mi...</td>\n",
       "      <td>OK OK BAD OK OK BAD OK OK OK OK OK BAD BAD BAD...</td>\n",
       "      <td>OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>he trend krishna 's most dangerous enemy , Jar...</td>\n",
       "      <td>er tötete Krishnas gefährlichsten Feind Jarasa...</td>\n",
       "      <td>OK BAD OK OK OK OK OK OK OK OK OK BAD BAD OK O...</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  source  \\\n",
       "0      José Ortega y Gasset visited Husserl at Freibu...   \n",
       "1      however , a disappointing ninth in China meant...   \n",
       "2      in his diary , Chase wrote that the release of...   \n",
       "3      Heavy arquebuses mounted on wagons were called...   \n",
       "4      once North Pacific salmon die off after spawni...   \n",
       "...                                                  ...   \n",
       "13995  some may too discourage or disallow insanitary...   \n",
       "13996  in the late 1860s , the crinolines disappeared...   \n",
       "13997  disco was knock as mindless , consumerist , ov...   \n",
       "13998  planters would then satisfy large hogsheads wi...   \n",
       "13999  he trend krishna 's most dangerous enemy , Jar...   \n",
       "\n",
       "                                                  target  \\\n",
       "0      1934 besuchte José Ortega y Gasset Husserl in ...   \n",
       "1      eine enttäuschende Neunte in China bedeutete j...   \n",
       "2      in seinem Tagebuch , Chase schrieb , dass die ...   \n",
       "3      schwere Arquebuses auf Waggons montiert wurden...   \n",
       "4      sobald der nordpazifische Lachs nach dem Laich...   \n",
       "...                                                  ...   \n",
       "13995  einige können auch unhygienische Praktiken wie...   \n",
       "13996  in den späten 1860er Jahren verschwanden die K...   \n",
       "13997  Disco wurde als geistlos , konsumistisch , übe...   \n",
       "13998  die Pflanzer würden dann große Heuschrecken mi...   \n",
       "13999  er tötete Krishnas gefährlichsten Feind Jarasa...   \n",
       "\n",
       "                                              src_tokens  \\\n",
       "0                    OK OK OK OK BAD OK OK OK BAD BAD OK   \n",
       "1      OK BAD BAD BAD BAD OK OK OK OK OK OK OK OK OK ...   \n",
       "2      OK OK OK OK OK BAD OK OK BAD OK OK BAD OK BAD ...   \n",
       "3                  BAD BAD OK OK BAD BAD BAD OK OK OK OK   \n",
       "4      OK OK OK OK OK OK OK BAD OK BAD BAD BAD BAD OK...   \n",
       "...                                                  ...   \n",
       "13995  OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD ...   \n",
       "13996  OK OK OK OK OK OK OK BAD OK BAD BAD BAD OK OK ...   \n",
       "13997             OK OK OK OK BAD BAD OK OK OK BAD OK OK   \n",
       "13998  OK OK BAD OK OK BAD OK OK OK OK OK BAD BAD BAD...   \n",
       "13999  OK BAD OK OK OK OK OK OK OK OK OK BAD BAD OK O...   \n",
       "\n",
       "                                              tar_tokens  \n",
       "0      OK BAD OK BAD OK OK OK OK OK OK OK OK BAD OK O...  \n",
       "1      BAD BAD OK BAD OK BAD OK OK OK OK OK OK OK OK ...  \n",
       "2      OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...  \n",
       "3      OK OK BAD BAD OK OK OK BAD OK OK BAD OK BAD OK...  \n",
       "4      OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD ...  \n",
       "...                                                  ...  \n",
       "13995  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "13996  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...  \n",
       "13997  OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...  \n",
       "13998  OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...  \n",
       "13999  OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...  \n",
       "\n",
       "[14000 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataObj = loadDatafromFile(config.filePath_src,config.filePath_tar, config.filePath_srcTags,config.filePath_tarTags)\n",
    "df= dataObj.createDf() \n",
    "augObj = DataAugmentation()\n",
    "augObj.synonym_replacement(df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', \n",
    "    'ours', 'ourselves', 'you', 'your', 'yours', \n",
    "    'yourself', 'yourselves', 'he', 'him', 'his', \n",
    "    'himself', 'she', 'her', 'hers', 'herself', \n",
    "    'it', 'its', 'itself', 'they', 'them', 'their', \n",
    "    'theirs', 'themselves', 'what', 'which', 'who', \n",
    "    'whom', 'this', 'that', 'these', 'those', 'am', \n",
    "    'is', 'are', 'was', 'were', 'be', 'been', 'being', \n",
    "    'have', 'has', 'had', 'having', 'do', 'does', 'did',\n",
    "    'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n",
    "    'because', 'as', 'until', 'while', 'of', 'at', \n",
    "    'by', 'for', 'with', 'about', 'against', 'between',\n",
    "    'into', 'through', 'during', 'before', 'after', \n",
    "    'above', 'below', 'to', 'from', 'up', 'down', 'in',\n",
    "    'out', 'on', 'off', 'over', 'under', 'again', \n",
    "    'further', 'then', 'once', 'here', 'there', 'when', \n",
    "    'where', 'why', 'how', 'all', 'any', 'both', 'each', \n",
    "    'few', 'more', 'most', 'other', 'some', 'such', 'no', \n",
    "    'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', \n",
    "    'very', 's', 't', 'can', 'will', 'just', 'don', \n",
    "    'should', 'now', '']\n",
    "def synonym_replacement(words, n):\n",
    "    new_words = words.copy()\n",
    "    random_word_list = list(set([word for word in words if word not in stop_words]))\n",
    "    random.shuffle(random_word_list)\n",
    "    num_replaced = 0\n",
    "    for random_word in random_word_list:\n",
    "        synonyms = get_synonyms(random_word)\n",
    "        if len(synonyms) >= 1:\n",
    "            synonym = random.choice(list(synonyms))\n",
    "            new_words = [synonym if word == random_word else word for word in new_words]\n",
    "            print(new_words)\n",
    "            print(\"replaced\", random_word, \"with\", synonym)\n",
    "            num_replaced += 1\n",
    "        if num_replaced >= n: #only replace up to n words\n",
    "            break\n",
    "\n",
    "    #this is stupid but we need it, trust me\n",
    "    sentence = ' '.join(new_words)\n",
    "    new_words = sentence.split(' ')\n",
    "\n",
    "    return new_words\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas(): \n",
    "            synonym = l.name().replace(\"_\", \" \").replace(\"-\", \" \").lower()\n",
    "            synonym = \"\".join([char for char in synonym if char in ' qwertyuiopasdfghjklzxcvbnm'])\n",
    "            synonyms.add(synonym) \n",
    "    if word in synonyms:\n",
    "        synonyms.remove(word)\n",
    "    return list(synonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disco', 'was', 'criticise', 'as', 'mindless', ',', 'consumerist', ',', 'overproduced', 'and', 'escapist.']\n",
      "replaced criticized with criticise\n",
      "['discotheque', 'was', 'criticise', 'as', 'mindless', ',', 'consumerist', ',', 'overproduced', 'and', 'escapist.']\n",
      "replaced disco with discotheque\n",
      "['discotheque', 'was', 'criticise', 'as', 'mindless', ',', 'consumerist', ',', 'overproduce', 'and', 'escapist.']\n",
      "replaced overproduced with overproduce\n",
      "['discotheque', 'was', 'criticise', 'as', 'senseless', ',', 'consumerist', ',', 'overproduce', 'and', 'escapist.']\n",
      "replaced mindless with senseless\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'discotheque was criticise as senseless , consumerist , overproduce and escapist.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'disco was criticized as mindless , consumerist , overproduced and escapist. '\n",
    "tokens = 'OK BAD OK OK BAD OK BAD OK OK OK BAD BAD'\n",
    "text = text.split()\n",
    "' '.join(synonym_replacement(text,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brand': 'Ford', 'year': 1965, 'price': 4546}\n"
     ]
    }
   ],
   "source": [
    "# lk = 'OK'\n",
    "# lst = [lk] * 5\n",
    "# lst.split()\n",
    "thisdict = {\n",
    "  \"brand\": \"Ford\",\n",
    "  \"year\": 1964,\n",
    "   \"price\":4545 \n",
    "}\n",
    "flag=0\n",
    "for key, value in thisdict.items():\n",
    "    \n",
    "    if key=='year':\n",
    "        flag+=1\n",
    "    if flag ==1:\n",
    "        thisdict[key] = value + 1 \n",
    "print(thisdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "augObj = DataAugmentation()\n",
    "swapped_df = augObj.random_swap(df,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tar_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
       "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
       "      <td>OK OK OK OK BAD OK OK OK BAD BAD OK</td>\n",
       "      <td>OK BAD OK BAD OK OK OK OK OK OK OK OK BAD OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>however , a disappointing ninth in China meant...</td>\n",
       "      <td>eine enttäuschende Neunte in China bedeutete j...</td>\n",
       "      <td>OK BAD BAD BAD BAD OK OK OK OK OK OK OK OK OK ...</td>\n",
       "      <td>BAD BAD OK BAD OK BAD OK OK OK OK OK OK OK OK ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in his diary , Chase wrote that the release of...</td>\n",
       "      <td>in seinem Tagebuch , Chase schrieb , dass die ...</td>\n",
       "      <td>OK OK OK OK OK BAD OK OK BAD OK OK BAD OK BAD ...</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>BAD BAD OK OK BAD BAD BAD OK OK OK OK</td>\n",
       "      <td>OK OK BAD BAD OK OK OK BAD OK OK BAD OK BAD OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>once North Pacific salmon die off after spawni...</td>\n",
       "      <td>sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK BAD BAD BAD BAD OK...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>the may also on or disallow unsanitary practic...</td>\n",
       "      <td>einige können auch unhygienische Praktiken wie...</td>\n",
       "      <td>BAD OK OK OK OK OK OK OK OK OK OK OK OK OK OK ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>in 1870s late 1860s , the the disappeared and ...</td>\n",
       "      <td>in den späten 1860er Jahren verschwanden die K...</td>\n",
       "      <td>OK OK OK OK OK OK BAD BAD OK OK BAD BAD OK OK ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>criticized was disco as mindless , consumerist...</td>\n",
       "      <td>Disco wurde als geistlos , konsumistisch , übe...</td>\n",
       "      <td>OK OK OK OK BAD BAD OK OK OK BAD OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>planters would and fill large tobacco with hog...</td>\n",
       "      <td>die Pflanzer würden dann große Heuschrecken mi...</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD BAD OK BAD BAD BAD BA...</td>\n",
       "      <td>OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>he Kichaka Krishna 's most dangerous enemy , i...</td>\n",
       "      <td>er tötete Krishnas gefährlichsten Feind Jarasa...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK BAD BAD OK OK...</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  source  \\\n",
       "0      José Ortega y Gasset visited Husserl at Freibu...   \n",
       "1      however , a disappointing ninth in China meant...   \n",
       "2      in his diary , Chase wrote that the release of...   \n",
       "3      Heavy arquebuses mounted on wagons were called...   \n",
       "4      once North Pacific salmon die off after spawni...   \n",
       "...                                                  ...   \n",
       "13995  the may also on or disallow unsanitary practic...   \n",
       "13996  in 1870s late 1860s , the the disappeared and ...   \n",
       "13997  criticized was disco as mindless , consumerist...   \n",
       "13998  planters would and fill large tobacco with hog...   \n",
       "13999  he Kichaka Krishna 's most dangerous enemy , i...   \n",
       "\n",
       "                                                  target  \\\n",
       "0      1934 besuchte José Ortega y Gasset Husserl in ...   \n",
       "1      eine enttäuschende Neunte in China bedeutete j...   \n",
       "2      in seinem Tagebuch , Chase schrieb , dass die ...   \n",
       "3      schwere Arquebuses auf Waggons montiert wurden...   \n",
       "4      sobald der nordpazifische Lachs nach dem Laich...   \n",
       "...                                                  ...   \n",
       "13995  einige können auch unhygienische Praktiken wie...   \n",
       "13996  in den späten 1860er Jahren verschwanden die K...   \n",
       "13997  Disco wurde als geistlos , konsumistisch , übe...   \n",
       "13998  die Pflanzer würden dann große Heuschrecken mi...   \n",
       "13999  er tötete Krishnas gefährlichsten Feind Jarasa...   \n",
       "\n",
       "                                              src_tokens  \\\n",
       "0                    OK OK OK OK BAD OK OK OK BAD BAD OK   \n",
       "1      OK BAD BAD BAD BAD OK OK OK OK OK OK OK OK OK ...   \n",
       "2      OK OK OK OK OK BAD OK OK BAD OK OK BAD OK BAD ...   \n",
       "3                  BAD BAD OK OK BAD BAD BAD OK OK OK OK   \n",
       "4      OK OK OK OK OK OK OK BAD OK BAD BAD BAD BAD OK...   \n",
       "...                                                  ...   \n",
       "13995  BAD OK OK OK OK OK OK OK OK OK OK OK OK OK OK ...   \n",
       "13996  OK OK OK OK OK OK BAD BAD OK OK BAD BAD OK OK ...   \n",
       "13997             OK OK OK OK BAD BAD OK OK OK BAD OK OK   \n",
       "13998  OK OK OK OK OK OK OK BAD BAD OK BAD BAD BAD BA...   \n",
       "13999  OK OK OK OK OK OK OK OK OK OK OK BAD BAD OK OK...   \n",
       "\n",
       "                                              tar_tokens  \n",
       "0      OK BAD OK BAD OK OK OK OK OK OK OK OK BAD OK O...  \n",
       "1      BAD BAD OK BAD OK BAD OK OK OK OK OK OK OK OK ...  \n",
       "2      OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...  \n",
       "3      OK OK BAD BAD OK OK OK BAD OK OK BAD OK BAD OK...  \n",
       "4      OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD ...  \n",
       "...                                                  ...  \n",
       "13995  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "13996  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...  \n",
       "13997  OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...  \n",
       "13998  OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...  \n",
       "13999  OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...  \n",
       "\n",
       "[14000 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swapped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tar_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
       "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
       "      <td>OK OK OK OK BAD OK OK OK BAD BAD OK</td>\n",
       "      <td>OK BAD OK BAD OK OK OK OK OK OK OK OK BAD OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>however , a disappointing ninth in China meant...</td>\n",
       "      <td>eine enttäuschende Neunte in China bedeutete j...</td>\n",
       "      <td>OK BAD BAD BAD BAD OK OK OK OK OK OK OK OK OK ...</td>\n",
       "      <td>BAD BAD OK BAD OK BAD OK OK OK OK OK OK OK OK ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in his diary , Chase wrote that the release of...</td>\n",
       "      <td>in seinem Tagebuch , Chase schrieb , dass die ...</td>\n",
       "      <td>OK OK OK OK OK BAD OK OK BAD OK OK BAD OK BAD ...</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>BAD BAD OK OK BAD BAD BAD OK OK OK OK</td>\n",
       "      <td>OK OK BAD BAD OK OK OK BAD OK OK BAD OK BAD OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>once North Pacific salmon die off after spawni...</td>\n",
       "      <td>sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK BAD BAD BAD BAD OK...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>some may also or disallow unsanitary such as k...</td>\n",
       "      <td>einige können auch unhygienische Praktiken wie...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK BAD OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>the late , the crinolines disappeared and the ...</td>\n",
       "      <td>in den späten 1860er Jahren verschwanden die K...</td>\n",
       "      <td>OK OK OK OK OK BAD OK BAD BAD OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>disco criticized as , consumerist , and escapi...</td>\n",
       "      <td>Disco wurde als geistlos , konsumistisch , übe...</td>\n",
       "      <td>OK OK OK BAD OK OK BAD OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>planters would then hogsheads with tobacco con...</td>\n",
       "      <td>die Pflanzer würden dann große Heuschrecken mi...</td>\n",
       "      <td>OK OK BAD BAD OK OK OK BAD BAD BAD OK</td>\n",
       "      <td>OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13999</th>\n",
       "      <td>slew Krishna 's dangerous enemy , Jarasandha ,...</td>\n",
       "      <td>er tötete Krishnas gefährlichsten Feind Jarasa...</td>\n",
       "      <td>BAD OK OK OK OK OK OK OK OK BAD OK BAD OK OK O...</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  source  \\\n",
       "0      José Ortega y Gasset visited Husserl at Freibu...   \n",
       "1      however , a disappointing ninth in China meant...   \n",
       "2      in his diary , Chase wrote that the release of...   \n",
       "3      Heavy arquebuses mounted on wagons were called...   \n",
       "4      once North Pacific salmon die off after spawni...   \n",
       "...                                                  ...   \n",
       "13995  some may also or disallow unsanitary such as k...   \n",
       "13996  the late , the crinolines disappeared and the ...   \n",
       "13997  disco criticized as , consumerist , and escapi...   \n",
       "13998  planters would then hogsheads with tobacco con...   \n",
       "13999  slew Krishna 's dangerous enemy , Jarasandha ,...   \n",
       "\n",
       "                                                  target  \\\n",
       "0      1934 besuchte José Ortega y Gasset Husserl in ...   \n",
       "1      eine enttäuschende Neunte in China bedeutete j...   \n",
       "2      in seinem Tagebuch , Chase schrieb , dass die ...   \n",
       "3      schwere Arquebuses auf Waggons montiert wurden...   \n",
       "4      sobald der nordpazifische Lachs nach dem Laich...   \n",
       "...                                                  ...   \n",
       "13995  einige können auch unhygienische Praktiken wie...   \n",
       "13996  in den späten 1860er Jahren verschwanden die K...   \n",
       "13997  Disco wurde als geistlos , konsumistisch , übe...   \n",
       "13998  die Pflanzer würden dann große Heuschrecken mi...   \n",
       "13999  er tötete Krishnas gefährlichsten Feind Jarasa...   \n",
       "\n",
       "                                              src_tokens  \\\n",
       "0                    OK OK OK OK BAD OK OK OK BAD BAD OK   \n",
       "1      OK BAD BAD BAD BAD OK OK OK OK OK OK OK OK OK ...   \n",
       "2      OK OK OK OK OK BAD OK OK BAD OK OK BAD OK BAD ...   \n",
       "3                  BAD BAD OK OK BAD BAD BAD OK OK OK OK   \n",
       "4      OK OK OK OK OK OK OK BAD OK BAD BAD BAD BAD OK...   \n",
       "...                                                  ...   \n",
       "13995               OK OK OK OK OK OK OK OK OK OK BAD OK   \n",
       "13996          OK OK OK OK OK BAD OK BAD BAD OK OK OK OK   \n",
       "13997                       OK OK OK BAD OK OK BAD OK OK   \n",
       "13998              OK OK BAD BAD OK OK OK BAD BAD BAD OK   \n",
       "13999  BAD OK OK OK OK OK OK OK OK BAD OK BAD OK OK O...   \n",
       "\n",
       "                                              tar_tokens  \n",
       "0      OK BAD OK BAD OK OK OK OK OK OK OK OK BAD OK O...  \n",
       "1      BAD BAD OK BAD OK BAD OK OK OK OK OK OK OK OK ...  \n",
       "2      OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...  \n",
       "3      OK OK BAD BAD OK OK OK BAD OK OK BAD OK BAD OK...  \n",
       "4      OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD ...  \n",
       "...                                                  ...  \n",
       "13995  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "13996  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...  \n",
       "13997  OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...  \n",
       "13998  OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...  \n",
       "13999  OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...  \n",
       "\n",
       "[14000 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augObj.random_deletion(df,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
