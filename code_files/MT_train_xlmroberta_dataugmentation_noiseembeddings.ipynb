{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.17.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.47)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.3.2)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.6.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.6/site-packages (from nltk) (2022.3.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.6/site-packages (7.6.5)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (7.16.3)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (3.5.2)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (5.5.6)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (1.0.2)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.26)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi<=0.17.2,>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (59.3.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pexpect in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from jedi<=0.17.2,>=0.10->ipython>=4.0.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.6/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.4.8)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (22.1.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.6/site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.10.0.0)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.9)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.6/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.9)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install nltk\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval) (1.19.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.6/site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.4)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.17.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.17.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.6/site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval) (1.19.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.17.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.6.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.6/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import torch\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "# from DataAugmentation \n",
    "from data_utils import loadDatafromFile,createTokenizedDf,CompDataset,createkfoldData,createDataloaders\n",
    "from data_utils_unlabelled import loadUnlabelledDatafromFile,createTokenizedDfUnlabelled,CompDatasetUnlabelled\n",
    "from DataAugmentation import DataAugmentation\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from importlib import reload\n",
    "import config\n",
    "from transformers import XLMRobertaForTokenClassification, XLMRobertaConfig ,BertModel, XLMRobertaTokenizer, XLMRobertaModel, BertForTokenClassification\n",
    "from seqeval.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import matthews_corrcoef,classification_report,f1_score\n",
    "import engine\n",
    "# from model_new import EntityModel\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting seed\n",
    "torch.manual_seed(config.random_seed)\n",
    "np.random.seed(config.random_seed)\n",
    "random.seed(config.random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the labelled data\n",
    "def process_data_labelled(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags,\n",
    "                 filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval,\n",
    "                 model_type='xlm'):\n",
    "    \n",
    "    \n",
    "    dataObjTrain = loadDatafromFile(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags)\n",
    "    df_train= dataObjTrain.createDf() # get dataframe from files    \n",
    "    dataObjEval = loadDatafromFile(filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval)\n",
    "    df_eval = dataObjEval.createDf()\n",
    "    df_combined = df_train.append(df_eval, ignore_index=True)\n",
    "    df_combined.reset_index(drop=True)\n",
    "    split_ratio_len = int(len(df_combined) - config.test_split_ratio*len(df_combined))\n",
    "    df_train_splitted = df_combined.iloc[:split_ratio_len,:]\n",
    "    df_eval_splitted = df_combined.iloc[split_ratio_len:,:]\n",
    "    obj_tokenized_train = createTokenizedDf(df_train_splitted,model_type)\n",
    "    obj_tokenized_test = createTokenizedDf(df_eval_splitted,model_type)\n",
    "    df_new_train = obj_tokenized_train.convertDf()\n",
    "    df_new_eval = obj_tokenized_test.convertDf()\n",
    "    train_data = CompDataset(df_new_train,model_type)\n",
    "    test_data = CompDataset(df_new_eval,model_type)\n",
    "    return train_data,test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the labelled data\n",
    "# def process_data_labelled(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags,\n",
    "#                  filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval,\n",
    "#                  model_type='xlm'):\n",
    "    \n",
    "    \n",
    "#     dataObjTrain = loadDatafromFile(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags)\n",
    "#     df_train= dataObjTrain.createDf() # get dataframe from files    \n",
    "#     df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "#     df_train=df_train.iloc[:500,:]\n",
    "#     dataObjEval = loadDatafromFile(filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval)\n",
    "#     df_eval = dataObjEval.createDf()\n",
    "#     obj_tokenized_train = createTokenizedDf(df_train,model_type)\n",
    "#     obj_tokenized_test = createTokenizedDf(df_eval,model_type)\n",
    "#     df_new_train = obj_tokenized_train.convertDf()\n",
    "#     df_new_eval = obj_tokenized_test.convertDf()\n",
    "#     train_data = CompDataset(df_new_train,model_type)\n",
    "#     test_data = CompDataset(df_new_eval,model_type)\n",
    "#     return train_data,test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data , eval_data = process_data_labelled(config.filePath_src,config.filePath_tar, config.filePath_srcTags,config.filePath_tarTags,config.filePath_src_eval,config.filePath_tar_eval, config.filePath_srcTags_eval,config.filePath_tarTags_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800\n",
      "3200\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(eval_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_unlabelled(filePath_src,filePath_tar,model_type):\n",
    "    \n",
    "    dataObj = loadUnlabelledDatafromFile(filePath_src,filePath_tar)\n",
    "    df= dataObj.createDfUnlabelled() # get dataframe from files\n",
    "    df['len_src'] = df['source'].str.split().map(lambda x:len(x))\n",
    "    df['len_tar'] = df['target'].str.split().map(lambda x:len(x))\n",
    "    \n",
    "    df = df[df.len_tar != 36]\n",
    "    df = df[df.len_tar != 2]\n",
    "    df = df[df.len_src != 1]\n",
    "    \n",
    "    df=df.iloc[:,:-2]\n",
    "#     df=df.iloc[:1000,:]\n",
    "    obj_tokenized = createTokenizedDfUnlabelled(df,model_type)\n",
    "    df_new= obj_tokenized.convertDf()\n",
    "#     enc_label = preprocessing.LabelEncoder()\n",
    "#     df_new['labels']= enc_label.fit_transform(df_new['labels'])\n",
    "    train_data = CompDatasetUnlabelled(df_new,model_type)\n",
    "    return df,train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6997"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabelled_train, dataset_train_unlabelled = process_data_unlabelled(config.filePath_src_backtranslated,config.filePath_tar_backtranslated,model_type = 'xlm')\n",
    "len(dataset_train_unlabelled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11797"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining 2 tuples --> labelled and unlabelled data \n",
    "combined_Data = train_data + dataset_train_unlabelled\n",
    "len(combined_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([     0,    360,    903,      4,     70,  23552,      9,    112,    266,\n",
       "           2199,   1840,    344,   1577,    642,   4517,      7,      4,     44,\n",
       "          52231,     83,    442,    450,    756,     70,    552,   3334,      7,\n",
       "            621,  27095,   4017,   2852,     58,    450,    764,     83,   2160,\n",
       "            214,      5,      2,      2,    656,    360,    656,   8186,    656,\n",
       "          73351,    660,    656,    122,    656, 134942,  86828,    656,   1840,\n",
       "            344,    133,    656,     44, 125673,    656,    159,  21130, 162336,\n",
       "          14503,    656,  36263,    656, 128723,    656,  11841,    841,   9968,\n",
       "          31076,      4,     58,    656,  31005,    656,     72,    656,  96591,\n",
       "          16723,      5,    656,      2,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_Data[11576]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1475"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataloaders\n",
    "loader_obj = createDataloaders(combined_Data,config.TRAIN_BATCH_SIZE)\n",
    "train_dataloader = loader_obj.createDataloaders()\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(eval_data,config.VALID_BATCH_SIZE)\n",
    "val_dataloader = loader_obj.createDataloaders()\n",
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-17 13:01:27.792 pytorch-1-6-gpu-py36-ml-p3-2xlarge-aee363f24cc078bb4ee47bd46a8f:31 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-02-17 13:01:27.837 pytorch-1-6-gpu-py36-ml-p3-2xlarge-aee363f24cc078bb4ee47bd46a8f:31 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[     0, 126034,   7793,  ...,      1,      1,      1],\n",
       "         [     0,    581,  12877,  ...,      1,      1,      1],\n",
       "         [     0,    581,    601,  ...,      1,      1,      1],\n",
       "         ...,\n",
       "         [     0,    209,  15360,  ...,      1,      1,      1],\n",
       "         [     0,  52917,  10821,  ...,      1,      1,      1],\n",
       "         [     0,   2161,     70,  ...,      1,      1,      1]]),\n",
       " tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " tensor([[-100,    1,    1,  ..., -100, -100, -100],\n",
       "         [-100,    1,    1,  ..., -100, -100, -100],\n",
       "         [-100,    1,    1,  ..., -100, -100, -100],\n",
       "         ...,\n",
       "         [-100,    1,    1,  ..., -100, -100, -100],\n",
       "         [-100,    1,    1,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100]])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "batch # as seen, combination of labelled and unlabelled data in one training batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class GaussianNoise(nn.Module):\n",
    "#     \"\"\"Gaussian noise regularizer.\n",
    "\n",
    "#     Args:\n",
    "#         sigma (float, optional): relative standard deviation used to generate the\n",
    "#             noise. Relative means that it will be multiplied by the magnitude of\n",
    "#             the value your are adding the noise to. This means that sigma can be\n",
    "#             the same regardless of the scale of the vector.\n",
    "#         is_relative_detach (bool, optional): whether to detach the variable before\n",
    "#             computing the scale of the noise. If `False` then the scale of the noise\n",
    "#             won't be seen as a constant but something to optimize: this will bias the\n",
    "#             network to generate vectors with smaller values.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, sigma=0.1, is_relative_detach=True):\n",
    "#         super().__init__()\n",
    "#         self.sigma = sigma\n",
    "#         self.is_relative_detach = is_relative_detach\n",
    "#         self.noise = torch.tensor(0).to(device)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         if self.training and self.sigma != 0:\n",
    "#             scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n",
    "#             sampled_noise = self.noise.repeat(*x.size()).normal_() * scale\n",
    "#             x = x + sampled_noise\n",
    "#         return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loss = nn.MSELoss()\n",
    "# a = torch.tensor([[0.435,0.565],[0.820,0.180]])\n",
    "# b = torch.tensor([[0.620,0.380],[0.545,0.455]])\n",
    "# ConsistencyCost(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \n",
    "    def __init__(self, stddev):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.stddev = stddev\n",
    "\n",
    "    def forward(self, din):\n",
    "        \n",
    "        if self.training:\n",
    "            return din + torch.autograd.Variable(torch.randn(din.size()).cuda() * self.stddev)\n",
    "        \n",
    "        return din"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,std_gaussian=0.1,with_noise_layer = True, dropout_layer=False, dropout_prob = 0.3):\n",
    "        \n",
    "        super(EntityModel, self).__init__()\n",
    "        \n",
    "        self.std_gaussian = std_gaussian\n",
    "        self.with_noise_layer = with_noise_layer\n",
    "        self.bert = XLMRobertaModel.from_pretrained(config.BASE_MODEL,output_attentions = False, output_hidden_states = False)\n",
    "        self.dropout_layer = dropout_layer\n",
    "        self.dropout_prob = dropout_prob\n",
    "        if self.with_noise_layer:\n",
    "            self.noise = GaussianNoise(stddev=self.std_gaussian)\n",
    "        if self.dropout_layer:\n",
    "            self.bert_drop_1 = nn.Dropout(self.dropout_prob) # remove this or noise \n",
    "        self.out_tag = nn.Linear(768, 2)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "    \n",
    "    def forward(self, ids, attention_mask):\n",
    "        \n",
    "        outputs = self.bert(ids,\n",
    "                            attention_mask = attention_mask,\n",
    "                            return_dict=False)\n",
    "        \n",
    "        if (self.with_noise_layer):\n",
    "            \n",
    "            noise = self.noise(outputs[0]) # 256*768\n",
    "            \n",
    "            if self.dropout_layer:\n",
    "                bo_tag = self.bert_drop_1(noise)\n",
    "                tag = self.out_tag(bo_tag)\n",
    "            else:\n",
    "                tag = self.out_tag(noise)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if self.dropout_layer:\n",
    "                bo_tag = self.bert_drop_1(outputs[0])\n",
    "                tag = self.out_tag(bo_tag)\n",
    "            \n",
    "            else :\n",
    "                tag = self.out_tag(outputs[0])\n",
    "#         tag = self.out_tag(bo_tag) # 256 * 2 \n",
    "       \n",
    "        softmax_prob = self.softmax(tag)\n",
    "        \n",
    "#         loss_tag = loss_fn(tag,labels,attention_mask)\n",
    "        \n",
    "        return softmax_prob,tag\n",
    "#         return outputs[0], outputs[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationCost(output,target,mask):\n",
    "    \n",
    "    \n",
    "    active_loss = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "    active_logits = output.view(-1,2)\n",
    "    \n",
    "    active_labels = torch.where( # just append -100 for the padded tokens so its ignored when computing loss , no need now\n",
    "        active_loss,             # since its handled in preprocessing only\n",
    "        target.view(-1),\n",
    "        torch.tensor(-100).type_as(target)    \n",
    "    )\n",
    "    try:\n",
    "        class_0_weights =1/len(torch.where(active_labels==0)[0]) # trying to weight the labels as its unbalanced mostly\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        class_0_weights = 1e-8\n",
    "\n",
    "    try:\n",
    "        class_1_weights =1/len(torch.where(active_labels==1)[0])\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        class_1_weights = 1e-8\n",
    "    \n",
    "    weights_tensor = torch.tensor([class_0_weights,class_1_weights]).cuda()\n",
    "    lfn = nn.CrossEntropyLoss(weight = weights_tensor)\n",
    "    loss = lfn(active_logits,active_labels)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-08 1e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[0.2,0.5],[0.9,0.4],[0.9,0.2],[0.2,0.9],[0.7,0.4]])\n",
    "b = torch.tensor([-100,-100,-100,-100,-100])\n",
    "c = torch.tensor([1,1,1,1,1])\n",
    "ClassificationCost(a,b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConsistencyCost(student_output, teacher_output,mask):\n",
    "    \n",
    "    assert len(student_output) == len(teacher_output)\n",
    "    \n",
    "    loss = nn.MSELoss()\n",
    "    active_outputs = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "    flattened_outputs_student = student_output.view(-1,2)\n",
    "    flatenned_outputs_teacher = teacher_output.view(-1,2)\n",
    "\n",
    "    active_outputs_teacher=flatenned_outputs_teacher[torch.where(mask.view(-1) == 1)]\n",
    "    active_outputs_student=flattened_outputs_student[torch.where(mask.view(-1) == 1)]\n",
    "    \n",
    "    return 10*loss(active_outputs_student.view(-1),active_outputs_teacher.view(-1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8833333253860474\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "a = torch.tensor([[0.2,0.5],[0.9,0.4],[0.9,0.2],[0.2,0.9]])\n",
    "b = torch.tensor([[0.5,0.3],[0.7,0.2],[0.5,0.6],[0.7,0.2]])\n",
    "c = torch.tensor([1,1,1,0])\n",
    "print(ConsistencyCost(a,b,c).item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update teacher to be exponential moving average of student params.\n",
    "def update_teacher_params(student_model, teacher_model, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    \n",
    "    teacher_params = teacher_model.parameters()\n",
    "    student_params = student_model.parameters()\n",
    "    \n",
    "    assert sum(p.numel() for p in student_model.parameters()) == sum(p.numel() for p in teacher_model.parameters())\n",
    "    \n",
    "    alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    \n",
    "    for teacher_param, student_param in zip(teacher_params, student_params):\n",
    "            teacher_param.data.mul_(config.alpha).add_(1 - config.alpha, student_param.data)\n",
    "    \n",
    "    return teacher_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(p.numel() for p in model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, optimizer,scheduler, student_model, teacher_model,  epoch):\n",
    "    \n",
    "    student_model.train() # put student model in training mode\n",
    "    total_train_loss = 0\n",
    "    consistency_cst = 0\n",
    "    classification_cst=0\n",
    "    classification_cst_lst = []\n",
    "    consistency_cst_lst = []\n",
    "    overall_cst_lst = []\n",
    "    global_step = 0\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(train_dataloader, total = len(train_dataloader),position = 0 , leave = True)):\n",
    "\n",
    "        if (student_model.training):\n",
    "            \n",
    "            b_input_ids = batch[0].cuda()\n",
    "            b_input_mask = batch[1].cuda()\n",
    "            b_labels = batch[2].cuda()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output_student_softmax, output_student_logit = student_model( b_input_ids, attention_mask = b_input_mask )\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                \n",
    "                if (teacher_model.training!=True):\n",
    "                    output_teacher_softmax, _ = teacher_model( b_input_ids, attention_mask = b_input_mask )\n",
    "                else:\n",
    "                    print('Teacher is in training mode in current epoch',epoch)\n",
    "                    break\n",
    "\n",
    "            classification_cost =  ClassificationCost(output_student_logit,b_labels,b_input_mask)\n",
    "            classification_cst+=classification_cost.item()\n",
    "            \n",
    "            consistency_cost = ConsistencyCost(output_student_softmax,output_teacher_softmax,b_input_mask)\n",
    "            consistency_cst+=consistency_cost.item()\n",
    "            \n",
    "            overall_cost = (config.ratio * classification_cost) + ((1 - config.ratio) * consistency_cost)\n",
    "            \n",
    "            overall_cost.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            total_train_loss+=overall_cost.item()\n",
    "            \n",
    "            teacher_model = update_teacher_params(student_model , teacher_model , config.alpha,global_step)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                teacher_softmax,_ = teacher_model(b_input_ids, attention_mask = b_input_mask)\n",
    "            \n",
    "            if step % 50 == 0 and step!=0:\n",
    "                print ('train loss : ', total_train_loss/step)\n",
    "                print('Consistency Cost :', consistency_cst/step)\n",
    "                print('Classification Cost :', classification_cst/step)                         \n",
    "        \n",
    "        else:\n",
    "            print('Student model is not in training mode in epoch', epoch)\n",
    "#             break\n",
    "        global_step+=1\n",
    "    consistency_cst_lst.append(consistency_cst/len(train_dataloader))\n",
    "    classification_cst_lst.append(classification_cst/len(train_dataloader))\n",
    "    overall_cst_lst.append(total_train_loss/len(train_dataloader))  \n",
    "        \n",
    "    return (consistency_cst_lst, classification_cst_lst, overall_cst_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    lst_active_preds = []\n",
    "    lst_active_labels = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in tqdm(test_loader,total = len(test_loader),position = 0 , leave = True):\n",
    "            \n",
    "            b_input_ids_eval = batch[0].cuda()\n",
    "            b_input_mask_eval = batch[1].cuda()\n",
    "            b_labels_eval = batch[2].cuda()\n",
    "            \n",
    "            _, output= model(b_input_ids_eval,attention_mask = b_input_mask_eval)\n",
    "            \n",
    "            classification_cost =  ClassificationCost(output,b_labels_eval,b_input_mask_eval)\n",
    "            test_loss+=classification_cost\n",
    "            \n",
    "            labels = b_labels_eval.view(-1) \n",
    "            active_logits = output.view(-1, 2)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "            active_accuracy = labels.view(-1) != -100\n",
    "            labels_tmp = torch.masked_select(labels, active_accuracy) \n",
    "            pred_tmp = torch.masked_select(flattened_predictions, active_accuracy) \n",
    "            lst_active_labels.extend(labels_tmp.tolist())\n",
    "            lst_active_preds.extend(pred_tmp.tolist())\n",
    "            \n",
    "    avg_f1_score_0=f1_score(lst_active_labels,lst_active_preds,average='binary',pos_label = 0)\n",
    "    avg_f1_score_1=f1_score(lst_active_labels,lst_active_preds,average='binary',pos_label = 1)\n",
    "    avg_accuracy_score=accuracy_score(lst_active_labels,lst_active_preds)\n",
    "    avg_mcc_score = matthews_corrcoef(lst_active_labels,lst_active_preds)\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    print('Overall validation loss:', test_loss)\n",
    "    print('Average F1 Validation score for whole sentence class 0 :' ,avg_f1_score_0)\n",
    "    print('Average F1 Validation score for whole sentence class 1 :' ,avg_f1_score_1)\n",
    "    print('Average Accuracy Validation score whole sentence  :' ,avg_accuracy_score)\n",
    "    print('Average mcc Validation score whole sentence :' ,avg_mcc_score)\n",
    "    print('Classification Report :'+'\\n', classification_report(lst_active_labels,lst_active_preds))\n",
    "\n",
    "    return (test_loss, avg_f1_score_0 , avg_f1_score_1, avg_accuracy_score, avg_mcc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MeanTeacher(train_dataloader, val_dataloader,noise_layer=True, dropout_layer = False):\n",
    "    \n",
    "    \n",
    "    # train losses\n",
    "    epochs_consistency_lst =[]\n",
    "    epochs_classification_lst = []\n",
    "    epochs_overall_lst = []\n",
    "    \n",
    "    #test metrices for student\n",
    "    epochs_f1_score_0_lst_student = []\n",
    "    epochs_f1_score_1_lst_student = []\n",
    "    epochs_accuracy_lst_student = []\n",
    "    epochs_mcc_lst_student = []\n",
    "    epochs_cost_lst_student=[]\n",
    "    \n",
    "    #test metrices for teacher\n",
    "    epochs_f1_score_0_lst_teacher= []\n",
    "    epochs_f1_score_1_lst_teacher = []\n",
    "    epochs_accuracy_lst_teacher = []\n",
    "    epochs_mcc_lst_teacher = []\n",
    "    epochs_cost_lst_teacher=[]\n",
    "    \n",
    "    #initialaize the language models\n",
    "    student = EntityModel(std_gaussian=config.gaussian_noise_std_student, with_noise_layer=noise_layer, dropout_layer=dropout_layer) \n",
    "    teacher = EntityModel(std_gaussian=config.gaussian_noise_std_teacher, with_noise_layer=noise_layer)\n",
    "    \n",
    "    student.cuda() # take model to gpu\n",
    "    teacher.cuda()\n",
    "    teacher.eval()\n",
    "    param_optimizer_student = list(student.named_parameters())\n",
    "    param_teacher = list(teacher.named_parameters())\n",
    "    \n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer_student if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer_student if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "    optimizer = AdamW(optimizer_parameters, lr=config.lr)\n",
    "    num_train_steps = int(len(train_dataloader) * config.EPOCHS)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "#         optimizer, T_max=num_train_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    ")\n",
    "    for epoch in range(0,config.EPOCHS):\n",
    "        print(f'Current epoch is {epoch+1} of {config.EPOCHS}')\n",
    "        \n",
    "        consistency_cost , classification_cost , overall_cost = train(train_dataloader, optimizer,scheduler,student,teacher,epoch)\n",
    "        \n",
    "        epochs_consistency_lst.append(consistency_cost)\n",
    "        epochs_classification_lst.append(classification_cost)\n",
    "        epochs_overall_lst.append(overall_cost)\n",
    "        \n",
    "        print('---------Running validation for student -------------')\n",
    "        test_loss_student, avg_f1_score_0_student, avg_f1_score_1_student, avg_accuracy_score_student, avg_mcc_score_student = test(student,val_dataloader)\n",
    "        \n",
    "        epochs_f1_score_0_lst_student.append(avg_f1_score_0_student)\n",
    "        epochs_f1_score_1_lst_student.append(avg_f1_score_1_student)\n",
    "        epochs_accuracy_lst_student.append(avg_accuracy_score_student)\n",
    "        epochs_mcc_lst_student.append(avg_mcc_score_student)\n",
    "        epochs_cost_lst_student.append(test_loss_student)\n",
    "        \n",
    "        print('---------Running validation for teacher -------------')\n",
    "\n",
    "        test_loss_teacher, avg_f1_score_0_teacher, avg_f1_score_1_teacher, avg_accuracy_score_teacher, avg_mcc_score_teacher=test(teacher,val_dataloader)\n",
    "        \n",
    "        epochs_f1_score_0_lst_teacher.append(avg_f1_score_1_teacher)\n",
    "        epochs_f1_score_1_lst_teacher.append(avg_f1_score_0_teacher)\n",
    "        epochs_accuracy_lst_teacher.append(avg_accuracy_score_teacher)\n",
    "        epochs_mcc_lst_teacher.append(avg_mcc_score_teacher)\n",
    "        epochs_cost_lst_teacher.append(test_loss_teacher)\n",
    "        \n",
    "#         break\n",
    "        \n",
    "        \n",
    "    return (epochs_consistency_lst,epochs_classification_lst,epochs_overall_lst,epochs_f1_score_0_lst_student,epochs_f1_score_1_lst_student,\n",
    "           epochs_accuracy_lst_student,epochs_mcc_lst_student,epochs_cost_lst_student,epochs_f1_score_0_lst_teacher,epochs_f1_score_1_lst_teacher,\n",
    "            epochs_accuracy_lst_teacher,epochs_mcc_lst_teacher,epochs_cost_lst_teacher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> without weighted classification cost - with Noise - without dropout </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/1475 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 1 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /codebuild/output/src811146734/src/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  del sys.path[0]\n",
      "  3%|         | 51/1475 [00:31<14:58,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.2920157599449158\n",
      "Consistency Cost : 0.12211377955973149\n",
      "Classification Cost : 0.4619177380204201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 101/1475 [01:03<14:48,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.27036710843443873\n",
      "Consistency Cost : 0.09794396448880434\n",
      "Classification Cost : 0.4427902503311634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 151/1475 [01:36<14:31,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.2556134384870529\n",
      "Consistency Cost : 0.08304985461135705\n",
      "Classification Cost : 0.4281770211458206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 201/1475 [02:09<14:11,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.23714423509314655\n",
      "Consistency Cost : 0.07435021691024303\n",
      "Classification Cost : 0.3999382524192333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 251/1475 [02:43<13:57,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.229057481944561\n",
      "Consistency Cost : 0.06443319586664438\n",
      "Classification Cost : 0.3936817668676376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 301/1475 [03:17<13:21,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.22419390770296255\n",
      "Consistency Cost : 0.05710310551337898\n",
      "Classification Cost : 0.39128470892707506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 351/1475 [03:51<12:47,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.21780252531436936\n",
      "Consistency Cost : 0.05116686809541924\n",
      "Classification Cost : 0.38443818151950837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 401/1475 [04:25<12:14,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.21545040166238322\n",
      "Consistency Cost : 0.047681810455396774\n",
      "Classification Cost : 0.383218991830945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 451/1475 [04:59<11:39,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.2114437905471358\n",
      "Consistency Cost : 0.044007382730229035\n",
      "Classification Cost : 0.37888019720713295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 501/1475 [05:34<11:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.20804717661999167\n",
      "Consistency Cost : 0.04096882551535964\n",
      "Classification Cost : 0.37512552678585054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 551/1475 [06:08<10:34,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.2055562951398844\n",
      "Consistency Cost : 0.038503225418654356\n",
      "Classification Cost : 0.37260936374014075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 601/1475 [06:42<09:58,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.20400534658692776\n",
      "Consistency Cost : 0.03630163878047218\n",
      "Classification Cost : 0.3717090534542998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 651/1475 [07:16<09:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.20077362051663492\n",
      "Consistency Cost : 0.034531650375574825\n",
      "Classification Cost : 0.3670155898653544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 701/1475 [07:50<08:48,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.19895629946608095\n",
      "Consistency Cost : 0.03304554823253836\n",
      "Classification Cost : 0.364867049955896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 751/1475 [08:25<08:15,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1972683510798961\n",
      "Consistency Cost : 0.031667745728045704\n",
      "Classification Cost : 0.36286895562211674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 801/1475 [08:59<07:40,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.19606582018721383\n",
      "Consistency Cost : 0.03044711292721331\n",
      "Classification Cost : 0.36168452659621836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 851/1475 [09:33<07:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.19462986620143055\n",
      "Consistency Cost : 0.029301973236176896\n",
      "Classification Cost : 0.35995775831972854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 901/1475 [10:07<06:32,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1944362679962069\n",
      "Consistency Cost : 0.028370218282151555\n",
      "Classification Cost : 0.36050231696003016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 951/1475 [10:41<05:57,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.19259576770035844\n",
      "Consistency Cost : 0.027403883064459813\n",
      "Classification Cost : 0.35778765154512304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1001/1475 [11:16<05:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.19110013258084654\n",
      "Consistency Cost : 0.026565704292617738\n",
      "Classification Cost : 0.3556345601379871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 1051/1475 [11:50<04:49,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.19039089697590542\n",
      "Consistency Cost : 0.02579874342529192\n",
      "Classification Cost : 0.35498304987237567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 1101/1475 [12:24<04:15,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.18988577505192636\n",
      "Consistency Cost : 0.025126837680793622\n",
      "Classification Cost : 0.3546447117288004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1151/1475 [12:58<03:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1889017626558147\n",
      "Consistency Cost : 0.024537784355166167\n",
      "Classification Cost : 0.35326574036284636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 1201/1475 [13:32<03:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1878497375183118\n",
      "Consistency Cost : 0.023936027427747225\n",
      "Classification Cost : 0.35176344704503815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 1251/1475 [14:07<02:33,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.18776014084517956\n",
      "Consistency Cost : 0.023392095291614533\n",
      "Classification Cost : 0.35212818589806555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 1301/1475 [14:41<01:58,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.18679646626401405\n",
      "Consistency Cost : 0.02282489656112515\n",
      "Classification Cost : 0.35076803549551044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 1351/1475 [15:15<01:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1859076963447862\n",
      "Consistency Cost : 0.02231399722431821\n",
      "Classification Cost : 0.349501394999248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 1401/1475 [15:49<00:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.18497331592221078\n",
      "Consistency Cost : 0.021824642799994243\n",
      "Classification Cost : 0.3481219885711159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 1451/1475 [16:24<00:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.18420696363463226\n",
      "Consistency Cost : 0.021388765798624733\n",
      "Classification Cost : 0.347025160979608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1475/1475 [16:40<00:00,  1.47it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.3101, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.049021276595744685\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9330858135217678\n",
      "Average Accuracy Validation score whole sentence  : 0.8749692290477789\n",
      "Average mcc Validation score whole sentence : 0.11091686612715324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.03      0.05     28264\n",
      "           1       0.88      1.00      0.93    195161\n",
      "\n",
      "    accuracy                           0.87    223425\n",
      "   macro avg       0.76      0.51      0.49    223425\n",
      "weighted avg       0.85      0.87      0.82    223425\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.3162, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.004726964865246225\n",
      "Average F1 Validation score for whole sentence class 1 : 0.932583356829836\n",
      "Average Accuracy Validation score whole sentence  : 0.8737204878594607\n",
      "Average mcc Validation score whole sentence : 0.039153562243505295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1475 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.00      0.00     28264\n",
      "           1       0.87      1.00      0.93    195161\n",
      "\n",
      "    accuracy                           0.87    223425\n",
      "   macro avg       0.84      0.50      0.47    223425\n",
      "weighted avg       0.86      0.87      0.82    223425\n",
      "\n",
      "Current epoch is 2 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 51/1475 [00:34<16:14,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.17259153351187706\n",
      "Consistency Cost : 0.009171052491292358\n",
      "Classification Cost : 0.33601201117038726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 101/1475 [01:09<15:40,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.17130960269365458\n",
      "Consistency Cost : 0.009641253110021352\n",
      "Classification Cost : 0.33297794982790946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 151/1475 [01:43<15:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1672524958755821\n",
      "Consistency Cost : 0.009102491214871406\n",
      "Classification Cost : 0.3254024990399679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 201/1475 [02:17<14:34,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.16339776610257103\n",
      "Consistency Cost : 0.008951377808116376\n",
      "Classification Cost : 0.31784415293484924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 251/1475 [02:51<13:58,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.16034576003067194\n",
      "Consistency Cost : 0.008977956188842654\n",
      "Classification Cost : 0.31171356260031463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 301/1475 [03:26<13:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15732155460553865\n",
      "Consistency Cost : 0.008794871914821367\n",
      "Classification Cost : 0.3058482361150285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 351/1475 [04:00<12:48,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15760297650870467\n",
      "Consistency Cost : 0.00886608438566327\n",
      "Classification Cost : 0.30633986750351533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 401/1475 [04:34<12:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15663958525983618\n",
      "Consistency Cost : 0.008671752590453252\n",
      "Classification Cost : 0.3046074168244377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 451/1475 [05:08<11:40,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15652376448321673\n",
      "Consistency Cost : 0.00856240641636153\n",
      "Classification Cost : 0.3044851215721832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 501/1475 [05:43<11:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15414557320065797\n",
      "Consistency Cost : 0.008270724368747324\n",
      "Classification Cost : 0.3000204211510718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 551/1475 [06:17<10:32,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1540752543932335\n",
      "Consistency Cost : 0.008193515646271408\n",
      "Classification Cost : 0.29995699227194894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 601/1475 [06:51<09:57,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15427160332755496\n",
      "Consistency Cost : 0.008183396698053305\n",
      "Classification Cost : 0.3003598092403263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 651/1475 [07:25<09:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15402246260728975\n",
      "Consistency Cost : 0.008025571178071775\n",
      "Classification Cost : 0.30001935340177555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 701/1475 [08:00<08:51,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15386288558132946\n",
      "Consistency Cost : 0.00791571883418198\n",
      "Classification Cost : 0.29981005171846065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 751/1475 [08:34<08:15,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15514175304149588\n",
      "Consistency Cost : 0.007840353831027946\n",
      "Classification Cost : 0.3024431516552965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 801/1475 [09:08<07:43,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1557997699608677\n",
      "Consistency Cost : 0.007839272939017974\n",
      "Classification Cost : 0.3037602664087899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 851/1475 [09:42<07:06,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1560570066676968\n",
      "Consistency Cost : 0.007747825102551895\n",
      "Classification Cost : 0.3043661876921268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 901/1475 [10:16<06:34,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15693226072581537\n",
      "Consistency Cost : 0.0076703190348214574\n",
      "Classification Cost : 0.3061942018340859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 951/1475 [10:51<05:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15599908305960095\n",
      "Consistency Cost : 0.007504428847214991\n",
      "Classification Cost : 0.30449373672471236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1001/1475 [11:25<05:25,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15593808245114632\n",
      "Consistency Cost : 0.007388347176194657\n",
      "Classification Cost : 0.30448781727068125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 1051/1475 [11:59<04:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1554720679334908\n",
      "Consistency Cost : 0.007273389873305513\n",
      "Classification Cost : 0.303670745610836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 1101/1475 [12:33<04:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15542544559483015\n",
      "Consistency Cost : 0.007128244927787984\n",
      "Classification Cost : 0.3037226459028369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1151/1475 [13:08<03:42,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1557243561857309\n",
      "Consistency Cost : 0.0070773301498316555\n",
      "Classification Cost : 0.3043713818863034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 1201/1475 [13:42<03:08,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15518633832247966\n",
      "Consistency Cost : 0.0069787746417568994\n",
      "Classification Cost : 0.30339390169363467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 1251/1475 [14:16<02:33,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15520616174368188\n",
      "Consistency Cost : 0.006873944662790746\n",
      "Classification Cost : 0.30353837857693433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 1301/1475 [14:50<01:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1549735985982429\n",
      "Consistency Cost : 0.0067969968068288065\n",
      "Classification Cost : 0.3031502000686641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 1351/1475 [15:25<01:25,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15511247458828922\n",
      "Consistency Cost : 0.006828290587636056\n",
      "Classification Cost : 0.3033966582061516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 1401/1475 [15:59<00:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15521609575770395\n",
      "Consistency Cost : 0.0067608190572354945\n",
      "Classification Cost : 0.30367137207383554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 1451/1475 [16:33<00:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15526692622937344\n",
      "Consistency Cost : 0.006737382885486145\n",
      "Classification Cost : 0.30379646923136094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1475/1475 [16:49<00:00,  1.46it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.3119, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.16014932337844143\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9349007125547075\n",
      "Average Accuracy Validation score whole sentence  : 0.8791675058744545\n",
      "Average mcc Validation score whole sentence : 0.21467604355071182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.09      0.16     28264\n",
      "           1       0.88      0.99      0.93    195161\n",
      "\n",
      "    accuracy                           0.88    223425\n",
      "   macro avg       0.77      0.54      0.55    223425\n",
      "weighted avg       0.86      0.88      0.84    223425\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.3096, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.18258803460460582\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9351870190472971\n",
      "Average Accuracy Validation score whole sentence  : 0.8798970571780239\n",
      "Average mcc Validation score whole sentence : 0.2303095748981721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1475 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.11      0.18     28264\n",
      "           1       0.88      0.99      0.94    195161\n",
      "\n",
      "    accuracy                           0.88    223425\n",
      "   macro avg       0.77      0.55      0.56    223425\n",
      "weighted avg       0.86      0.88      0.84    223425\n",
      "\n",
      "Current epoch is 3 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 51/1475 [00:34<16:17,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15582989316433668\n",
      "Consistency Cost : 0.004344486435875297\n",
      "Classification Cost : 0.30731530010700225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 101/1475 [01:09<15:43,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15219980077818035\n",
      "Consistency Cost : 0.0048903681494994085\n",
      "Classification Cost : 0.2995092339813709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 151/1475 [01:43<15:09,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.14087349792011084\n",
      "Consistency Cost : 0.004865146681355933\n",
      "Classification Cost : 0.2768818501879772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 201/1475 [02:17<14:31,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.14177853656699882\n",
      "Consistency Cost : 0.004844655246706679\n",
      "Classification Cost : 0.2787124183960259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 251/1475 [02:51<13:57,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1409304646011442\n",
      "Consistency Cost : 0.004903445538366214\n",
      "Classification Cost : 0.2769574838280678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 301/1475 [03:26<13:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13870528589691578\n",
      "Consistency Cost : 0.004991304611321539\n",
      "Classification Cost : 0.27241926747684675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 351/1475 [04:00<12:49,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13715437931998167\n",
      "Consistency Cost : 0.0048469594225753095\n",
      "Classification Cost : 0.2694617996524487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 401/1475 [04:34<12:17,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13811968334302946\n",
      "Consistency Cost : 0.005021438773983391\n",
      "Classification Cost : 0.27121792823541907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 451/1475 [05:08<11:42,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1370884349362071\n",
      "Consistency Cost : 0.004975626283299385\n",
      "Classification Cost : 0.26920124378883176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 501/1475 [05:43<11:09,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1379468115567579\n",
      "Consistency Cost : 0.00520069410733413\n",
      "Classification Cost : 0.2706929291673005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 551/1475 [06:17<10:33,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13783620781175243\n",
      "Consistency Cost : 0.005197097450621765\n",
      "Classification Cost : 0.2704753183200955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 601/1475 [06:51<09:57,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13710437933763994\n",
      "Consistency Cost : 0.005143554565923599\n",
      "Classification Cost : 0.26906520426583785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 651/1475 [07:25<09:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.136285591104041\n",
      "Consistency Cost : 0.005055438338313251\n",
      "Classification Cost : 0.26751574410555456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 701/1475 [08:00<08:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1369941298970038\n",
      "Consistency Cost : 0.005096610520434167\n",
      "Classification Cost : 0.2688916494511068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 751/1475 [08:34<08:15,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13707055383800373\n",
      "Consistency Cost : 0.005134504447846363\n",
      "Classification Cost : 0.26900660335520904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 801/1475 [09:08<07:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13679828317883222\n",
      "Consistency Cost : 0.0051231547887437045\n",
      "Classification Cost : 0.26847341168671846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 851/1475 [09:42<07:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1369051143991665\n",
      "Consistency Cost : 0.00510542212471859\n",
      "Classification Cost : 0.2687048067459289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 901/1475 [10:17<06:32,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1363919451132339\n",
      "Consistency Cost : 0.005089043224514979\n",
      "Classification Cost : 0.2676948471501884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 951/1475 [10:51<05:58,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13632727896304506\n",
      "Consistency Cost : 0.005111079372306306\n",
      "Classification Cost : 0.26754347866008943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1001/1475 [11:25<05:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13625417327330797\n",
      "Consistency Cost : 0.005112430721521378\n",
      "Classification Cost : 0.26739591591153294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 1051/1475 [11:59<04:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1367213942075891\n",
      "Consistency Cost : 0.005130476442697857\n",
      "Classification Cost : 0.26831231207276385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 1101/1475 [12:34<04:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13656364523538453\n",
      "Consistency Cost : 0.005081453638743948\n",
      "Classification Cost : 0.2680458368589594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1151/1475 [13:08<03:42,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1371230023611165\n",
      "Consistency Cost : 0.005479771630717036\n",
      "Classification Cost : 0.2687662331395499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 1201/1475 [13:42<03:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13703168592975998\n",
      "Consistency Cost : 0.005556943877988185\n",
      "Classification Cost : 0.26850642811429376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 1251/1475 [14:16<02:33,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13663410485188943\n",
      "Consistency Cost : 0.005599621289782226\n",
      "Classification Cost : 0.26766858847364783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 1301/1475 [14:50<01:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13649808640329866\n",
      "Consistency Cost : 0.0056032022060110015\n",
      "Classification Cost : 0.2673929706065414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 1351/1475 [15:25<01:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1363034066175654\n",
      "Consistency Cost : 0.005566194062034979\n",
      "Classification Cost : 0.2670406191844355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 1401/1475 [15:59<00:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1359450562048005\n",
      "Consistency Cost : 0.005552867479896772\n",
      "Classification Cost : 0.2663372449330719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 1451/1475 [16:33<00:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1356031333240038\n",
      "Consistency Cost : 0.005538594861121463\n",
      "Classification Cost : 0.2656676717051144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1475/1475 [16:49<00:00,  1.46it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.3366, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.27872357701572525\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9349870579137015\n",
      "Average Accuracy Validation score whole sentence  : 0.8807250755287009\n",
      "Average mcc Validation score whole sentence : 0.2821898434785807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.18      0.28     28264\n",
      "           1       0.89      0.98      0.93    195161\n",
      "\n",
      "    accuracy                           0.88    223425\n",
      "   macro avg       0.74      0.58      0.61    223425\n",
      "weighted avg       0.85      0.88      0.85    223425\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.3293, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.25579500435503355\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9355953304365376\n",
      "Average Accuracy Validation score whole sentence  : 0.8814501510574018\n",
      "Average mcc Validation score whole sentence : 0.2740634967010711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1475 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.16      0.26     28264\n",
      "           1       0.89      0.99      0.94    195161\n",
      "\n",
      "    accuracy                           0.88    223425\n",
      "   macro avg       0.76      0.57      0.60    223425\n",
      "weighted avg       0.86      0.88      0.85    223425\n",
      "\n",
      "Current epoch is 4 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 51/1475 [00:34<16:18,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10975414164364337\n",
      "Consistency Cost : 0.005136605706065893\n",
      "Classification Cost : 0.21437167704105378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 101/1475 [01:09<15:39,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11020818299701204\n",
      "Consistency Cost : 0.004880702484515495\n",
      "Classification Cost : 0.21553566310554742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 151/1475 [01:43<15:05,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11243063764083976\n",
      "Consistency Cost : 0.005041702835975836\n",
      "Classification Cost : 0.2198195725431045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 201/1475 [02:17<14:31,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11594823544015526\n",
      "Consistency Cost : 0.004892675123701337\n",
      "Classification Cost : 0.22700379576534033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 251/1475 [02:51<13:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11612138252065052\n",
      "Consistency Cost : 0.005242524153320119\n",
      "Classification Cost : 0.22700024105608463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 301/1475 [03:26<13:22,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11533325292936449\n",
      "Consistency Cost : 0.005332052972516976\n",
      "Classification Cost : 0.22533445306122302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 351/1475 [04:00<12:49,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11616302212301109\n",
      "Consistency Cost : 0.005151901270562251\n",
      "Classification Cost : 0.22717414319515228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 401/1475 [04:34<12:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11744694036024157\n",
      "Consistency Cost : 0.005324725668469909\n",
      "Classification Cost : 0.22956915533170105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 451/1475 [05:08<11:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11806211976179232\n",
      "Consistency Cost : 0.005424795808374054\n",
      "Classification Cost : 0.23069944375918972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 501/1475 [05:43<11:06,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11733565480995457\n",
      "Consistency Cost : 0.005348968628328294\n",
      "Classification Cost : 0.2293223410397768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 551/1475 [06:17<10:32,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11720914570773444\n",
      "Consistency Cost : 0.005317279357166791\n",
      "Classification Cost : 0.22910101201046598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 601/1475 [06:51<09:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1178258716656031\n",
      "Consistency Cost : 0.005254991359057991\n",
      "Classification Cost : 0.23039675187629957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 651/1475 [07:25<09:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11773838081374728\n",
      "Consistency Cost : 0.0051921263778618035\n",
      "Classification Cost : 0.23028463524981188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 701/1475 [08:00<08:49,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11794760822497274\n",
      "Consistency Cost : 0.005246113854975972\n",
      "Classification Cost : 0.23064910263621383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 751/1475 [08:34<08:15,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11818367516965372\n",
      "Consistency Cost : 0.005274703383174104\n",
      "Classification Cost : 0.23109264711290597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 801/1475 [09:08<07:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11831312900003468\n",
      "Consistency Cost : 0.00529628232910909\n",
      "Classification Cost : 0.2313299759081565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 851/1475 [09:42<07:06,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11892158505587277\n",
      "Consistency Cost : 0.0052672874861437935\n",
      "Classification Cost : 0.2325758828244665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 901/1475 [10:17<06:33,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11870674677372639\n",
      "Consistency Cost : 0.005240202182936224\n",
      "Classification Cost : 0.2321732915027274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 951/1475 [10:51<05:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11787937418972816\n",
      "Consistency Cost : 0.005168036561624735\n",
      "Classification Cost : 0.23059071200066492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1001/1475 [11:25<05:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1173065416476893\n",
      "Consistency Cost : 0.005185592043650104\n",
      "Classification Cost : 0.22942749140784144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 1051/1475 [11:59<04:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11691802885176869\n",
      "Consistency Cost : 0.005157648969879596\n",
      "Classification Cost : 0.22867840882035947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 1101/1475 [12:34<04:15,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11671023428115983\n",
      "Consistency Cost : 0.0051759406284757215\n",
      "Classification Cost : 0.2282445279356431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1151/1475 [13:08<03:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11677408646279692\n",
      "Consistency Cost : 0.005231172638798497\n",
      "Classification Cost : 0.22831700026017168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 1201/1475 [13:42<03:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11641688107366159\n",
      "Consistency Cost : 0.0052384956914223344\n",
      "Classification Cost : 0.22759526640720046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 1251/1475 [14:16<02:33,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1161394780141185\n",
      "Consistency Cost : 0.005208491261606105\n",
      "Classification Cost : 0.22707046475186943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 1301/1475 [14:51<01:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11630361165601734\n",
      "Consistency Cost : 0.005215998317647833\n",
      "Classification Cost : 0.22739122494696998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 1351/1475 [15:25<01:25,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11654516660678416\n",
      "Consistency Cost : 0.0052295645019168864\n",
      "Classification Cost : 0.22786076872782024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 1401/1475 [15:59<00:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11611015955486177\n",
      "Consistency Cost : 0.0051934034974172915\n",
      "Classification Cost : 0.2270269156323879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 1451/1475 [16:33<00:16,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11590036671087828\n",
      "Consistency Cost : 0.005169579109943729\n",
      "Classification Cost : 0.22663115431426156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1475/1475 [16:50<00:00,  1.46it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.3790, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.26795159369721133\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9356403945084348\n",
      "Average Accuracy Validation score whole sentence  : 0.8816828913505651\n",
      "Average mcc Validation score whole sentence : 0.28125344408795167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.17      0.27     28264\n",
      "           1       0.89      0.98      0.94    195161\n",
      "\n",
      "    accuracy                           0.88    223425\n",
      "   macro avg       0.75      0.58      0.60    223425\n",
      "weighted avg       0.86      0.88      0.85    223425\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.3599, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.28102776491103787\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9356648437519048\n",
      "Average Accuracy Validation score whole sentence  : 0.8818977285442542\n",
      "Average mcc Validation score whole sentence : 0.2888736091804686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1475 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.18      0.28     28264\n",
      "           1       0.89      0.98      0.94    195161\n",
      "\n",
      "    accuracy                           0.88    223425\n",
      "   macro avg       0.75      0.58      0.61    223425\n",
      "weighted avg       0.86      0.88      0.85    223425\n",
      "\n",
      "Current epoch is 5 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 51/1475 [00:34<16:13,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08272884535021148\n",
      "Consistency Cost : 0.0037819027388468385\n",
      "Classification Cost : 0.16167578803375363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 101/1475 [01:09<15:40,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09258502991928254\n",
      "Consistency Cost : 0.0043365371268009765\n",
      "Classification Cost : 0.18083352216519416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 151/1475 [01:43<15:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09198780189733952\n",
      "Consistency Cost : 0.004342372441897169\n",
      "Classification Cost : 0.17963323067252834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 201/1475 [02:17<14:33,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09725244552013464\n",
      "Consistency Cost : 0.004531161728373263\n",
      "Classification Cost : 0.1899737284751609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 251/1475 [02:51<13:57,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09760727190691977\n",
      "Consistency Cost : 0.004572269616881386\n",
      "Classification Cost : 0.19064227357879282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 301/1475 [03:26<13:22,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09964092438186829\n",
      "Consistency Cost : 0.004578227013310728\n",
      "Classification Cost : 0.19470362132415175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 351/1475 [04:00<12:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10031118215568963\n",
      "Consistency Cost : 0.004622386485404734\n",
      "Classification Cost : 0.1959999774449638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 401/1475 [04:34<12:14,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10115078932816686\n",
      "Consistency Cost : 0.004728150996088516\n",
      "Classification Cost : 0.19757342723663895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 451/1475 [05:08<11:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1004794167497635\n",
      "Consistency Cost : 0.0047964105661958455\n",
      "Classification Cost : 0.19616242251565888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 501/1475 [05:42<11:08,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10177830656041624\n",
      "Consistency Cost : 0.0048124461139086635\n",
      "Classification Cost : 0.19874416677746923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 551/1475 [06:17<10:32,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10074458030205939\n",
      "Consistency Cost : 0.004827435046688399\n",
      "Classification Cost : 0.19666172528724102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 601/1475 [06:51<09:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10076920656618313\n",
      "Consistency Cost : 0.004909050128189847\n",
      "Classification Cost : 0.1966293627419509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 651/1475 [07:25<09:25,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10062564359489792\n",
      "Consistency Cost : 0.004932016412046953\n",
      "Classification Cost : 0.19631927044345782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 701/1475 [07:59<08:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.0996287017772972\n",
      "Consistency Cost : 0.0049550977378385146\n",
      "Classification Cost : 0.19430230550401445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 751/1475 [08:34<08:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10060841725595916\n",
      "Consistency Cost : 0.00498134269619671\n",
      "Classification Cost : 0.19623549146888156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 801/1475 [09:08<07:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10032647209736752\n",
      "Consistency Cost : 0.004976226184371626\n",
      "Classification Cost : 0.19567671765980776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 851/1475 [09:42<07:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10028448848409907\n",
      "Consistency Cost : 0.005003758263294859\n",
      "Classification Cost : 0.19556521841653568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 901/1475 [10:16<06:32,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10041452518528482\n",
      "Consistency Cost : 0.0050456727809634885\n",
      "Classification Cost : 0.1957833772778718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 951/1475 [10:51<05:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10046703325265921\n",
      "Consistency Cost : 0.005038798173252297\n",
      "Classification Cost : 0.19589526798429066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1001/1475 [11:25<05:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09989705667481757\n",
      "Consistency Cost : 0.00503057172356057\n",
      "Classification Cost : 0.19476354125374928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 1051/1475 [11:59<04:49,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10002354641189976\n",
      "Consistency Cost : 0.005025281877107253\n",
      "Classification Cost : 0.19502181063140078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 1101/1475 [12:33<04:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09991424133858262\n",
      "Consistency Cost : 0.0050405726465132\n",
      "Classification Cost : 0.19478790973609483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1151/1475 [13:07<03:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.10025633999179422\n",
      "Consistency Cost : 0.005053281661087606\n",
      "Classification Cost : 0.1954593980340692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 1201/1475 [13:42<03:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09983213413979683\n",
      "Consistency Cost : 0.005032259393604666\n",
      "Classification Cost : 0.19463200859997112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 1251/1475 [14:16<02:33,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09992630563385319\n",
      "Consistency Cost : 0.005060386350448243\n",
      "Classification Cost : 0.19479222463183105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 1301/1475 [14:50<01:58,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09978682282911346\n",
      "Consistency Cost : 0.0050476201570619685\n",
      "Classification Cost : 0.1945260252112236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 1351/1475 [15:24<01:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09963961392393146\n",
      "Consistency Cost : 0.005029073312762193\n",
      "Classification Cost : 0.19425015425068085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 1401/1475 [15:58<00:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09987211751364937\n",
      "Consistency Cost : 0.005012892638686545\n",
      "Classification Cost : 0.1947313420843732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 1451/1475 [16:33<00:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09984447762261722\n",
      "Consistency Cost : 0.005019430383208914\n",
      "Classification Cost : 0.194669524570927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1475/1475 [16:49<00:00,  1.46it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.3851, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.30525874711921225\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9350863541376087\n",
      "Average Accuracy Validation score whole sentence  : 0.8812666442877923\n",
      "Average mcc Validation score whole sentence : 0.29892900996142696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.21      0.31     28264\n",
      "           1       0.89      0.98      0.94    195161\n",
      "\n",
      "    accuracy                           0.88    223425\n",
      "   macro avg       0.74      0.59      0.62    223425\n",
      "weighted avg       0.86      0.88      0.86    223425\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.3860, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.30267312144811614\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9351730008169414\n",
      "Average Accuracy Validation score whole sentence  : 0.8813740628846369\n",
      "Average mcc Validation score whole sentence : 0.29794973161317956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1475 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.20      0.30     28264\n",
      "           1       0.89      0.98      0.94    195161\n",
      "\n",
      "    accuracy                           0.88    223425\n",
      "   macro avg       0.74      0.59      0.62    223425\n",
      "weighted avg       0.86      0.88      0.86    223425\n",
      "\n",
      "Current epoch is 6 of 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 51/1475 [00:34<16:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09470082729356363\n",
      "Consistency Cost : 0.00476528727565892\n",
      "Classification Cost : 0.18463636787608265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|         | 101/1475 [01:09<15:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08886254756886046\n",
      "Consistency Cost : 0.0044754136702977124\n",
      "Classification Cost : 0.17324968147091568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|         | 151/1475 [01:43<15:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08947349789979246\n",
      "Consistency Cost : 0.004700717114610597\n",
      "Classification Cost : 0.17424627854799232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|        | 201/1475 [02:17<14:31,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08817804422127665\n",
      "Consistency Cost : 0.00465418556239456\n",
      "Classification Cost : 0.17170190260745585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|        | 251/1475 [02:51<13:56,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08787658565875608\n",
      "Consistency Cost : 0.004558655753964558\n",
      "Classification Cost : 0.17119451532512903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|        | 301/1475 [03:25<13:22,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08850010418963696\n",
      "Consistency Cost : 0.00461106839182321\n",
      "Classification Cost : 0.17238913981243967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|       | 351/1475 [04:00<12:48,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08884934316796717\n",
      "Consistency Cost : 0.0045935684670361555\n",
      "Classification Cost : 0.17310511770392104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|       | 401/1475 [04:34<12:14,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.0883725280177896\n",
      "Consistency Cost : 0.004702481759886723\n",
      "Classification Cost : 0.17204257425270042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|       | 451/1475 [05:08<11:40,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08848340624037923\n",
      "Consistency Cost : 0.004663555389270186\n",
      "Classification Cost : 0.17230325696575974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|      | 501/1475 [05:42<11:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08863846951711457\n",
      "Consistency Cost : 0.0046389274604152885\n",
      "Classification Cost : 0.17263801151700317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|      | 551/1475 [06:16<10:32,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.0886542237559016\n",
      "Consistency Cost : 0.004601327668272212\n",
      "Classification Cost : 0.17270711975849487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|      | 601/1475 [06:51<09:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08779032226113487\n",
      "Consistency Cost : 0.004559569376384995\n",
      "Classification Cost : 0.17102107511445258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|     | 651/1475 [07:25<09:22,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08728040503557377\n",
      "Consistency Cost : 0.004603718694012899\n",
      "Classification Cost : 0.16995709131650913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|     | 701/1475 [07:59<08:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.087461041252952\n",
      "Consistency Cost : 0.0046277647542800485\n",
      "Classification Cost : 0.17029431770522413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|     | 751/1475 [08:33<08:15,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08762285225318435\n",
      "Consistency Cost : 0.00463268128146107\n",
      "Classification Cost : 0.1706130232485011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|    | 801/1475 [09:07<07:41,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08709183955288609\n",
      "Consistency Cost : 0.004629994161368813\n",
      "Classification Cost : 0.1695536849249038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|    | 851/1475 [09:42<07:06,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08753443050122929\n",
      "Consistency Cost : 0.004659669378032799\n",
      "Classification Cost : 0.17040919162415188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|    | 901/1475 [10:16<06:32,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08744947058168084\n",
      "Consistency Cost : 0.004741013987158011\n",
      "Classification Cost : 0.17015792718855663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|   | 951/1475 [10:50<05:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.0879055471386834\n",
      "Consistency Cost : 0.004732869546492829\n",
      "Classification Cost : 0.1710782247240116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|   | 1001/1475 [11:24<05:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08875349756045034\n",
      "Consistency Cost : 0.004773383680614643\n",
      "Classification Cost : 0.17273361141979696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|  | 1051/1475 [11:58<04:49,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08839547863568269\n",
      "Consistency Cost : 0.004805948633196143\n",
      "Classification Cost : 0.17198500859817223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|  | 1101/1475 [12:33<04:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08856944905832113\n",
      "Consistency Cost : 0.004767727914811323\n",
      "Classification Cost : 0.17237117013407194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|  | 1151/1475 [13:07<03:42,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08873228436553568\n",
      "Consistency Cost : 0.004783236233127789\n",
      "Classification Cost : 0.17268133242351366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%| | 1201/1475 [13:41<03:07,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.0887710722895766\n",
      "Consistency Cost : 0.004788665165712397\n",
      "Classification Cost : 0.17275347927604648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%| | 1251/1475 [14:15<02:32,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08877800260772929\n",
      "Consistency Cost : 0.004797804302792065\n",
      "Classification Cost : 0.17275820082519203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%| | 1301/1475 [14:49<01:59,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08881232827080217\n",
      "Consistency Cost : 0.00479918950409718\n",
      "Classification Cost : 0.17282546696700873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|| 1351/1475 [15:24<01:24,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08862795429312866\n",
      "Consistency Cost : 0.004785408227751894\n",
      "Classification Cost : 0.1724705002727677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|| 1401/1475 [15:58<00:50,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08875164177909028\n",
      "Consistency Cost : 0.004828912269793883\n",
      "Classification Cost : 0.17267437121514898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|| 1451/1475 [16:32<00:16,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08858933129701121\n",
      "Consistency Cost : 0.0048247522607261055\n",
      "Classification Cost : 0.17235391029333375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1475/1475 [16:48<00:00,  1.46it/s]\n",
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.4131, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3210453355239513\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9351599427305\n",
      "Average Accuracy Validation score whole sentence  : 0.8816247062772743\n",
      "Average mcc Validation score whole sentence : 0.3091479923671989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/400 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.22      0.32     28264\n",
      "           1       0.90      0.98      0.94    195161\n",
      "\n",
      "    accuracy                           0.88    223425\n",
      "   macro avg       0.74      0.60      0.63    223425\n",
      "weighted avg       0.86      0.88      0.86    223425\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:46<00:00,  8.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.4114, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.322833235241434\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9351032810082129\n",
      "Average Accuracy Validation score whole sentence  : 0.8815575696542464\n",
      "Average mcc Validation score whole sentence : 0.30990499066234123\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.22      0.32     28264\n",
      "           1       0.90      0.98      0.94    195161\n",
      "\n",
      "    accuracy                           0.88    223425\n",
      "   macro avg       0.74      0.60      0.63    223425\n",
      "weighted avg       0.86      0.88      0.86    223425\n",
      "\n",
      "Consistency_lost_train : [[0.021156814222429262], [0.0067179676626366955], [0.005546522213824851], [0.005186812233602059], [0.005001483762032999], [0.004816116306208611]] \n",
      " Classificataion_lost_train :  [[0.34655216847688464], [0.3038343197195712], [0.2658115643610136], [0.22582192918412008], [0.19428667776760156], [0.17203124177736878]] \n",
      " Overall_loss_train : [[0.18385449159921985], [0.15527614386770006], [0.13567904334665293], [0.11550437070438205], [0.09964408091993576], [0.08842367907431592]] \n",
      " f1_class0_student_test : [0.049021276595744685, 0.16014932337844143, 0.27872357701572525, 0.26795159369721133, 0.30525874711921225, 0.3210453355239513] \n",
      " f1_class1_student_test : [0.9330858135217678, 0.9349007125547075, 0.9349870579137015, 0.9356403945084348, 0.9350863541376087, 0.9351599427305] \n",
      " accuracy_student : [0.8749692290477789, 0.8791675058744545, 0.8807250755287009, 0.8816828913505651, 0.8812666442877923, 0.8816247062772743] \n",
      " mcc_cost_student : [0.11091686612715324, 0.21467604355071182, 0.2821898434785807, 0.28125344408795167, 0.29892900996142696, 0.3091479923671989] \n",
      " test_cost_student : [tensor(0.3101, device='cuda:0'), tensor(0.3119, device='cuda:0'), tensor(0.3366, device='cuda:0'), tensor(0.3790, device='cuda:0'), tensor(0.3851, device='cuda:0'), tensor(0.4131, device='cuda:0')] \n",
      " f1_class0_teacher_test : [0.932583356829836, 0.9351870190472971, 0.9355953304365376, 0.9356648437519048, 0.9351730008169414, 0.9351032810082129] \n",
      " f1_class1_teacher_test : [0.004726964865246225, 0.18258803460460582, 0.25579500435503355, 0.28102776491103787, 0.30267312144811614, 0.322833235241434] \n",
      " accuracy_teacher : [0.8737204878594607, 0.8798970571780239, 0.8814501510574018, 0.8818977285442542, 0.8813740628846369, 0.8815575696542464] \n",
      " mcc_cost_teacher [0.039153562243505295, 0.2303095748981721, 0.2740634967010711, 0.2888736091804686, 0.29794973161317956, 0.30990499066234123] \n",
      " test_cost_teacher [tensor(0.3162, device='cuda:0'), tensor(0.3096, device='cuda:0'), tensor(0.3293, device='cuda:0'), tensor(0.3599, device='cuda:0'), tensor(0.3860, device='cuda:0'), tensor(0.4114, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,noise_layer=True) # alpha = 0.995 and full data with noise and w/o dropout\n",
    "print('Consistency_lost_train :',metrices[0],'\\n','Classificataion_lost_train : ',metrices[1],'\\n','Overall_loss_train :',metrices[2],'\\n',\n",
    "      'f1_class0_student_test :',metrices[3],'\\n','f1_class1_student_test :',metrices[4],'\\n','accuracy_student :',metrices[5],'\\n','mcc_cost_student :',metrices[6],\n",
    "      '\\n','test_cost_student :',metrices[7],'\\n','f1_class0_teacher_test :',metrices[8],'\\n','f1_class1_teacher_test :',metrices[9],'\\n',\n",
    "    'accuracy_teacher :', metrices[10],'\\n','mcc_cost_teacher',metrices[11],'\\n','test_cost_teacher',metrices[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        for item in items :\n",
    "            new_lst.append(float(item))\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensors_to_lst(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        new_lst.append(items.item())\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensors_to_lst(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        new_lst.append(items.item())\n",
    "    return new_lst\n",
    "\n",
    "def get_items(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        for item in items :\n",
    "            new_lst.append(float(item))\n",
    "    return new_lst\n",
    "\n",
    "\n",
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency_lost_train : [0.021156814222429262, 0.0067179676626366955, 0.005546522213824851, 0.005186812233602059, 0.005001483762032999, 0.004816116306208611] \n",
      " Classificataion_lost_train :  [0.34655216847688464, 0.3038343197195712, 0.2658115643610136, 0.22582192918412008, 0.19428667776760156, 0.17203124177736878] \n",
      " Overall_loss_train : [0.18385449159921985, 0.15527614386770006, 0.13567904334665293, 0.11550437070438205, 0.09964408091993576, 0.08842367907431592] \n",
      " f1_class0_student_test : [0.049021276595744685, 0.16014932337844143, 0.27872357701572525, 0.26795159369721133, 0.30525874711921225, 0.3210453355239513] \n",
      " f1_class1_student_test : [0.9330858135217678, 0.9349007125547075, 0.9349870579137015, 0.9356403945084348, 0.9350863541376087, 0.9351599427305] \n",
      " accuracy_student : [0.8749692290477789, 0.8791675058744545, 0.8807250755287009, 0.8816828913505651, 0.8812666442877923, 0.8816247062772743] \n",
      " mcc_cost_student : [0.11091686612715324, 0.21467604355071182, 0.2821898434785807, 0.28125344408795167, 0.29892900996142696, 0.3091479923671989] \n",
      " test_cost_student : [0.3101390302181244, 0.31188657879829407, 0.3366025984287262, 0.3789551556110382, 0.3851167857646942, 0.4130603075027466] \n",
      " f1_class0_teacher_test : [0.004726964865246225, 0.18258803460460582, 0.25579500435503355, 0.28102776491103787, 0.30267312144811614, 0.322833235241434] \n",
      " f1_class1_teacher_test : [0.932583356829836, 0.9351870190472971, 0.9355953304365376, 0.9356648437519048, 0.9351730008169414, 0.9351032810082129] \n",
      " accuracy_teacher : [0.8737204878594607, 0.8798970571780239, 0.8814501510574018, 0.8818977285442542, 0.8813740628846369, 0.8815575696542464] \n",
      " mcc_cost_teacher [0.039153562243505295, 0.2303095748981721, 0.2740634967010711, 0.2888736091804686, 0.29794973161317956, 0.30990499066234123] \n",
      " test_cost_teacher [0.31616419553756714, 0.3095984160900116, 0.3293320834636688, 0.3599173128604889, 0.3859928548336029, 0.4114389717578888]\n"
     ]
    }
   ],
   "source": [
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_against_epochs(matrix1,matrix2,label1 , label2 ,y_label , title):\n",
    "    \n",
    "    epochs = np.arange(1,config.EPOCHS+1)\n",
    "    # print(epochs)\n",
    "    plt.plot(epochs,matrix1,label=label1)\n",
    "    if matrix2 is not None :\n",
    "        plt.plot(epochs,matrix2,label=label2)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_against_epochs(test_cost_teacher,test_cost_student,label1 = 'ValidationLoss_teacher', \n",
    "                    label2 = 'ValidationLoss_student', y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(mcc_cost_teacher,mcc_cost_student,label1 = 'mcc_teacher', \n",
    "                    label2 = 'mcc_student', y_label = 'mcc_score_test', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(classification_cost_lst,None,label1 = 'classification_cost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(consistency_cost_lst,None,label1 = 'Consistency_lost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "# Classificataion_lost_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Use less data to check results - with Nosie and dropout, and scaling consistency cost by 10  </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AddGaussianNoise(nn.Module):\n",
    "#     def __init__(self, mean=0., std=1.):\n",
    "#         super().__init__()\n",
    "#         self.std = std\n",
    "#         self.mean = mean\n",
    "        \n",
    "#     def forward(self, tensor):\n",
    "#         if self.training:\n",
    "#             return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "#         else:\n",
    "#             return tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, mode='max', min_delta=0, patience=10, percentage=False):\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = 0\n",
    "        self.num_bad_epochs = 0\n",
    "        self.is_better = None\n",
    "        self._init_is_better(mode, min_delta, percentage)\n",
    "\n",
    "        if patience == 0:\n",
    "            self.is_better = lambda a, b: True\n",
    "            self.step = lambda a: False\n",
    "\n",
    "    def step(self, metrics):\n",
    "        if self.best is None:\n",
    "            self.best = metrics\n",
    "            return False\n",
    "\n",
    "        if np.isnan(metrics):\n",
    "            return True\n",
    "\n",
    "        if self.is_better(metrics, self.best):\n",
    "            self.num_bad_epochs = 0\n",
    "            self.best = metrics\n",
    "        else:\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            print('terminating because of early stopping!')\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _init_is_better(self, mode, min_delta, percentage):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError('mode ' + mode + ' is unknown!')\n",
    "        if not percentage:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best \n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best \n",
    "        else:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - (\n",
    "                            best * min_delta / 100)\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + (\n",
    "                            best * min_delta / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'syn_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-231ec86e0a4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     },\n\u001b[1;32m     16\u001b[0m ]\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mnum_train_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn_dataset\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN_BATCH_SIZE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#10 is the batchsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2e-5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# used 3e-5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m scheduler = get_linear_schedule_with_warmup(\n",
      "\u001b[0;31mNameError\u001b[0m: name 'syn_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "num_train_steps = int(len(syn_dataset) / config.TRAIN_BATCH_SIZE * config.EPOCHS) #10 is the batchsize\n",
    "optimizer = AdamW(optimizer_parameters, lr=2e-5) # used 3e-5\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    ")\n",
    "# early_stopping = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    if 'classifier' not in name:\n",
    "        param.requires_grad = True"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
