{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
      "  Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.4.24-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Installing collected packages: regex, filelock, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.4.1 huggingface-hub-0.4.0 regex-2022.4.24 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.96-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.6/site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.6.7\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-7.7.0-py2.py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (5.5.6)\n",
      "Collecting widgetsnbextension~=3.6.0\n",
      "  Using cached widgetsnbextension-3.6.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting nbformat>=4.2.0\n",
      "  Using cached nbformat-5.1.3-py3-none-any.whl (178 kB)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Using cached jupyterlab_widgets-1.1.0-py3-none-any.whl (245 kB)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (7.16.3)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Collecting jedi<=0.17.2,>=0.10\n",
      "  Using cached jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.28)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (59.3.0)\n",
      "Requirement already satisfied: pexpect in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Collecting parso<0.8.0,>=0.7.0\n",
      "  Using cached parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n",
      "Collecting jsonschema!=2.5.0,>=2.4\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Using cached pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Collecting notebook>=4.4.1\n",
      "  Using cached notebook-6.4.10-py3-none-any.whl (9.9 MB)\n",
      "Collecting argon2-cffi\n",
      "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.4)\n",
      "Collecting prometheus-client\n",
      "  Using cached prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Using cached terminado-0.12.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.1.0)\n",
      "Collecting nbconvert>=5\n",
      "  Using cached nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Collecting Send2Trash>=1.8.0\n",
      "  Using cached Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting bleach\n",
      "  Using cached bleach-4.1.0-py2.py3-none-any.whl (157 kB)\n",
      "Collecting testpath\n",
      "  Using cached testpath-0.6.0-py3-none-any.whl (83 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Using cached nbclient-0.5.9-py3-none-any.whl (69 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
      "Collecting async-generator\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.6/site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10.0.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4.7)\n",
      "Installing collected packages: pyrsistent, parso, jsonschema, webencodings, nbformat, jedi, async-generator, testpath, pandocfilters, nbclient, mistune, jupyterlab-pygments, defusedxml, bleach, argon2-cffi-bindings, terminado, Send2Trash, prometheus-client, nbconvert, argon2-cffi, notebook, widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "  Attempting uninstall: parso\n",
      "    Found existing installation: parso 0.8.0\n",
      "    Uninstalling parso-0.8.0:\n",
      "      Successfully uninstalled parso-0.8.0\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.18.0\n",
      "    Uninstalling jedi-0.18.0:\n",
      "      Successfully uninstalled jedi-0.18.0\n",
      "Successfully installed Send2Trash-1.8.0 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 async-generator-1.10 bleach-4.1.0 defusedxml-0.7.1 ipywidgets-7.7.0 jedi-0.17.2 jsonschema-3.2.0 jupyterlab-pygments-0.1.2 jupyterlab-widgets-1.1.0 mistune-0.8.4 nbclient-0.5.9 nbconvert-6.0.7 nbformat-5.1.3 notebook-6.4.10 pandocfilters-1.5.0 parso-0.7.1 prometheus-client-0.14.1 pyrsistent-0.18.0 terminado-0.12.1 testpath-0.6.0 webencodings-0.5.1 widgetsnbextension-3.6.0\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.35.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (59.3.0)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.44.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.0.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (3.17.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.25.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from absl-py>=0.4->tensorboard) (1.16.0)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\n",
      "Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\n",
      "Successfully installed absl-py-1.0.0 cachetools-4.2.4 google-auth-2.6.6 google-auth-oauthlib-0.4.6 grpcio-1.44.0 markdown-3.3.6 oauthlib-3.2.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install nltk\n",
    "!pip install ipywidgets\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.6/site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval) (1.19.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.18.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.18.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.6/site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval) (1.19.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.18.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.6.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.6/site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval) (1.19.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.6/site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.18.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.6/site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval) (1.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.4)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.6/site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval) (1.19.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.4.24)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.53)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "# from DataAugmentation \n",
    "from data_utils import loadDatafromFile,createTokenizedDf,CompDataset,createkfoldData,createDataloaders\n",
    "from data_utils_unlabelled import loadUnlabelledDatafromFile,createTokenizedDfUnlabelled,CompDatasetUnlabelled\n",
    "from DataAugmentation import DataAugmentation\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from importlib import reload\n",
    "import config\n",
    "from transformers import XLMRobertaForTokenClassification, XLMRobertaConfig ,BertModel, XLMRobertaTokenizer, XLMRobertaModel, BertForTokenClassification\n",
    "from seqeval.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import matthews_corrcoef,classification_report,f1_score\n",
    "import engine\n",
    "# from model_new import EntityModel\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from  loss_functions import ClassificationCost, ConsistencyCost, update_teacher_params\n",
    "from utils_functions import set_seed, sigmoid_rampup, get_consistency_weight, EarlyStopping\n",
    "from model_xlmroberta import EntityModel , GaussianNoise\n",
    "from DataAugmentation import DataAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data_utils\n",
    "# data_utils = reload(data_utils)\n",
    "# from data_utils import loadDatafromFile,createTokenizedDf,CompDataset,createkfoldData,createDataloaders\n",
    "# import data_utils_unlabelled\n",
    "# data_utils_unlabelled = reload(data_utils_unlabelled)\n",
    "# from data_utils_unlabelled import loadUnlabelledDatafromFile,createTokenizedDfUnlabelled,CompDatasetUnlabelled, createkfoldData,createDataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config= reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.tensorboard.summary import hparams\n",
    "\n",
    "class SummaryWriter(SummaryWriter):\n",
    "    def add_hparams(self, hparam_dict, metric_dict):\n",
    "        torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n",
    "        if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n",
    "            raise TypeError('hparam_dict and metric_dict should be dictionary.')\n",
    "        exp, ssi, sei = hparams(hparam_dict, metric_dict)\n",
    "\n",
    "        logdir = self._get_file_writer().get_logdir()\n",
    "        \n",
    "        with SummaryWriter(log_dir=logdir) as w_hp:\n",
    "            w_hp.file_writer.add_summary(exp)\n",
    "            w_hp.file_writer.add_summary(ssi)\n",
    "            w_hp.file_writer.add_summary(sei)\n",
    "            for k, v in metric_dict.items():\n",
    "                w_hp.add_scalar(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_labelled(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags,\n",
    "                 filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval,train_data_needed,\n",
    "                          unlabel_data_needed,total_train_data=2000, model_type='xlm'):\n",
    "    \n",
    "    set_seed()\n",
    "    dataObjTrain = loadDatafromFile(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags)\n",
    "    df_train= dataObjTrain.createDf() # get dataframe from files    \n",
    "    \n",
    "    dataObjEval = loadDatafromFile(filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval)\n",
    "    df_test = dataObjEval.createDf()\n",
    "#     df_combined = df_train.append(df_eval, ignore_index=True)\n",
    "#     df_combined.reset_index(drop=True)\n",
    "    split_ratio_len = int(len(df_train) - config.test_split_ratio*len(df_train))# 7k - 2450 = 4550\n",
    "   \n",
    "    df_train_splitted = df_train.iloc[:split_ratio_len,:] #[:4550]\n",
    "    df_eval_splitted = df_train.iloc[split_ratio_len:,:] #[4550:] \n",
    "    df_train_splitted = df_train_splitted[:total_train_data]#2000,3000\n",
    "    df_train_splitted_ = df_train_splitted[:train_data_needed] # amount of labeled data needed for training out of 2000 for eg. 250\n",
    "    eval_data_needed_ssl = int(0.25 * (train_data_needed+unlabel_data_needed)) # 25 % reserve for validation -->500 for 2k data train\n",
    "    eval_data_needed_sl = int(0.25*train_data_needed)\n",
    "    df_eval_splitted_ssl = df_eval_splitted[:eval_data_needed_ssl] # fix this 500 for all experiments\n",
    "    df_eval_splitted_sl = df_eval_splitted[:eval_data_needed_sl] \n",
    "    \n",
    "#     df_train_splitted_ = df_train_splitted[:1000]\n",
    "    df_unlabel_splitted_train = df_train_splitted[train_data_needed:] # get remaining data in train df to be used as unlabeled\n",
    "    df_unlabel_splitted_train = df_unlabel_splitted_train.reset_index(drop=True)\n",
    "#     df_eval_splitted = df_eval_splitted[:500]\n",
    "\n",
    "#     df_unlabel_splitted_test = df_eval_splitted[eval_data_needed:]# get remaining data in eval df to use for unlabel\n",
    "#     df_unlabel_splitted_test=df_unlabel_splitted_test.reset_index(drop=True)\n",
    "    \n",
    "#     df_unlabeled = df_unlabel_splitted_train.append(df_unlabel_splitted_test, ignore_index = True) # combine both unlabel df's\n",
    "    \n",
    "    obj_tokenized_train = createTokenizedDf(df_train_splitted_,model_type)\n",
    "    obj_tokenized_eval_ssl = createTokenizedDf(df_eval_splitted_ssl,model_type)\n",
    "    obj_tokenized_eval_sl = createTokenizedDf(df_eval_splitted_sl,model_type)\n",
    "    obj_tokenized_test = createTokenizedDf(df_test,model_type)\n",
    "    \n",
    "    \n",
    "    df_new_train = obj_tokenized_train.convertDf()\n",
    "    df_new_eval_ssl = obj_tokenized_eval_ssl.convertDf()\n",
    "    df_new_eval_sl = obj_tokenized_eval_sl.convertDf()\n",
    "    df_new_test = obj_tokenized_test.convertDf()\n",
    "    \n",
    "    train_data = CompDataset(df_new_train,model_type)\n",
    "    eval_data_ssl = CompDataset(df_new_eval_ssl,model_type)\n",
    "    eval_data_sl = CompDataset(df_new_eval_sl,model_type)\n",
    "    test_data = CompDataset(df_new_test,model_type)\n",
    "    \n",
    "    return train_data, eval_data_ssl, eval_data_sl, test_data, df_unlabel_splitted_train,df_train_splitted_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the labelled data\n",
    "# def process_data_labelled(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags,\n",
    "#                  filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval,\n",
    "#                  model_type='xlm'):\n",
    "    \n",
    "    \n",
    "#     dataObjTrain = loadDatafromFile(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags)\n",
    "#     df_train= dataObjTrain.createDf() # get dataframe from files    \n",
    "#     df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "#     df_train=df_train.iloc[:500,:]\n",
    "#     dataObjEval = loadDatafromFile(filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval)\n",
    "#     df_eval = dataObjEval.createDf()\n",
    "#     obj_tokenized_train = createTokenizedDf(df_train,model_type)\n",
    "#     obj_tokenized_test = createTokenizedDf(df_eval,model_type)\n",
    "#     df_new_train = obj_tokenized_train.convertDf()\n",
    "#     df_new_eval = obj_tokenized_test.convertDf()\n",
    "#     train_data = CompDataset(df_new_train,model_type)\n",
    "#     test_data = CompDataset(df_new_eval,model_type)\n",
    "#     return train_data,test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config=reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter labeled data needed 1750\n"
     ]
    }
   ],
   "source": [
    "total_train_data = 2000 \n",
    "label_data_required = int(input('enter labeled data needed'))\n",
    "unlabel_data_required = total_train_data - label_data_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seed()\n",
    "train_data , eval_data_ssl,eval_data_sl, test_data, df_unlabel, df_train = process_data_labelled(config.filePath_src,config.filePath_tar, config.filePath_srcTags,config.filePath_tarTags,\n",
    "                                                config.filePath_src_eval,config.filePath_tar_eval, config.filePath_srcTags_eval,\n",
    "                                                config.filePath_tarTags_eval,label_data_required,unlabel_data_required, total_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tar_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jos Ortega y Gasset visited Husserl at Freibu...</td>\n",
       "      <td>1934 besuchte Jos Ortega y Gasset Husserl in ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However , a disappointing ninth in China meant...</td>\n",
       "      <td>Eine enttuschende Neunte in China bedeutete j...</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...</td>\n",
       "      <td>OK BAD OK BAD OK BAD OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his diary , Chase wrote that the release of...</td>\n",
       "      <td>In seinem Tagebuch , Chase schrieb , dass die ...</td>\n",
       "      <td>OK OK OK OK BAD BAD OK OK OK OK OK OK OK OK BA...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>OK BAD BAD OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK BAD BAD OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once North Pacific salmon die off after spawni...</td>\n",
       "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>OK OK OK OK BAD OK OK OK OK OK BAD OK BAD OK O...</td>\n",
       "      <td>OK OK OK BAD OK OK OK BAD OK OK OK OK OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>This inhibits both transcription and DNA repli...</td>\n",
       "      <td>Dies hemmt sowohl die Transkription als auch d...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>Many barons assigned themselves grandiose titl...</td>\n",
       "      <td>Viele Barone gaben sich grandiose Titel , wie ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>The dialect of the educated stratum among the ...</td>\n",
       "      <td>Der Dialekt der gebildeten Schicht unter den P...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK BAD OK OK OK OK OK OK ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748</th>\n",
       "      <td>Raynald responded by looting a caravan of pilg...</td>\n",
       "      <td>Raynald reagierte 1185 mit der Plnderung eine...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>The clutch accomplishes this in manual transmi...</td>\n",
       "      <td>Die Kupplung erfllt dies bei manuellen Getrie...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1750 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "0     Jos Ortega y Gasset visited Husserl at Freibu...   \n",
       "1     However , a disappointing ninth in China meant...   \n",
       "2     In his diary , Chase wrote that the release of...   \n",
       "3     Heavy arquebuses mounted on wagons were called...   \n",
       "4     Once North Pacific salmon die off after spawni...   \n",
       "...                                                 ...   \n",
       "1745  This inhibits both transcription and DNA repli...   \n",
       "1746  Many barons assigned themselves grandiose titl...   \n",
       "1747  The dialect of the educated stratum among the ...   \n",
       "1748  Raynald responded by looting a caravan of pilg...   \n",
       "1749  The clutch accomplishes this in manual transmi...   \n",
       "\n",
       "                                                 target  \\\n",
       "0     1934 besuchte Jos Ortega y Gasset Husserl in ...   \n",
       "1     Eine enttuschende Neunte in China bedeutete j...   \n",
       "2     In seinem Tagebuch , Chase schrieb , dass die ...   \n",
       "3     Schwere Arquebuses auf Waggons montiert wurden...   \n",
       "4     Sobald der nordpazifische Lachs nach dem Laich...   \n",
       "...                                                 ...   \n",
       "1745  Dies hemmt sowohl die Transkription als auch d...   \n",
       "1746  Viele Barone gaben sich grandiose Titel , wie ...   \n",
       "1747  Der Dialekt der gebildeten Schicht unter den P...   \n",
       "1748  Raynald reagierte 1185 mit der Plnderung eine...   \n",
       "1749  Die Kupplung erfllt dies bei manuellen Getrie...   \n",
       "\n",
       "                                             src_tokens  \\\n",
       "0                      OK OK OK OK OK OK OK OK OK OK OK   \n",
       "1     OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...   \n",
       "2     OK OK OK OK BAD BAD OK OK OK OK OK OK OK OK BA...   \n",
       "3                    OK BAD BAD OK OK OK OK OK OK OK OK   \n",
       "4     OK OK OK OK BAD OK OK OK OK OK BAD OK BAD OK O...   \n",
       "...                                                 ...   \n",
       "1745             OK OK OK OK OK OK OK OK OK OK OK OK OK   \n",
       "1746    OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK   \n",
       "1747  OK OK OK OK OK OK OK OK BAD OK OK OK OK OK OK ...   \n",
       "1748          OK OK OK OK OK OK OK OK OK OK OK OK OK OK   \n",
       "1749                            OK OK OK OK OK OK OK OK   \n",
       "\n",
       "                                             tar_tokens  \n",
       "0     OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1     OK BAD OK BAD OK BAD OK OK OK OK OK OK OK OK O...  \n",
       "2     OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...  \n",
       "3     OK OK OK BAD OK OK OK OK BAD BAD OK OK OK OK O...  \n",
       "4     OK OK OK BAD OK OK OK BAD OK OK OK OK OK OK OK...  \n",
       "...                                                 ...  \n",
       "1745  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1746  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1747  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...  \n",
       "1748  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1749  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "\n",
       "[1750 rows x 4 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tar_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He wrote an eclogue , heavily influenced by hi...</td>\n",
       "      <td>Er schrieb einen Exlog , der stark von seinem ...</td>\n",
       "      <td>OK OK BAD BAD OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK BAD OK BAD OK OK OK BAD OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hamlet picks up the skull , saying \" alas , po...</td>\n",
       "      <td>Hamlet nimmt den Schdel auf und sagt \" Ach , ...</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK OK BAD OK OK...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In defiance of the instructions of his superio...</td>\n",
       "      <td>Trotz der Anweisungen seiner Vorgesetzten str...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The dialect of the educated stratum among the ...</td>\n",
       "      <td>Der Dialekt der gebildeten Schicht unter den P...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK BAD OK OK OK OK OK OK ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Both Figures 0.1 and 3.1 show open impellers w...</td>\n",
       "      <td>Beide Abbildungen 0.1 und 3.1 zeigen offene La...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>At Raw 1000 , Stephanie McMahon goaded Heyman ...</td>\n",
       "      <td>Bei Raw 1000 , Stephanie McMahon goaded Heyman...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK BAD BAD OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK OK OK BAD OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>In her passion , she stabs Lilla and throws he...</td>\n",
       "      <td>In ihrer Leidenschaft stach sie Lilla und warf...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK BAD OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK OK OK OK OK ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>The \" higher elevation \" campsites included St...</td>\n",
       "      <td>Zu den \" hher gelegenen \" Campingpltzen geh...</td>\n",
       "      <td>OK BAD OK OK BAD OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Troops H and I of the 10th near . forth for an...</td>\n",
       "      <td>Die Truppen H und I der 10. Kavallerie salbten...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK BAD BAD OK BAD BAD ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Gnaeus Cornelius L. f . L. n . Lentulus , cons...</td>\n",
       "      <td>Gnaeus Cornelius L. f. L. n. Lentulus , Konsul...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "0     He wrote an eclogue , heavily influenced by hi...   \n",
       "1     Hamlet picks up the skull , saying \" alas , po...   \n",
       "2     In defiance of the instructions of his superio...   \n",
       "3     The dialect of the educated stratum among the ...   \n",
       "4     Both Figures 0.1 and 3.1 show open impellers w...   \n",
       "...                                                 ...   \n",
       "1995  At Raw 1000 , Stephanie McMahon goaded Heyman ...   \n",
       "1996  In her passion , she stabs Lilla and throws he...   \n",
       "1997  The \" higher elevation \" campsites included St...   \n",
       "1998  Troops H and I of the 10th near . forth for an...   \n",
       "1999  Gnaeus Cornelius L. f . L. n . Lentulus , cons...   \n",
       "\n",
       "                                                 target  \\\n",
       "0     Er schrieb einen Exlog , der stark von seinem ...   \n",
       "1     Hamlet nimmt den Schdel auf und sagt \" Ach , ...   \n",
       "2     Trotz der Anweisungen seiner Vorgesetzten str...   \n",
       "3     Der Dialekt der gebildeten Schicht unter den P...   \n",
       "4     Beide Abbildungen 0.1 und 3.1 zeigen offene La...   \n",
       "...                                                 ...   \n",
       "1995  Bei Raw 1000 , Stephanie McMahon goaded Heyman...   \n",
       "1996  In ihrer Leidenschaft stach sie Lilla und warf...   \n",
       "1997  Zu den \" hher gelegenen \" Campingpltzen geh...   \n",
       "1998  Die Truppen H und I der 10. Kavallerie salbten...   \n",
       "1999  Gnaeus Cornelius L. f. L. n. Lentulus , Konsul...   \n",
       "\n",
       "                                             src_tokens  \\\n",
       "0           OK OK BAD BAD OK OK OK OK OK OK OK OK OK OK   \n",
       "1     OK OK OK OK OK OK OK BAD OK OK OK OK BAD OK OK...   \n",
       "2     OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...   \n",
       "3     OK OK OK OK OK OK OK OK BAD OK OK OK OK OK OK ...   \n",
       "4                      OK OK OK OK OK OK OK OK OK OK OK   \n",
       "...                                                 ...   \n",
       "1995  OK OK OK OK OK OK OK OK OK OK OK BAD BAD OK OK OK   \n",
       "1996         OK OK OK OK OK OK OK OK BAD OK OK OK OK OK   \n",
       "1997     OK BAD OK OK BAD OK OK OK OK OK OK OK OK OK OK   \n",
       "1998  OK OK OK OK OK OK OK OK OK BAD BAD OK BAD BAD ...   \n",
       "1999  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...   \n",
       "\n",
       "                                             tar_tokens  \n",
       "0     OK OK OK OK OK BAD OK BAD OK OK OK BAD OK OK O...  \n",
       "1     OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD ...  \n",
       "2     OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "3     OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...  \n",
       "4     OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "...                                                 ...  \n",
       "1995  OK OK OK OK OK OK OK BAD OK OK OK OK OK BAD OK...  \n",
       "1996  OK OK OK OK OK OK OK BAD OK OK OK OK OK OK OK ...  \n",
       "1997  OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...  \n",
       "1998  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1999  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataaug_obj = DataAugmentation(df_train,swap_words=2,syn_words=2,del_words_prob=0.2,num_sentences=1)  \n",
    "swapDataset = dataaug_obj.random_swap()\n",
    "swapdata_temp = swapDataset[len(df_train):]\n",
    "swapdata_temp = swapdata_temp.sample(frac=1).reset_index(drop=True)\n",
    "# swapDataset=swapDataset[:len(df_train)]\n",
    "# swapDataset = swapDataset[:len(df_train)]\n",
    "drop_indices = np.random.choice(swapdata_temp.index, 1500, replace=False)\n",
    "df_subset = swapdata_temp.drop(drop_indices)\n",
    "frames = [swapDataset[:len(df_train)],df_subset]\n",
    "aug_df  = pd.concat(frames)\n",
    "aug_df = aug_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# delDataset = dataaug_obj.random_deletion()\n",
    "# delDataset= delDataset[len(df_train):]\n",
    "# delDataset = delDataset.sample(frac=1).reset_index(drop=True)\n",
    "# delDataset_temp = delDataset[len(df_train):]\n",
    "# delDataset=delDataset[:len(df_train)]\n",
    "\n",
    "# drop_indices = np.random.choice(delDataset_temp.index, 1000, replace=False)\n",
    "# df_subset = delDataset_temp.drop(drop_indices)\n",
    "# frames = [delDataset,df_subset]\n",
    "# aug_df  = pd.concat(frames)\n",
    "# aug_df = aug_df.sample(frac=1).reset_index(drop=True)\n",
    "# drop_indices = np.random.choice(delDataset.index, 250, replace=False)\n",
    "# df_subset = delDataset.drop(drop_indices)\n",
    "# delDataset = delDataset[1000:]\n",
    "\n",
    "\n",
    "# synDataset = dataaug_obj.synonym_replacement()\n",
    "# synDataset=synDataset[len(df_train):]\n",
    "# synDataset = synDataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "# synDataset_temp = synDataset[len(df_train):]\n",
    "# synDataset = synDataset[:len(df_train)]\n",
    "# drop_indices = np.random.choice(synDataset_temp.index, 1000, replace=False)\n",
    "# df_subset = synDataset_temp.drop(drop_indices)\n",
    "# frames = [synDataset,df_subset]\n",
    "# aug_df  = pd.concat(frames)\n",
    "# aug_df = aug_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# drop_indices = np.random.choice(synDataset.index, 250, replace=False)\n",
    "# df_subset = synDataset.drop(drop_indices)\n",
    "# synDataset=synDataset[1000:]\n",
    "# frames = [swapdata_temp , delDataset,synDataset]\n",
    "# aug_df  = pd.concat(frames)\n",
    "# aug_df = aug_df.sample(frac=1).reset_index(drop=True)\n",
    "# drop_indices = np.random.choice(aug_df.index, 4000, replace=False)\n",
    "# df_subset = aug_df.drop(drop_indices)\n",
    "# df_subset = df_subset.sample(frac=1).reset_index(drop=True)\n",
    "# frames = [swapDataset, df_subset]\n",
    "# aug_df  = pd.concat(frames)\n",
    "# aug_df = aug_df.sample(frac=1).reset_index(drop=True)\n",
    "aug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['In his single semester there , he averaged 17.6 points and 13.3 rebounds , before flunking out due to poor academic performance .',\n",
       "        'In seinem Semester dort lag er im Durchschnitt bei 17,6 Punkten und 13,3 Rebounds , bevor er aufgrund schlechter akademischer Leistungen ausflog .',\n",
       "        'OK OK BAD OK OK OK OK BAD OK OK OK OK OK OK OK BAD OK OK OK OK OK OK OK',\n",
       "        'OK OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD BAD OK OK OK'],\n",
       "       ['French instead reinforced habe with obligatory subject pronouns .',\n",
       "        'Franzsisch stattdessen verstrkt habe mit obligatorischen Subjekt Pronomen .',\n",
       "        'OK OK OK OK OK OK BAD BAD OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_df[:2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_subset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a2fcedc203c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_subset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_subset' is not defined"
     ]
    }
   ],
   "source": [
    "df_subset[-2:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tar_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For many \" libertarian orthodoxy , Marxian the...</td>\n",
       "      <td>Fr viele marxistische libertre Sozialisten \"...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So claimants petitioned the King to sidestep t...</td>\n",
       "      <td>So Klger bat den Knig , die Common Law Geric...</td>\n",
       "      <td>BAD BAD BAD OK OK OK OK OK OK OK BAD OK</td>\n",
       "      <td>BAD BAD OK BAD OK BAD OK BAD OK OK OK OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It protects him from gunfire and other signifi...</td>\n",
       "      <td>Es schtzt ihn vor Schusswaffen und anderen er...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK BAD OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soon after 8 a.m. , June 25 , the Union brigad...</td>\n",
       "      <td>Bald nach 8 Uhr morgens , 25. Juni , die Union...</td>\n",
       "      <td>BAD OK OK OK OK OK OK OK OK BAD BAD BAD BAD OK</td>\n",
       "      <td>OK BAD OK OK OK OK OK OK OK OK OK OK OK OK OK ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" Large Amplitude Liquid M.A in Seismically \" ...</td>\n",
       "      <td>\" Groe Amplitude Liquid Sloshing in seismisch...</td>\n",
       "      <td>OK BAD OK OK BAD OK BAD OK OK OK BAD OK OK OK ...</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK OK OK OK OK OK BAD OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Five year old Sarah developed hydrocephaly aft...</td>\n",
       "      <td>Die fnfjhrige Sarah entwickelte nach Fieber ...</td>\n",
       "      <td>OK OK OK OK OK BAD OK BAD BAD OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK BAD BAD OK BAD O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>In 1970 Neustein , collaborated with Georgette...</td>\n",
       "      <td>1970 arbeitete Neustein mit Georgette Batlle u...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK BAD OK OK ...</td>\n",
       "      <td>OK OK OK OK OK OK BAD OK OK OK OK OK OK OK OK ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>A number of private auto rickshaws and jeeps p...</td>\n",
       "      <td>Eine Reihe von privaten Auto-Rikschas und Jeep...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK BAD OK OK OK OK OK OK ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>His partially morbid motifs appealed to the su...</td>\n",
       "      <td>Seine teilweise morbiden Motive appellierten a...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>After Whitefield preached at St. Philip 's , C...</td>\n",
       "      <td>Nachdem Whitefield bei St. Philip ' s , Charle...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "0     For many \" libertarian orthodoxy , Marxian the...   \n",
       "1     So claimants petitioned the King to sidestep t...   \n",
       "2     It protects him from gunfire and other signifi...   \n",
       "3     Soon after 8 a.m. , June 25 , the Union brigad...   \n",
       "4     \" Large Amplitude Liquid M.A in Seismically \" ...   \n",
       "...                                                 ...   \n",
       "1995  Five year old Sarah developed hydrocephaly aft...   \n",
       "1996  In 1970 Neustein , collaborated with Georgette...   \n",
       "1997  A number of private auto rickshaws and jeeps p...   \n",
       "1998  His partially morbid motifs appealed to the su...   \n",
       "1999  After Whitefield preached at St. Philip 's , C...   \n",
       "\n",
       "                                                 target  \\\n",
       "0     Fr viele marxistische libertre Sozialisten \"...   \n",
       "1     So Klger bat den Knig , die Common Law Geric...   \n",
       "2     Es schtzt ihn vor Schusswaffen und anderen er...   \n",
       "3     Bald nach 8 Uhr morgens , 25. Juni , die Union...   \n",
       "4     \" Groe Amplitude Liquid Sloshing in seismisch...   \n",
       "...                                                 ...   \n",
       "1995  Die fnfjhrige Sarah entwickelte nach Fieber ...   \n",
       "1996  1970 arbeitete Neustein mit Georgette Batlle u...   \n",
       "1997  Eine Reihe von privaten Auto-Rikschas und Jeep...   \n",
       "1998  Seine teilweise morbiden Motive appellierten a...   \n",
       "1999  Nachdem Whitefield bei St. Philip ' s , Charle...   \n",
       "\n",
       "                                             src_tokens  \\\n",
       "0     OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...   \n",
       "1               BAD BAD BAD OK OK OK OK OK OK OK BAD OK   \n",
       "2                        OK OK OK OK OK OK OK OK BAD OK   \n",
       "3        BAD OK OK OK OK OK OK OK OK BAD BAD BAD BAD OK   \n",
       "4     OK BAD OK OK BAD OK BAD OK OK OK BAD OK OK OK ...   \n",
       "...                                                 ...   \n",
       "1995                   OK OK OK OK OK BAD OK BAD BAD OK   \n",
       "1996  OK OK OK OK OK OK OK OK OK OK OK OK BAD OK OK ...   \n",
       "1997  OK OK OK OK OK OK OK OK BAD OK OK OK OK OK OK ...   \n",
       "1998                         OK OK OK OK OK OK OK OK OK   \n",
       "1999  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...   \n",
       "\n",
       "                                             tar_tokens  \n",
       "0     OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1     BAD BAD OK BAD OK BAD OK BAD OK OK OK OK OK OK...  \n",
       "2     OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "3     OK BAD OK OK OK OK OK OK OK OK OK OK OK OK OK ...  \n",
       "4     OK OK OK BAD OK OK OK OK OK OK OK OK OK BAD OK...  \n",
       "...                                                 ...  \n",
       "1995  OK OK OK OK OK OK OK OK OK OK BAD BAD OK BAD O...  \n",
       "1996  OK OK OK OK OK OK BAD OK OK OK OK OK OK OK OK ...  \n",
       "1997  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK B...  \n",
       "1998  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1999  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# swapDataset=swapDataset.sample()\n",
    "aug_df = aug_df.sample(frac=1).reset_index(drop=True)\n",
    "aug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<data_utils.CompDataset at 0x7f927915cf28>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_tokenized_train = createTokenizedDf(aug_df,model_type='xlm')\n",
    "df_new_train = obj_tokenized_train.convertDf()\n",
    "train_data = CompDataset(df_new_train,model_type='xlm')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled data 2000\n",
      "ssl eval data 500\n",
      "sl eval data 437\n",
      "unlabel data 250\n",
      "test data 1000\n"
     ]
    }
   ],
   "source": [
    "len_labelled_data = len(train_data)\n",
    "len_eval_data_ssl = len(eval_data_ssl)\n",
    "print('labeled data',len_labelled_data)\n",
    "print('ssl eval data',len_eval_data_ssl)\n",
    "print('sl eval data',len(eval_data_sl))\n",
    "print('unlabel data',len(df_unlabel))\n",
    "print('test data',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([     0,   1326,   5941,     44,  14788,  92812,      6, 236479,     53,\n",
      "             6,      4,  66128,   3378,     70,  68894,   4620,   9167,     18,\n",
      "          2408,    111,  99866,  99866,      7, 106919,    297,     10,     70,\n",
      "          4524,  70760,  36356,      6,      5,      2,      2,    656,  10333,\n",
      "           656,   9510,    656,   1108,    425,  70556,    656,  14788,   3492,\n",
      "           107,    656,  57139,   6892,    656,     44,    656, 233150,     13,\n",
      "           656,    122,    656, 142534,    656,   4932,  40337,    656,    122,\n",
      "           656,  65231,  70556,     19,    656,  12426,    497,    246, 111659,\n",
      "           656,   1918,    656,     70,   4524,  97521,    656,  19528,    206,\n",
      "           656,      6,      5,    656,      2,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1])\n",
      "tensor([     0, 121220,  14432, 122273,      7,    450,   2412,    290,  27686,\n",
      "            98,   1155,     66,      6,      4,   3129,   5809,   3564,     70,\n",
      "         76755,      6,      5,      2,      2,    656, 121220,    656,    493,\n",
      "         65512,    656,  38985,    656,      6,      4,    656,   1421,    656,\n",
      "          1329,    656,   1155,     66,    656,   1600,  79556,    656,   1256,\n",
      "           656,      6,      4,    656,    509,    656,     68,    656,  93577,\n",
      "           656,   2809,    555,    656,  25482,    656,      6,      5,    656,\n",
      "             2,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_data))[0]) # 0,17151,12456,..\n",
    "print(next(iter(eval_data_sl))[0])#121220,.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(train_data,config.TRAIN_BATCH_SIZE)\n",
    "train_dataloader = loader_obj.createDataloaders()\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(eval_data_ssl,config.TRAIN_BATCH_SIZE)\n",
    "val_dataloader = loader_obj.createDataloaders()\n",
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(test_data,config.TRAIN_BATCH_SIZE)\n",
    "test_dataloader = loader_obj.createDataloaders()\n",
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Training supervised Model for the same labeled data </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Experiment name :  supervised_1750_labeled_data_withdropout_aug_swap\n",
      "Enter Model name : supervised_with_1750_labeled_data_aug_swap\n"
     ]
    }
   ],
   "source": [
    "experiment_name_supervised = input('Enter Experiment name : ')\n",
    "model_name_supervised = input('Enter Model name :')\n",
    "#supervised_1500_labeled_data_withdropout_aug_syn\n",
    "#supervised_with_1500_labeled_data_aug_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'supervised_with_1750_labeled_data_aug_swap'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_supervised = SummaryWriter(f\"runs/Supervised_and_MeanTeacherTraining_resampleddata/supervised_with_1750_labelled_withdropout_augData_swap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = reload(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EntityModel(with_noise_layer = False, dropout_layer=True)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "num_train_steps = int(len(train_data) / config.TRAIN_BATCH_SIZE * config.EPOCHS) #10 is the batchsize\n",
    "optimizer = AdamW(optimizer_parameters, lr=2e-5) # used 3e-5\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    ")\n",
    "early_stopping = EarlyStopping(patience=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|| 250/250 [01:10<00:00,  3.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.34209658709322915\n",
      "Average F1 Training score for class 1 : 0.730536286753122\n",
      "Average Accuracy Training score  : 0.6176679297767559\n",
      "Average mcc Training score  : 0.24897828269069613\n",
      "Average F1 Training score for source sentence class 0 : 0.3231751722592572\n",
      "Average F1 Training score for source sentence class 1 : 0.6455124255493941\n",
      "Average Accuracy Training score source sentence  : 0.5347171409866369\n",
      "Average mcc Training score source sentence : 0.1931899942280261\n",
      "Average F1 Training score for target sentence class 0 : 0.3685082378223496\n",
      "Average F1 Training score for target sentence class 1 : 0.5640684880702188\n",
      "Average Accuracy Training score target sentence  : 0.48420244277042346\n",
      "Average mcc Training score target sentence : 0.19980221278934818\n",
      "Average F1 Training score for gaps in target sentence class 0 : 0.01051939513477975\n",
      "Average F1 Training score for gaps in target sentence class 1 : 0.9775610919771586\n",
      "Average Accuracy Training score gaps in target sentence  : 0.9561173314672265\n",
      "Average mcc Training score gaps in target sentence : -0.011235971626776621\n",
      "Average F1 Training score for whole target sentence class 0 : 0.35672071525988786\n",
      "Average F1 Training score for whole target sentence class 1 : 0.7745156810817785\n",
      "Average Accuracy Training score whole target sentence  : 0.6660785723917831\n",
      "Average mcc Training score whole target sentence : 0.2815261912944254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.78      0.34     18036\n",
      "           1       0.95      0.59      0.73    122886\n",
      "\n",
      "    accuracy                           0.62    140922\n",
      "   macro avg       0.58      0.69      0.54    140922\n",
      "weighted avg       0.85      0.62      0.68    140922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.3779556650246306\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8103694248385643\n",
      "Average Accuracy Validation score whole sentence  : 0.7093451490390148\n",
      "Average mcc Validation score whole sentence : 0.2855610867492221\n",
      "Average F1 Validation score for source sentence class 0 : 0.362122495060683\n",
      "Average F1 Validation score for source sentence class 1 : 0.7572502685284641\n",
      "Average Accuracy Validation score source sentence  : 0.6483311289193184\n",
      "Average mcc Validation score source sentence : 0.24078806684336024\n",
      "Average F1 Validation score for target sentence class 0 : 0.4002240896358544\n",
      "Average F1 Validation score for target sentence class 1 : 0.7034841854539412\n",
      "Average Accuracy Validation score target sentence  : 0.6031581288457262\n",
      "Average mcc Validation score target sentence : 0.25030281595002124\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.0\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9862039881920598\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.972783456144521\n",
      "Average mcc Validation score gaps in target sentence : 0.0\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.3902119292112738\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8389126168763709\n",
      "Average Accuracy Validation score whole target sentence  : 0.7451490663379445\n",
      "Average mcc Validation score whole target sentence : 0.31261404860379693\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.69      0.38      4418\n",
      "           1       0.94      0.71      0.81     30338\n",
      "\n",
      "    accuracy                           0.71     34756\n",
      "   macro avg       0.60      0.70      0.59     34756\n",
      "weighted avg       0.85      0.71      0.76     34756\n",
      "\n",
      "Train Loss = 0.5956139250993728 Valid Loss = 0.5764526701162732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for this epoch!\n",
      "Epoch 2 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|| 250/250 [01:12<00:00,  3.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.4156107157322224\n",
      "Average F1 Training score for class 1 : 0.8100718342171574\n",
      "Average Accuracy Training score  : 0.7133165864804644\n",
      "Average mcc Training score  : 0.34580193872322207\n",
      "Average F1 Training score for source sentence class 0 : 0.40025273519337573\n",
      "Average F1 Training score for source sentence class 1 : 0.7556133718172824\n",
      "Average Accuracy Training score source sentence  : 0.6527323140909616\n",
      "Average mcc Training score source sentence : 0.31059605601416385\n",
      "Average F1 Training score for target sentence class 0 : 0.4425725364353523\n",
      "Average F1 Training score for target sentence class 1 : 0.7104418730639404\n",
      "Average Accuracy Training score target sentence  : 0.6188656476267096\n",
      "Average mcc Training score target sentence : 0.32008434927230894\n",
      "Average F1 Training score for gaps in target sentence class 0 : 0.08763505402160864\n",
      "Average F1 Training score for gaps in target sentence class 1 : 0.9772883483250155\n",
      "Average Accuracy Training score gaps in target sentence  : 0.9556799626778633\n",
      "Average mcc Training score gaps in target sentence : 0.06545574839704427\n",
      "Average F1 Training score for whole target sentence class 0 : 0.4274340134661171\n",
      "Average F1 Training score for whole target sentence class 1 : 0.8390022675736962\n",
      "Average Accuracy Training score whole target sentence  : 0.7486739785139569\n",
      "Average mcc Training score whole target sentence : 0.36728132213480774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.80      0.42     18036\n",
      "           1       0.96      0.70      0.81    122886\n",
      "\n",
      "    accuracy                           0.71    140922\n",
      "   macro avg       0.62      0.75      0.61    140922\n",
      "weighted avg       0.87      0.71      0.76    140922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.3923279701845287\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8857479790124934\n",
      "Average Accuracy Validation score whole sentence  : 0.8076591092185522\n",
      "Average mcc Validation score whole sentence : 0.2912492048549359\n",
      "Average F1 Validation score for source sentence class 0 : 0.363521215959468\n",
      "Average F1 Validation score for source sentence class 1 : 0.8562163193285326\n",
      "Average Accuracy Validation score source sentence  : 0.7654244145335719\n",
      "Average mcc Validation score source sentence : 0.23739850928858172\n",
      "Average F1 Validation score for target sentence class 0 : 0.43020746887966804\n",
      "Average F1 Validation score for target sentence class 1 : 0.8361571135398271\n",
      "Average Accuracy Validation score target sentence  : 0.7454963303432427\n",
      "Average mcc Validation score target sentence : 0.2878143428091976\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.008368200836820083\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9857134245584424\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9718326598526266\n",
      "Average mcc Validation score gaps in target sentence : 0.01542996983785796\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.4141123882503193\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9022428213733952\n",
      "Average Accuracy Validation score whole target sentence  : 0.8324430443318267\n",
      "Average mcc Validation score whole target sentence : 0.3267927001611367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.49      0.39      4418\n",
      "           1       0.92      0.85      0.89     30338\n",
      "\n",
      "    accuracy                           0.81     34756\n",
      "   macro avg       0.62      0.67      0.64     34756\n",
      "weighted avg       0.84      0.81      0.82     34756\n",
      "\n",
      "Train Loss = 0.5239175763130188 Valid Loss = 0.6313543433234805\n",
      "Epoch 3 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|| 250/250 [01:13<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.48645637034002465\n",
      "Average F1 Training score for class 1 : 0.8580783356504648\n",
      "Average Accuracy Training score  : 0.7776145669235464\n",
      "Average mcc Training score  : 0.4309319764524234\n",
      "Average F1 Training score for source sentence class 0 : 0.46894822805484854\n",
      "Average F1 Training score for source sentence class 1 : 0.8196953869565777\n",
      "Average Accuracy Training score source sentence  : 0.7307929294874264\n",
      "Average mcc Training score source sentence : 0.3987387983895767\n",
      "Average F1 Training score for target sentence class 0 : 0.5200760129957702\n",
      "Average F1 Training score for target sentence class 1 : 0.7960082336694548\n",
      "Average Accuracy Training score target sentence  : 0.7137058436334381\n",
      "Average mcc Training score target sentence : 0.42695631179891885\n",
      "Average F1 Training score for gaps in target sentence class 0 : 0.1795366795366795\n",
      "Average F1 Training score for gaps in target sentence class 1 : 0.9744437763078773\n",
      "Average Accuracy Training score gaps in target sentence  : 0.950431537205505\n",
      "Average mcc Training score gaps in target sentence : 0.15552056210123\n",
      "Average F1 Training score for whole target sentence class 0 : 0.4997406190558534\n",
      "Average F1 Training score for whole target sentence class 1 : 0.8788509052331831\n",
      "Average Accuracy Training score whole target sentence  : 0.8049399919090214\n",
      "Average mcc Training score whole target sentence : 0.45139934700416673\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.82      0.49     18036\n",
      "           1       0.97      0.77      0.86    122886\n",
      "\n",
      "    accuracy                           0.78    140922\n",
      "   macro avg       0.66      0.80      0.67    140922\n",
      "weighted avg       0.89      0.78      0.81    140922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.4236488291336479\n",
      "Average F1 Validation score for whole sentence class 1 : 0.888934644223675\n",
      "Average Accuracy Validation score whole sentence  : 0.8137587754632294\n",
      "Average mcc Validation score whole sentence : 0.32919048886917773\n",
      "Average F1 Validation score for source sentence class 0 : 0.40099729898192393\n",
      "Average F1 Validation score for source sentence class 1 : 0.8620111999234193\n",
      "Average Accuracy Validation score source sentence  : 0.7756943904146891\n",
      "Average mcc Validation score source sentence : 0.2843213119200441\n",
      "Average F1 Validation score for target sentence class 0 : 0.4589253633839621\n",
      "Average F1 Validation score for target sentence class 1 : 0.8411412131383361\n",
      "Average Accuracy Validation score target sentence  : 0.7543924679368375\n",
      "Average mcc Validation score target sentence : 0.32550234088945723\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.061016949152542375\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9832456299522169\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9670786783931543\n",
      "Average mcc Validation score gaps in target sentence : 0.05964421726667008\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.44063571205983165\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9039798865946292\n",
      "Average Accuracy Validation score whole target sentence  : 0.8360955120303155\n",
      "Average mcc Validation score whole target sentence : 0.35836141577011194\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.54      0.42      4418\n",
      "           1       0.93      0.85      0.89     30338\n",
      "\n",
      "    accuracy                           0.81     34756\n",
      "   macro avg       0.64      0.70      0.66     34756\n",
      "weighted avg       0.85      0.81      0.83     34756\n",
      "\n",
      "Train Loss = 0.45036656272411346 Valid Loss = 0.6317864155012464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for this epoch!\n",
      "Epoch 4 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|| 250/250 [01:12<00:00,  3.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.5565173392124618\n",
      "Average F1 Training score for class 1 : 0.8916545625521508\n",
      "Average Accuracy Training score  : 0.8258540185350761\n",
      "Average mcc Training score  : 0.5115188535928243\n",
      "Average F1 Training score for source sentence class 0 : 0.5406728861496897\n",
      "Average F1 Training score for source sentence class 1 : 0.8642911485551079\n",
      "Average Accuracy Training score source sentence  : 0.7904840759425424\n",
      "Average mcc Training score source sentence : 0.4855497516412678\n",
      "Average F1 Training score for target sentence class 0 : 0.5994085688742177\n",
      "Average F1 Training score for target sentence class 1 : 0.8549226669323304\n",
      "Average Accuracy Training score target sentence  : 0.7869889563373071\n",
      "Average mcc Training score target sentence : 0.5268310527764523\n",
      "Average F1 Training score for gaps in target sentence class 0 : 0.2166796570537802\n",
      "Average F1 Training score for gaps in target sentence class 1 : 0.9695574470663072\n",
      "Average Accuracy Training score gaps in target sentence  : 0.9413925822253324\n",
      "Average mcc Training score gaps in target sentence : 0.19788864255442573\n",
      "Average F1 Training score for whole target sentence class 0 : 0.5683771486349848\n",
      "Average F1 Training score for whole target sentence class 1 : 0.9066480782898693\n",
      "Average Accuracy Training score whole target sentence  : 0.8464961567851845\n",
      "Average mcc Training score whole target sentence : 0.5283114649304391\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.85      0.56     18036\n",
      "           1       0.97      0.82      0.89    122886\n",
      "\n",
      "    accuracy                           0.83    140922\n",
      "   macro avg       0.69      0.84      0.72    140922\n",
      "weighted avg       0.90      0.83      0.85    140922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.38956282902265965\n",
      "Average F1 Validation score for whole sentence class 1 : 0.912232204561161\n",
      "Average Accuracy Validation score whole sentence  : 0.8465300955230751\n",
      "Average mcc Validation score whole sentence : 0.3018324947008006\n",
      "Average F1 Validation score for source sentence class 0 : 0.3615363953800699\n",
      "Average F1 Validation score for source sentence class 1 : 0.8918709912204885\n",
      "Average Accuracy Validation score source sentence  : 0.8150626312923053\n",
      "Average mcc Validation score source sentence : 0.2534551541601177\n",
      "Average F1 Validation score for target sentence class 0 : 0.4308016877637131\n",
      "Average F1 Validation score for target sentence class 1 : 0.8786761399406422\n",
      "Average Accuracy Validation score target sentence  : 0.7999851731040106\n",
      "Average mcc Validation score target sentence : 0.30950192474472493\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.05818181818181818\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9843532894339395\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9692179700499168\n",
      "Average mcc Validation score gaps in target sentence : 0.06684412702381745\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.4103688933200399\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9237709778041299\n",
      "Average Accuracy Validation score whole target sentence  : 0.864995662694608\n",
      "Average mcc Validation score whole target sentence : 0.33439008385875657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.39      0.39      4418\n",
      "           1       0.91      0.91      0.91     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.65      0.65      0.65     34756\n",
      "weighted avg       0.85      0.85      0.85     34756\n",
      "\n",
      "Train Loss = 0.37845520228147506 Valid Loss = 0.8218225065677885\n",
      "Epoch 5 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|| 250/250 [01:12<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.6310471888743611\n",
      "Average F1 Training score for class 1 : 0.9195041622364565\n",
      "Average Accuracy Training score  : 0.8678417848171329\n",
      "Average mcc Training score  : 0.5941356627935596\n",
      "Average F1 Training score for source sentence class 0 : 0.6121748806156985\n",
      "Average F1 Training score for source sentence class 1 : 0.8983584247682233\n",
      "Average Accuracy Training score source sentence  : 0.838930180613856\n",
      "Average mcc Training score source sentence : 0.5675181210482294\n",
      "Average F1 Training score for target sentence class 0 : 0.6820510874103313\n",
      "Average F1 Training score for target sentence class 1 : 0.899117260980045\n",
      "Average Accuracy Training score target sentence  : 0.8468331748701821\n",
      "Average mcc Training score target sentence : 0.6263632989084182\n",
      "Average F1 Training score for gaps in target sentence class 0 : 0.26541764246682276\n",
      "Average F1 Training score for gaps in target sentence class 1 : 0.9714978040284719\n",
      "Average Accuracy Training score gaps in target sentence  : 0.945124795894565\n",
      "Average mcc Training score gaps in target sentence : 0.25069997765294405\n",
      "Average F1 Training score for whole target sentence class 0 : 0.6451278148673423\n",
      "Average F1 Training score for whole target sentence class 1 : 0.9311785975433865\n",
      "Average Accuracy Training score whole target sentence  : 0.8847147930057986\n",
      "Average mcc Training score whole target sentence : 0.6119755602852944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.88      0.63     18036\n",
      "           1       0.98      0.87      0.92    122886\n",
      "\n",
      "    accuracy                           0.87    140922\n",
      "   macro avg       0.74      0.87      0.78    140922\n",
      "weighted avg       0.92      0.87      0.88    140922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.40362009778425045\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9042888862919246\n",
      "Average Accuracy Validation score whole sentence  : 0.8350500632984232\n",
      "Average mcc Validation score whole sentence : 0.30999776325829836\n",
      "Average F1 Validation score for source sentence class 0 : 0.3883309421329508\n",
      "Average F1 Validation score for source sentence class 1 : 0.8811559189741682\n",
      "Average Accuracy Validation score source sentence  : 0.8009803158795612\n",
      "Average mcc Validation score source sentence : 0.2744227099789678\n",
      "Average F1 Validation score for target sentence class 0 : 0.43907271646522683\n",
      "Average F1 Validation score for target sentence class 1 : 0.8709133190460991\n",
      "Average Accuracy Validation score target sentence  : 0.7901252872711098\n",
      "Average mcc Validation score target sentence : 0.31182927491115436\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.10416666666666667\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9790805156896131\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9591157594485381\n",
      "Average mcc Validation score gaps in target sentence : 0.08572201137222824\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.4153931136070705\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9172638436482083\n",
      "Average Accuracy Validation score whole target sentence  : 0.8550426882162261\n",
      "Average mcc Validation score whole target sentence : 0.3334330038330469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.44      0.40      4418\n",
      "           1       0.92      0.89      0.90     30338\n",
      "\n",
      "    accuracy                           0.84     34756\n",
      "   macro avg       0.64      0.67      0.65     34756\n",
      "weighted avg       0.85      0.84      0.84     34756\n",
      "\n",
      "Train Loss = 0.3103582325577736 Valid Loss = 0.9895938147628118\n",
      "Epoch 6 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|| 250/250 [01:12<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.6707314552632122\n",
      "Average F1 Training score for class 1 : 0.9317616218554705\n",
      "Average Accuracy Training score  : 0.886951647010403\n",
      "Average mcc Training score  : 0.6377600408355074\n",
      "Average F1 Training score for source sentence class 0 : 0.6580368874397781\n",
      "Average F1 Training score for source sentence class 1 : 0.9156614937769297\n",
      "Average Accuracy Training score source sentence  : 0.8646936496322255\n",
      "Average mcc Training score source sentence : 0.619813195786845\n",
      "Average F1 Training score for target sentence class 0 : 0.7220449832509173\n",
      "Average F1 Training score for target sentence class 1 : 0.917326944062248\n",
      "Average Accuracy Training score target sentence  : 0.8725590579975133\n",
      "Average mcc Training score target sentence : 0.6725184726652774\n",
      "Average F1 Training score for gaps in target sentence class 0 : 0.2987672226250907\n",
      "Average F1 Training score for gaps in target sentence class 1 : 0.9706230822979007\n",
      "Average Accuracy Training score gaps in target sentence  : 0.9436085840914392\n",
      "Average mcc Training score gaps in target sentence : 0.29134052609957695\n",
      "Average F1 Training score for whole target sentence class 0 : 0.6801034705755551\n",
      "Average F1 Training score for whole target sentence class 1 : 0.9406961409865326\n",
      "Average Accuracy Training score whole target sentence  : 0.8999415651548524\n",
      "Average mcc Training score whole target sentence : 0.6496607750951902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.90      0.67     18036\n",
      "           1       0.98      0.89      0.93    122886\n",
      "\n",
      "    accuracy                           0.89    140922\n",
      "   macro avg       0.76      0.89      0.80    140922\n",
      "weighted avg       0.93      0.89      0.90    140922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.38402003186888234\n",
      "Average F1 Validation score for whole sentence class 1 : 0.910878371702401\n",
      "Average Accuracy Validation score whole sentence  : 0.8442858786972034\n",
      "Average mcc Validation score whole sentence : 0.29490796471740083\n",
      "Average F1 Validation score for source sentence class 0 : 0.37115646258503404\n",
      "Average F1 Validation score for source sentence class 1 : 0.895102355771413\n",
      "Average Accuracy Validation score source sentence  : 0.8201976192328639\n",
      "Average mcc Validation score source sentence : 0.2662588408392456\n",
      "Average F1 Validation score for target sentence class 0 : 0.4228521964942653\n",
      "Average F1 Validation score for target sentence class 1 : 0.8807085029297312\n",
      "Average Accuracy Validation score target sentence  : 0.802283341982356\n",
      "Average mcc Validation score target sentence : 0.30367285501697355\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.1142857142857143\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9734361610968294\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9484193011647255\n",
      "Average mcc Validation score gaps in target sentence : 0.08803789057068778\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.3932694189004109\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9198604470861869\n",
      "Average Accuracy Validation score whole target sentence  : 0.8584212208373282\n",
      "Average mcc Validation score whole target sentence : 0.3131566494412932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.38      0.38      4418\n",
      "           1       0.91      0.91      0.91     30338\n",
      "\n",
      "    accuracy                           0.84     34756\n",
      "   macro avg       0.65      0.65      0.65     34756\n",
      "weighted avg       0.84      0.84      0.84     34756\n",
      "\n",
      "Train Loss = 0.2682003614008427 Valid Loss = 1.1840769478252955\n",
      "Epoch 7 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|| 250/250 [01:12<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.7194288056256606\n",
      "Average F1 Training score for class 1 : 0.944765059345606\n",
      "Average Accuracy Training score  : 0.9077007138700841\n",
      "Average mcc Training score  : 0.691777469797784\n",
      "Average F1 Training score for source sentence class 0 : 0.7063158972259187\n",
      "Average F1 Training score for source sentence class 1 : 0.9319577848926835\n",
      "Average Accuracy Training score source sentence  : 0.8895136134324335\n",
      "Average mcc Training score source sentence : 0.673632237134086\n",
      "Average F1 Training score for target sentence class 0 : 0.7783960172363302\n",
      "Average F1 Training score for target sentence class 1 : 0.9380330131842164\n",
      "Average Accuracy Training score target sentence  : 0.9031485409200615\n",
      "Average mcc Training score target sentence : 0.7396872798040561\n",
      "Average F1 Training score for gaps in target sentence class 0 : 0.32419465387251545\n",
      "Average F1 Training score for gaps in target sentence class 1 : 0.9699728964278101\n",
      "Average Accuracy Training score gaps in target sentence  : 0.9425005831583858\n",
      "Average mcc Training score gaps in target sentence : 0.3239726409251344\n",
      "Average F1 Training score for whole target sentence class 0 : 0.7289810223332464\n",
      "Average F1 Training score for whole target sentence class 1 : 0.9519102907611392\n",
      "Average Accuracy Training score whole target sentence  : 0.9183148289657033\n",
      "Average mcc Training score whole target sentence : 0.7038419875983455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72     18036\n",
      "           1       0.99      0.91      0.94    122886\n",
      "\n",
      "    accuracy                           0.91    140922\n",
      "   macro avg       0.79      0.91      0.83    140922\n",
      "weighted avg       0.94      0.91      0.92    140922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.37541024993688465\n",
      "Average F1 Validation score for whole sentence class 1 : 0.919662282838123\n",
      "Average Accuracy Validation score whole sentence  : 0.8576360916100817\n",
      "Average mcc Validation score whole sentence : 0.298812857034876\n",
      "Average F1 Validation score for source sentence class 0 : 0.35427887492519444\n",
      "Average F1 Validation score for source sentence class 1 : 0.9035056340547308\n",
      "Average Accuracy Validation score source sentence  : 0.8321014549132498\n",
      "Average mcc Validation score source sentence : 0.26061076790857995\n",
      "Average F1 Validation score for target sentence class 0 : 0.4154246510527561\n",
      "Average F1 Validation score for target sentence class 1 : 0.8913893894773857\n",
      "Average Accuracy Validation score target sentence  : 0.8168137000518941\n",
      "Average mcc Validation score target sentence : 0.311198684173802\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.09631728045325778\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.980637329286798\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9620869978607084\n",
      "Average mcc Validation score gaps in target sentence : 0.08259020861270222\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.39082969432314413\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9288737062152654\n",
      "Average Accuracy Validation score whole target sentence  : 0.8726201890152034\n",
      "Average mcc Validation score whole target sentence : 0.3242213239055326\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.34      0.38      4418\n",
      "           1       0.91      0.93      0.92     30338\n",
      "\n",
      "    accuracy                           0.86     34756\n",
      "   macro avg       0.67      0.64      0.65     34756\n",
      "weighted avg       0.84      0.86      0.85     34756\n",
      "\n",
      "Train Loss = 0.2225978255867958 Valid Loss = 1.6020351345576938\n",
      "Epoch 8 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|| 250/250 [01:12<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.7569408421479961\n",
      "Average F1 Training score for class 1 : 0.9546241131765647\n",
      "Average Accuracy Training score  : 0.9235250706064347\n",
      "Average mcc Training score  : 0.7313142035716974\n",
      "Average F1 Training score for source sentence class 0 : 0.7445576407506702\n",
      "Average F1 Training score for source sentence class 1 : 0.9440963176793635\n",
      "Average Accuracy Training score source sentence  : 0.9082681865444603\n",
      "Average mcc Training score source sentence : 0.714621372492306\n",
      "Average F1 Training score for target sentence class 0 : 0.8124044551212055\n",
      "Average F1 Training score for target sentence class 1 : 0.9503405057290523\n",
      "Average Accuracy Training score target sentence  : 0.9214693190960287\n",
      "Average mcc Training score target sentence : 0.7778828513889428\n",
      "Average F1 Training score for gaps in target sentence class 0 : 0.3851109520400859\n",
      "Average F1 Training score for gaps in target sentence class 1 : 0.9738897838840085\n",
      "Average Accuracy Training score gaps in target sentence  : 0.9499066946582692\n",
      "Average mcc Training score gaps in target sentence : 0.38817857272214573\n",
      "Average F1 Training score for whole target sentence class 0 : 0.765930943205263\n",
      "Average F1 Training score for whole target sentence class 1 : 0.9605153427410088\n",
      "Average Accuracy Training score whole target sentence  : 0.9324290915629073\n",
      "Average mcc Training score whole target sentence : 0.7425027923667292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.76     18036\n",
      "           1       0.99      0.92      0.95    122886\n",
      "\n",
      "    accuracy                           0.92    140922\n",
      "   macro avg       0.81      0.93      0.86    140922\n",
      "weighted avg       0.94      0.92      0.93    140922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.36255983875031494\n",
      "Average F1 Validation score for whole sentence class 1 : 0.917822457530776\n",
      "Average Accuracy Validation score whole sentence  : 0.8544136264242145\n",
      "Average mcc Validation score whole sentence : 0.28388452133464004\n",
      "Average F1 Validation score for source sentence class 0 : 0.3356685957965276\n",
      "Average F1 Validation score for source sentence class 1 : 0.9027338001159523\n",
      "Average Accuracy Validation score source sentence  : 0.8303119894188127\n",
      "Average mcc Validation score source sentence : 0.24227960163532836\n",
      "Average F1 Validation score for target sentence class 0 : 0.4073898626243486\n",
      "Average F1 Validation score for target sentence class 1 : 0.8900509755668834\n",
      "Average Accuracy Validation score target sentence  : 0.8145155311735488\n",
      "Average mcc Validation score target sentence : 0.3018628729541689\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.12933025404157045\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9770051845074719\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9551937247444735\n",
      "Average mcc Validation score gaps in target sentence : 0.10660143020777825\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.3815252416756176\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9264642027023575\n",
      "Average Accuracy Validation score whole target sentence  : 0.8685568187006346\n",
      "Average mcc Validation score whole target sentence : 0.31125151220819997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.33      0.36      4418\n",
      "           1       0.90      0.93      0.92     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.66      0.63      0.64     34756\n",
      "weighted avg       0.84      0.85      0.85     34756\n",
      "\n",
      "Train Loss = 0.19472000451385976 Valid Loss = 1.6682386147597479\n",
      "Epoch 9 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|| 250/250 [01:12<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.7782289338017245\n",
      "Average F1 Training score for class 1 : 0.9591522902783963\n",
      "Average Accuracy Training score  : 0.931011481528789\n",
      "Average mcc Training score  : 0.7555070386519598\n",
      "Average F1 Training score for source sentence class 0 : 0.7686013528256601\n",
      "Average F1 Training score for source sentence class 1 : 0.9504068462401796\n",
      "Average Accuracy Training score source sentence  : 0.9183194053991605\n",
      "Average mcc Training score source sentence : 0.7420020581304918\n",
      "Average F1 Training score for target sentence class 0 : 0.8328237848376091\n",
      "Average F1 Training score for target sentence class 1 : 0.9565397684731901\n",
      "Average Accuracy Training score target sentence  : 0.9310136765888978\n",
      "Average mcc Training score target sentence : 0.8022362237740608\n",
      "Average F1 Training score for gaps in target sentence class 0 : 0.4187946884576098\n",
      "Average F1 Training score for gaps in target sentence class 1 : 0.9740004569339731\n",
      "Average Accuracy Training score gaps in target sentence  : 0.9502274317704689\n",
      "Average mcc Training score gaps in target sentence : 0.43130249691359623\n",
      "Average F1 Training score for whole target sentence class 0 : 0.7851485924880419\n",
      "Average F1 Training score for whole target sentence class 1 : 0.9640585033121271\n",
      "Average Accuracy Training score whole target sentence  : 0.9384186631905426\n",
      "Average mcc Training score whole target sentence : 0.7644204002322702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.95      0.78     18036\n",
      "           1       0.99      0.93      0.96    122886\n",
      "\n",
      "    accuracy                           0.93    140922\n",
      "   macro avg       0.83      0.94      0.87    140922\n",
      "weighted avg       0.95      0.93      0.94    140922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.35449941566030385\n",
      "Average F1 Validation score for whole sentence class 1 : 0.919577421494556\n",
      "Average Accuracy Validation score whole sentence  : 0.8569743353665554\n",
      "Average mcc Validation score whole sentence : 0.27988634844495175\n",
      "Average F1 Validation score for source sentence class 0 : 0.3406491499227202\n",
      "Average F1 Validation score for source sentence class 1 : 0.9050776556450537\n",
      "Average Accuracy Validation score source sentence  : 0.8340465261028553\n",
      "Average mcc Validation score source sentence : 0.2507912283672663\n",
      "Average F1 Validation score for target sentence class 0 : 0.3910780669144982\n",
      "Average F1 Validation score for target sentence class 1 : 0.8929085124002963\n",
      "Average Accuracy Validation score target sentence  : 0.8178515827711469\n",
      "Average mcc Validation score target sentence : 0.2929445291257132\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.1160092807424594\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9767640422028421\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9547183265985263\n",
      "Average mcc Validation score gaps in target sentence : 0.09305938331612783\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.36453201970443344\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9278596847991866\n",
      "Average Accuracy Validation score whole target sentence  : 0.8704287083961101\n",
      "Average mcc Validation score whole target sentence : 0.2988088662528276\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.31      0.35      4418\n",
      "           1       0.90      0.94      0.92     30338\n",
      "\n",
      "    accuracy                           0.86     34756\n",
      "   macro avg       0.66      0.62      0.64     34756\n",
      "weighted avg       0.84      0.86      0.85     34756\n",
      "\n",
      "Train Loss = 0.1686815654784441 Valid Loss = 1.956616172241786\n",
      "Epoch 10 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|| 250/250 [01:12<00:00,  3.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.8017617039125673\n",
      "Average F1 Training score for class 1 : 0.9643955786398583\n",
      "Average Accuracy Training score  : 0.939633272306666\n",
      "Average mcc Training score  : 0.7810258198863681\n",
      "Average F1 Training score for source sentence class 0 : 0.7902678024608875\n",
      "Average F1 Training score for source sentence class 1 : 0.9561502555088641\n",
      "Average Accuracy Training score source sentence  : 0.927465629452767\n",
      "Average mcc Training score source sentence : 0.7658426088065328\n",
      "Average F1 Training score for target sentence class 0 : 0.8625756266205704\n",
      "Average F1 Training score for target sentence class 1 : 0.9654351780872072\n",
      "Average Accuracy Training score target sentence  : 0.9447634023257515\n",
      "Average mcc Training score target sentence : 0.8370125705566361\n",
      "Average F1 Training score for gaps in target sentence class 0 : 0.421017177500842\n",
      "Average F1 Training score for gaps in target sentence class 1 : 0.9738049159593436\n",
      "Average Accuracy Training score gaps in target sentence  : 0.9498775367389783\n",
      "Average mcc Training score gaps in target sentence : 0.43512542227811585\n",
      "Average F1 Training score for whole target sentence class 0 : 0.8100352677140109\n",
      "Average F1 Training score for whole target sentence class 1 : 0.9690244667503137\n",
      "Average Accuracy Training score whole target sentence  : 0.9467343911538635\n",
      "Average mcc Training score whole target sentence : 0.7912154861180498\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.95      0.80     18036\n",
      "           1       0.99      0.94      0.96    122886\n",
      "\n",
      "    accuracy                           0.94    140922\n",
      "   macro avg       0.84      0.95      0.88    140922\n",
      "weighted avg       0.95      0.94      0.94    140922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.3694267515923567\n",
      "Average F1 Validation score for whole sentence class 1 : 0.908695652173913\n",
      "Average Accuracy Validation score whole sentence  : 0.8404879732995741\n",
      "Average mcc Validation score whole sentence : 0.2781295862448597\n",
      "Average F1 Validation score for source sentence class 0 : 0.35596535345068453\n",
      "Average F1 Validation score for source sentence class 1 : 0.8958286256609572\n",
      "Average Accuracy Validation score source sentence  : 0.8206644363183693\n",
      "Average mcc Validation score source sentence : 0.2520077843153196\n",
      "Average F1 Validation score for target sentence class 0 : 0.413869748833074\n",
      "Average F1 Validation score for target sentence class 1 : 0.8826905111437341\n",
      "Average Accuracy Validation score target sentence  : 0.8045073763807546\n",
      "Average mcc Validation score target sentence : 0.297282618781708\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.1568627450980392\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9626411815812337\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9284525790349417\n",
      "Average mcc Validation score gaps in target sentence : 0.13413399950100288\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.3786687128333014\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9160728629544218\n",
      "Average Accuracy Validation score whole target sentence  : 0.8521207140574351\n",
      "Average mcc Validation score whole target sentence : 0.29477105098625445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.37      0.37      4418\n",
      "           1       0.91      0.91      0.91     30338\n",
      "\n",
      "    accuracy                           0.84     34756\n",
      "   macro avg       0.64      0.64      0.64     34756\n",
      "weighted avg       0.84      0.84      0.84     34756\n",
      "\n",
      "Train Loss = 0.14898566113412381 Valid Loss = 1.857944588339518\n",
      "Epoch 11 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|| 250/250 [01:12<00:00,  3.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.8215564885315118\n",
      "Average F1 Training score for class 1 : 0.9686129711913554\n",
      "Average Accuracy Training score  : 0.946615858418132\n",
      "Average mcc Training score  : 0.8025008576531083\n",
      "Average F1 Training score for source sentence class 0 : 0.8094779207527917\n",
      "Average F1 Training score for source sentence class 1 : 0.9610214897885814\n",
      "Average Accuracy Training score source sentence  : 0.9352832441175338\n",
      "Average mcc Training score source sentence : 0.7869548458521739\n",
      "Average F1 Training score for target sentence class 0 : 0.8772870079467752\n",
      "Average F1 Training score for target sentence class 1 : 0.9697287440164122\n",
      "Average Accuracy Training score target sentence  : 0.9514371388868573\n",
      "Average mcc Training score target sentence : 0.8539803605248272\n",
      "Average F1 Training score for gaps in target sentence class 0 : 0.47599164926931103\n",
      "Average F1 Training score for gaps in target sentence class 1 : 0.9770839039532548\n",
      "Average Accuracy Training score gaps in target sentence  : 0.9560881735479356\n",
      "Average mcc Training score gaps in target sentence : 0.4928865310675285\n",
      "Average F1 Training score for whole target sentence class 0 : 0.8302471653479077\n",
      "Average F1 Training score for whole target sentence class 1 : 0.9728785726387676\n",
      "Average Accuracy Training score whole target sentence  : 0.9532296489414303\n",
      "Average mcc Training score whole target sentence : 0.8130140935805541\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82     18036\n",
      "           1       0.99      0.94      0.97    122886\n",
      "\n",
      "    accuracy                           0.95    140922\n",
      "   macro avg       0.86      0.95      0.90    140922\n",
      "weighted avg       0.96      0.95      0.95    140922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.35852973501037977\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9143388288244214\n",
      "Average Accuracy Validation score whole sentence  : 0.8488606283807112\n",
      "Average mcc Validation score whole sentence : 0.27457573037736466\n",
      "Average F1 Validation score for source sentence class 0 : 0.3356144004760488\n",
      "Average F1 Validation score for source sentence class 1 : 0.900067129111658\n",
      "Average Accuracy Validation score source sentence  : 0.8262662413444332\n",
      "Average mcc Validation score source sentence : 0.2380742021636872\n",
      "Average F1 Validation score for target sentence class 0 : 0.403755868544601\n",
      "Average F1 Validation score for target sentence class 1 : 0.8881943833083897\n",
      "Average Accuracy Validation score target sentence  : 0.8116984209355771\n",
      "Average mcc Validation score target sentence : 0.2956200962204547\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.15492957746478875\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9704797047970479\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9429522224863323\n",
      "Average mcc Validation score gaps in target sentence : 0.1291676801343445\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.3744821872410936\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9225203961208889\n",
      "Average Accuracy Validation score whole target sentence  : 0.8621193443820481\n",
      "Average mcc Validation score whole target sentence : 0.29830523155916505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.33      0.36      4418\n",
      "           1       0.90      0.92      0.91     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.65      0.63      0.64     34756\n",
      "weighted avg       0.84      0.85      0.84     34756\n",
      "\n",
      "Train Loss = 0.1315105997622013 Valid Loss = 2.0327193065295144\n",
      "terminating because of early stopping!\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "best_accuracy = -1\n",
    "train_loss_lst = []\n",
    "val_loss_lst = []\n",
    "with open(f'../Logs/Supervised_logs/{experiment_name_supervised}', 'w') as f:\n",
    "    f.write(f'{experiment_name_supervised}'+'\\n')\n",
    "    for epoch in range(config.EPOCHS):\n",
    "            print(f'Epoch {epoch+1} of {config.EPOCHS}')\n",
    "            train_metrics = engine.train_fn(train_dataloader, model, optimizer, scheduler)\n",
    "            print(classification_report(train_metrics[21],train_metrics[22]))\n",
    "            test_metrics = engine.eval_fn(val_dataloader, model)\n",
    "            print(classification_report(test_metrics[21],test_metrics[22]))\n",
    "#             print('For gaps : ',classification_report(test_metrics[27],test_metrics[28]) )\n",
    "#             print('For tar :',classification_report(test_metrics[25],test_metrics[26]) )\n",
    "#             print('For source : ',classification_report(test_metrics[23],test_metrics[24]) )\n",
    "            print(f\"Train Loss = {train_metrics[0]} Valid Loss = {test_metrics[0]}\")\n",
    "            writer_supervised.add_scalar('Train_loss/Supervised',train_metrics[0], epoch)\n",
    "            writer_supervised.add_scalar('Validation_loss/Supervised',test_metrics[0],epoch)\n",
    "            writer_supervised.add_scalar('mcc_score/Supervised_validation',test_metrics[4],epoch)\n",
    "            writer_supervised.add_scalar('mcc_score/Supervised_train',train_metrics[4],epoch)\n",
    "            train_loss_lst.append(train_metrics[:-14])\n",
    "            val_loss_lst.append(test_metrics[:-14])\n",
    "            f.write(f\"Train_loss {epoch+1} : {str(train_loss_lst)}\" + '\\n')\n",
    "            f.write(f\"val_loss {epoch+1} : {str(val_loss_lst)}\" + '\\n')\n",
    "            \n",
    "            if early_stopping.step(float(\"{:.2f}\".format(test_metrics[4]))): #mcc score for early stopping \"{:.2f}\".format(a_float)\n",
    "                  break  # early stop criterion is met, we can stop now\n",
    "            if float(\"{:.2f}\".format(test_metrics[4])) >  best_accuracy:\n",
    "                torch.save(model.state_dict(), f'../models/training_data/{model_name_supervised}.bin')\n",
    "                best_accuracy = float(\"{:.2f}\".format(test_metrics[4]))\n",
    "                print('Model saved for this epoch!')\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Testing Supervised model on hold out data <h/4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.44011446847908425\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8859767908260341\n",
      "Average Accuracy Validation score whole sentence  : 0.8105383081743093\n",
      "Average mcc Validation score whole sentence : 0.34489669421422875\n",
      "Average F1 Validation score for source sentence class 0 : 0.4211559218918654\n",
      "Average F1 Validation score for source sentence class 1 : 0.8580230571132879\n",
      "Average Accuracy Validation score source sentence  : 0.7719752609199846\n",
      "Average mcc Validation score source sentence : 0.30414451008368587\n",
      "Average F1 Validation score for target sentence class 0 : 0.4714131607335491\n",
      "Average F1 Validation score for target sentence class 1 : 0.8346031439868841\n",
      "Average Accuracy Validation score target sentence  : 0.7480442208102251\n",
      "Average mcc Validation score target sentence : 0.33347978256435984\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.08094435075885328\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9838053071048645\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9681714652806167\n",
      "Average mcc Validation score gaps in target sentence : 0.08257747619392802\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.4543511900375801\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9014361964088434\n",
      "Average Accuracy Validation score whole target sentence  : 0.833032694475761\n",
      "Average mcc Validation score whole target sentence : 0.3709310474878608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.34489669421422875"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'../models/training_data/{model_name_supervised}.bin'))\n",
    "model.eval()\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "mcc_score_supervised = test_metrics[4]\n",
    "mcc_score_supervised\n",
    "# Thesis/src/code/models/training_data/supervised_with_1250_labeled_data.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.42321557317952413\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8580301685891748\n",
      "Average Accuracy Validation score whole sentence  : 0.7721446881230418\n",
      "Average mcc Validation score whole sentence : 0.32821672191465334\n",
      "Average F1 Validation score for source sentence class 0 : 0.40723831659334275\n",
      "Average F1 Validation score for source sentence class 1 : 0.8200942231627744\n",
      "Average Accuracy Validation score source sentence  : 0.7239659837649788\n",
      "Average mcc Validation score source sentence : 0.2887107865421552\n",
      "Average F1 Validation score for target sentence class 0 : 0.44915421575725667\n",
      "Average F1 Validation score for target sentence class 1 : 0.7868368100659688\n",
      "Average Accuracy Validation score target sentence  : 0.6926212950380137\n",
      "Average mcc Validation score target sentence : 0.3038110403822042\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.02\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.985479760564215\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9713835192431233\n",
      "Average mcc Validation score gaps in target sentence : 0.026982087635793718\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.43548078761231124\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8786554713931539\n",
      "Average Accuracy Validation score whole target sentence  : 0.8002480270574972\n",
      "Average mcc Validation score whole target sentence : 0.35272455463726404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32821672191465334"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'../models/training_data/supervised_with_1750_labeled_data.bin'))\n",
    "model.eval()\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "mcc_score_supervised = test_metrics[4]\n",
    "mcc_score_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'supervised_with_1500_labeled_data_aug_syn'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-04-27 15:38:05.376 pytorch-1-6-gpu-py-ml-g4dn-2xlarge-775645915fb58e49f1a4db4ff39d:48 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-04-27 15:38:05.401 pytorch-1-6-gpu-py-ml-g4dn-2xlarge-775645915fb58e49f1a4db4ff39d:48 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.45008152276949914\n",
      "Average F1 Validation score for whole sentence class 1 : 0.872855427073562\n",
      "Average Accuracy Validation score whole sentence  : 0.7934634007405298\n",
      "Average mcc Validation score whole sentence : 0.3606928518711579\n",
      "Average F1 Validation score for source sentence class 0 : 0.43341172371744624\n",
      "Average F1 Validation score for source sentence class 1 : 0.8384212225837702\n",
      "Average Accuracy Validation score source sentence  : 0.748550444530344\n",
      "Average mcc Validation score source sentence : 0.32287545960497577\n",
      "Average F1 Validation score for target sentence class 0 : 0.478185234152112\n",
      "Average F1 Validation score for target sentence class 1 : 0.8129132050994187\n",
      "Average Accuracy Validation score target sentence  : 0.7245748705329269\n",
      "Average mcc Validation score target sentence : 0.34419956265479695\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.04222648752399232\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9852038547071905\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9708579104128949\n",
      "Average mcc Validation score gaps in target sentence : 0.054184275881262664\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.4629331184528606\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8916377628441362\n",
      "Average Accuracy Validation score whole target sentence  : 0.8196617812852312\n",
      "Average mcc Validation score whole target sentence : 0.3845762604810503\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3606928518711579"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'../models/training_data/supervised_with_3000_labeled_data.bin'))\n",
    "model.eval()\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "mcc_score_supervised = test_metrics[4]\n",
    "mcc_score_supervised\n",
    "# Thesis/src/code/models/training_data/supervised_with_1250_labeled_data.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.4520824269271843\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8797033614977814\n",
      "Average Accuracy Validation score whole sentence  : 0.8027200227855312\n",
      "Average mcc Validation score whole sentence : 0.3613334105721021\n",
      "Average F1 Validation score for source sentence class 0 : 0.43302990897269183\n",
      "Average F1 Validation score for source sentence class 1 : 0.8510274808415093\n",
      "Average Accuracy Validation score source sentence  : 0.7640510243525319\n",
      "Average mcc Validation score source sentence : 0.3201388797931383\n",
      "Average F1 Validation score for target sentence class 0 : 0.48088287646849415\n",
      "Average F1 Validation score for target sentence class 1 : 0.8195698977950455\n",
      "Average Accuracy Validation score target sentence  : 0.7322143460535497\n",
      "Average mcc Validation score target sentence : 0.34725342659258746\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.029661016949152543\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9864392728134067\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9732523506394908\n",
      "Average mcc Validation score gaps in target sentence : 0.07550230156356405\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.46621202727836325\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8955421053341062\n",
      "Average Accuracy Validation score whole target sentence  : 0.8252762119503946\n",
      "Average mcc Validation score whole target sentence : 0.38740244612386665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3613334105721021"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'../models/MeanTeacher_models/TeacherModels/teacherModel_v1_with_1750_labeled_250_unlabeled_data_withdropout_alpha_0.99_noises_changed_t_0.5_s_0.3.bin'))\n",
    "model.eval()\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "mcc_score_supervised = test_metrics[4]\n",
    "mcc_score_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'supervised_with_250_labeled_data_resampled_2'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_supervised "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'writer_supervised' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7f4a083340ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m writer_supervised.add_hparams(\n\u001b[0m\u001b[1;32m      2\u001b[0m                     { \"lr\": float(config.lr),  \n\u001b[1;32m      3\u001b[0m                      \u001b[0;34m\"labelled_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                      \u001b[0;34m\"validation_data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_data_sl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                      \u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'writer_supervised' is not defined"
     ]
    }
   ],
   "source": [
    "writer_supervised.add_hparams(\n",
    "                    { \"lr\": float(config.lr),  \n",
    "                     \"labelled_data\": float(len(train_data)), \n",
    "                     \"validation_data\": float(len(eval_data_sl)),\n",
    "                     \"alpha\":0.0, \n",
    "                     \"teacher_noise_gaussian_std\":0.0,\n",
    "                     \"student_noise_gaussian_std\":0.0,\n",
    "                     \"unlabelled_data\":0.0, \n",
    "                    },\n",
    "                    {\n",
    "                    \"mcc_score_test\" : float(mcc_score_supervised),\n",
    "                    \"mcc_score_teacher\": float(0) ,\n",
    "                    \"mcc_score_student\" : float(0),\n",
    "                    },\n",
    "                )\n",
    "# writer_supervised.flush()\n",
    "# writer_supervised.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training semi supervised Model for the same labeled data and added unlabeled data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_semisupervised = SummaryWriter(f\"runs/Supervised_and_MeanTeacherTraining_resampleddata/SemiSupervised_with_{label_data_required}_labelled_and_{unlabel_data_required}_unlabeled_data_rampup_steps_dropout_0.99_resampled3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_unlabel['len_src'] = df_unlabel['source'].str.split().map(lambda x:len(x))\n",
    "# df_unlabel['len_tar'] = df_unlabel['target'].str.split().map(lambda x:len(x))\n",
    "# print('Source : Max length: {}, Min length: {}, Average Length :  {}'.format(max(df_unlabel['len_tar']),min(df_unlabel['len_tar']),df_unlabel['len_tar'].mean()))\n",
    "\n",
    "# df_unlabel['len_tar'].hist()\n",
    "# df_unlabel[df_unlabel['len_tar']==30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_data_unlabelled(filePath_src,filePath_tar,len_train_data,df_unlabelled_train,model_type):\n",
    "    \n",
    "#     dataObj = loadUnlabelledDatafromFile(filePath_src,filePath_tar)\n",
    "#     df= dataObj.createDfUnlabelled() # get dataframe from files\n",
    "#     df['len_src'] = df['source'].str.split().map(lambda x:len(x))\n",
    "#     df['len_tar'] = df['target'].str.split().map(lambda x:len(x))\n",
    "    \n",
    "#     df = df[df.len_tar != 36]\n",
    "#     df = df[df.len_tar != 2]\n",
    "#     df = df[df.len_src != 1]\n",
    "    \n",
    "#     df = df.iloc[:,:-2]\n",
    "#     df = df.reset_index(drop=True)\n",
    "#     df_unlabelled_train = df_unlabelled_train.iloc[:,:-2]\n",
    "#     df_new = df.append(df_unlabelled_train, ignore_index = True)\n",
    "#     len_unlabelled_needed = config.fix_train_size - len_train_data\n",
    "#     df_new=df_new[:len_unlabelled_needed]\n",
    "# #     print(df_new)\n",
    "    \n",
    "#     obj_tokenized = createTokenizedDfUnlabelled(df_new,model_type)\n",
    "#     df_unlabelled= obj_tokenized.convertDf()\n",
    "# #     enc_label = preprocessing.LabelEncoder()\n",
    "# #     df_new['labels']= enc_label.fit_transform(df_new['labels'])\n",
    "#     train_data = CompDatasetUnlabelled(df_unlabelled,model_type)\n",
    "#     return df_new,train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_unlabelled(filePath_src,filePath_tar,df_unlabel, unlabel_data_needed, model_type):\n",
    "    \n",
    "    set_seed()\n",
    "    dataObj = loadUnlabelledDatafromFile(filePath_src,filePath_tar)\n",
    "    df= dataObj.createDfUnlabelled() # get dataframe from files\n",
    "    df['len_src'] = df['source'].str.split().map(lambda x:len(x))\n",
    "    df['len_tar'] = df['target'].str.split().map(lambda x:len(x))\n",
    "    \n",
    "    df = df[df.len_tar != 36]\n",
    "    df = df[df.len_tar != 2]\n",
    "    df = df[df.len_src != 1]\n",
    "    \n",
    "    df=df.iloc[:,:-2]\n",
    "#     df=df.iloc[:1000,:]\n",
    "#     df = df[:2000]\n",
    "    if unlabel_data_needed > len(df_unlabel):\n",
    "        \n",
    "        extra_data_needed = unlabel_data_needed - len(df_unlabel) # TAKE IT FROM THE BACKTRANSLATED DATASET\n",
    "        df = df[:extra_data_needed]\n",
    "        df_unlabel = df_unlabel.append(df,ignore_index=True)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        df_unlabel = df_unlabel[:unlabel_data_needed]\n",
    "        \n",
    "    obj_tokenized = createTokenizedDfUnlabelled(df_unlabel,model_type) # change to df\n",
    "    df_new = obj_tokenized.convertDf()\n",
    "#     enc_label = preprocessing.LabelEncoder()\n",
    "#     df_new['labels']= enc_label.fit_transform(df_new['labels'])\n",
    "    train_data = CompDatasetUnlabelled(df_new,model_type)\n",
    "    return df_new,train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([     0, 104431,     56,   1225,  80430,     10,    228,  32775,  35966,\n",
       "              6,      4,  12960, 123573,     31,   4527,      7,     10,  51876,\n",
       "           6967,    136,     10,   4989,  13986,    147,      6,      5,      2,\n",
       "              2,    656, 104431,     56,    656,  45786,    214,     18,    656,\n",
       "            599,    656,    228,  32775,  35966,    656,      6,      4,    656,\n",
       "          31005,    656, 123573,     31,    656,    909,    656,   8643,  16210,\n",
       "          36361,   1479,    656,    165,    656,   1918,    656,   1937,     33,\n",
       "            656,  26530,     56,    656, 190602,    656,      6,      5,    656,\n",
       "              2,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabelled_train, dataset_train_unlabelled = process_data_unlabelled(config.filePath_src_backtranslated,config.filePath_tar_backtranslated,df_unlabel,\n",
    "                                                                       unlabel_data_required, model_type = 'xlm')\n",
    "len_unlabelled_data = len(dataset_train_unlabelled)\n",
    "print(len_unlabelled_data)\n",
    "temp_val = next(iter(dataset_train_unlabelled)) # 31384,..\n",
    "temp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining 2 tuples --> labelled and unlabelled data \n",
    "combined_Data = train_data + dataset_train_unlabelled\n",
    "len(combined_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config= reload(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataloaders\n",
    "loader_obj = createDataloaders(combined_Data,config.TRAIN_BATCH_SIZE)\n",
    "train_dataloader = loader_obj.createDataloaders()\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(eval_data_ssl,config.VALID_BATCH_SIZE)\n",
    "val_dataloader = loader_obj.createDataloaders()\n",
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0,  20204,    191,   1314,   1295,     70,  30839,    209,    927,\n",
       "         39076,   3089,  26783, 141117,   1799,    191,    613,  18280,   2822,\n",
       "            47,     70,    606,    330,  60636,  70069,      7,      6,      5,\n",
       "             2,      2,    656,   2206,  72450,     13,    656,    224,    656,\n",
       "          4068,    656,  39076,   3089,  26783,    656,  42173,  62339,      7,\n",
       "           656,      6,  65860,    656,    833,    656,    168,    656,   1248,\n",
       "         69418,  26316,    656,  62980,   9022,    656,   5122,    656,      6,\n",
       "             5,    656,      2,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "batch[0][1] # as seen, combination of labelled and unlabelled data in one training batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seed()\n",
    "# a = torch.tensor([[1,2],[3,4]])\n",
    "# a= a.cuda()\n",
    "# noise = GaussianNoise(0.7)\n",
    "# print(noise(a))\n",
    "# # print(torch.randn(a.size()) * 0.7 )\n",
    "# # print(torch.autograd.Variable(torch.randn(a.size()).cuda() * 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class EntityModel(nn.Module):\n",
    "    \n",
    "#     def __init__(self,std_gaussian=0.1,with_noise_layer = True, dropout_layer=False, dropout_prob = 0.3):\n",
    "        \n",
    "#         super(EntityModel, self).__init__()\n",
    "        \n",
    "#         self.std_gaussian = std_gaussian\n",
    "#         self.with_noise_layer = with_noise_layer\n",
    "#         self.bert = XLMRobertaModel.from_pretrained(config.BASE_MODEL,output_attentions = False, output_hidden_states = False) # , add_pooling_layer=False\n",
    "#         self.dropout_layer = dropout_layer\n",
    "#         self.dropout_prob = dropout_prob\n",
    "#         if self.with_noise_layer:\n",
    "#             self.noise = GaussianNoise(stddev=self.std_gaussian)\n",
    "#         if self.dropout_layer:\n",
    "#             self.bert_drop_1 = nn.Dropout(self.dropout_prob) # remove this or noise \n",
    "#         self.out_tag = nn.Linear(768, 2)\n",
    "#         self.softmax = nn.Softmax(dim=2)\n",
    "    \n",
    "#     def forward(self, ids, attention_mask):\n",
    "        \n",
    "#         outputs = self.bert(ids,\n",
    "#                             attention_mask = attention_mask,\n",
    "#                             return_dict=False)\n",
    "        \n",
    "#         if (self.with_noise_layer):\n",
    "            \n",
    "#             noise = self.noise(outputs[0]) # 256*768\n",
    "            \n",
    "#             if self.dropout_layer:\n",
    "#                 bo_tag = self.bert_drop_1(noise)\n",
    "#                 tag = self.out_tag(bo_tag)\n",
    "#             else:\n",
    "#                 tag = self.out_tag(noise)\n",
    "        \n",
    "#         else:\n",
    "            \n",
    "#             if self.dropout_layer:\n",
    "#                 bo_tag = self.bert_drop_1(outputs[0])\n",
    "#                 tag = self.out_tag(bo_tag)\n",
    "            \n",
    "#             else :\n",
    "#                 tag = self.out_tag(outputs[0])\n",
    "# #         tag = self.out_tag(bo_tag) # 256 * 2 \n",
    "       \n",
    "#         softmax_prob = self.softmax(tag)\n",
    "        \n",
    "# #         loss_tag = loss_fn(tag,labels,attention_mask)\n",
    "        \n",
    "#         return softmax_prob,tag\n",
    "# #         return outputs[0], outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EntityModel(std_gaussian=config.gaussian_noise_std_student, with_noise_layer=True )\n",
    "# model.cuda()# print(noise ,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs, outputs1 = model(batch[0].cuda(), attention_mask = batch[1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = EntityModel(std_gaussian=config.gaussian_noise_std_teacher)\n",
    "# model2.cuda()\n",
    "# outputs, outputs1 = model2(batch[0].cuda(), attention_mask = batch[1].cuda())\n",
    "# print(outputs,'\\n')\n",
    "# print(outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ClassificationCost(output,target,mask):\n",
    "    \n",
    "    \n",
    "#     active_loss = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "#     active_logits = output.view(-1,2)\n",
    "    \n",
    "#     active_labels = torch.where( # just append -100 for the padded tokens so its ignored when computing loss , no need now\n",
    "#         active_loss,             # since its handled in preprocessing only\n",
    "#         target.view(-1),\n",
    "#         torch.tensor(-100).type_as(target)    \n",
    "#     )\n",
    "#     try:\n",
    "#         class_0_weights =1/len(torch.where(active_labels==0)[0]) # trying to weight the labels as its unbalanced mostly\n",
    "    \n",
    "#     except ZeroDivisionError:\n",
    "#         class_0_weights = float(1)\n",
    "    \n",
    "\n",
    "#     try:\n",
    "#         class_1_weights =1/len(torch.where(active_labels==1)[0])\n",
    "    \n",
    "#     except ZeroDivisionError:\n",
    "#         class_1_weights = float(1)\n",
    "    \n",
    "#     weights_tensor = torch.tensor([class_0_weights,class_1_weights]).cuda()\n",
    "#     lfn = nn.CrossEntropyLoss(weight = weights_tensor)\n",
    "#     loss = lfn(active_logits,active_labels)\n",
    "    \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([[0.2,0.5],[0.9,0.4],[0.9,0.2],[0.2,0.9],[0.7,0.4]])\n",
    "# b = torch.tensor([-100,-100,-100,-100,-100])\n",
    "# c = torch.tensor([1,1,1,1,1])\n",
    "# ClassificationCost(a,b,c).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ConsistencyCost(student_output, teacher_output,mask,scale=10):\n",
    "    \n",
    "#     assert len(student_output) == len(teacher_output)\n",
    "    \n",
    "#     loss = nn.MSELoss()\n",
    "#     active_outputs = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "#     flattened_outputs_student = student_output.view(-1,2)\n",
    "#     flatenned_outputs_teacher = teacher_output.view(-1,2)\n",
    "\n",
    "#     active_outputs_teacher=flatenned_outputs_teacher[torch.where(mask.view(-1) == 1)]\n",
    "#     active_outputs_student=flattened_outputs_student[torch.where(mask.view(-1) == 1)]\n",
    "    \n",
    "#     return scale * loss(active_outputs_student.view(-1),active_outputs_teacher.view(-1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ConsistencyCost(student_output, teacher_output,mask):\n",
    "    \n",
    "#     assert len(student_output) == len(teacher_output)\n",
    "    \n",
    "#     loss = nn.MSELoss()\n",
    "#     active_outputs = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "#     flattened_outputs_student = student_output.view(-1,2)\n",
    "#     flatenned_outputs_teacher = teacher_output.view(-1,2)\n",
    "    \n",
    "#     # [0.2,0.8] , [0.3,0.7] , [0.9,0.1] -> s\n",
    "#     # [0.7,0.3] , [0.9,0.1] , [0.8,0.2] -> T \n",
    "    \n",
    "    \n",
    "    \n",
    "#     pseudo_label = torch.softmax(logits_u_w.detach()/args.T, dim=-1)\n",
    "#     max_probs, targets_u = torch.max(pseudo_label, dim=-1)\n",
    "#     mask = max_probs.ge(config.threshold).float()\n",
    "\n",
    "#     Lu = (F.cross_entropy(logits_u_s, targets_u,\n",
    "#                                   reduction='none') * mask)\n",
    "    \n",
    "#     active_outputs_teacher=flatenned_outputs_teacher[torch.where(active_outputs == 1)]\n",
    "#     active_outputs_student=flattened_outputs_student[torch.where(active_outputs == 1)]\n",
    "    \n",
    "#     return torch.sqrt(loss(active_outputs_student,active_outputs_teacher))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Update teacher to be exponential moving average of student params.\n",
    "# def update_teacher_params(student_model, teacher_model, alpha, global_step):\n",
    "#     # Use the true average until the exponential average is more correct\n",
    "    \n",
    "#     teacher_params = teacher_model.parameters()\n",
    "#     student_params = student_model.parameters()\n",
    "    \n",
    "#     assert sum(p.numel() for p in student_model.parameters()) == sum(p.numel() for p in teacher_model.parameters())\n",
    "    \n",
    "# #     alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    \n",
    "# #     if global_step == 10 or global_step==20 or global_step == 30:\n",
    "# #         print(alpha)\n",
    "    \n",
    "#     for teacher_param, student_param in zip(teacher_params, student_params):\n",
    "#             teacher_param.data.mul_(alpha).add_(1 - alpha, student_param.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, optimizer,scheduler, student_model, teacher_model ,writer, global_step, epoch):\n",
    "    \n",
    "    student_model.train() # put student model in training mode\n",
    "    teacher_model.train()\n",
    "    total_train_loss = 0\n",
    "    consistency_cst = 0\n",
    "    classification_cst_student=0\n",
    "    classification_cst_teacher=0\n",
    "    classification_cst_lst = []\n",
    "    consistency_cst_lst = []\n",
    "    overall_cst_lst = []\n",
    "#     global_step = 0\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(train_dataloader, total = len(train_dataloader),position = 0 , leave = True)):\n",
    "\n",
    "            \n",
    "        b_input_ids = batch[0].cuda()\n",
    "        b_input_mask = batch[1].cuda()\n",
    "        b_labels = batch[2].cuda()\n",
    "     \n",
    "        \n",
    "        output_student_softmax, output_student_logit = student_model( b_input_ids, attention_mask = b_input_mask )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "                output_teacher_softmax, output_teacher_logit = teacher_model( b_input_ids, attention_mask = b_input_mask )\n",
    "          \n",
    "        \n",
    "        classification_cost_student =  ClassificationCost(output_student_logit,b_labels,b_input_mask)\n",
    "        classification_cst_student+=classification_cost_student.item()\n",
    "        \n",
    "        classification_cost_teacher =  ClassificationCost(output_teacher_logit,b_labels,b_input_mask)\n",
    "        classification_cst_teacher+=classification_cost_teacher.item()\n",
    "        \n",
    "        writer.add_scalar('Train_loss/Classification', classification_cost_student.item(), global_step)\n",
    "        \n",
    "        consistency_cost = ConsistencyCost(output_student_softmax,output_teacher_softmax.detach(),b_input_mask,scale=10)\n",
    "        consistency_cst+=consistency_cost.item()\n",
    "        \n",
    "        writer.add_scalar('Train_loss/Consistency', consistency_cost.item(), global_step)\n",
    "        \n",
    "#         overall_cost = (config.ratio * classification_cost) + ((1 - config.ratio) * consistency_cost)\n",
    "        \n",
    "        overall_cost =  classification_cost_student + get_consistency_weight(global_step) * consistency_cost\n",
    "        \n",
    "        writer.add_scalar('Train_loss/Overall', overall_cost.item(), global_step)\n",
    "        \n",
    "        total_train_loss+=overall_cost.item()\n",
    "\n",
    "        overall_cost.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        update_teacher_params(student_model , teacher_model , config.alpha,global_step)\n",
    "\n",
    "        if (len(train_dataloader) < 200):\n",
    "            if step % 50 == 0 and step!=0:\n",
    "                print ('train loss : ', total_train_loss/step)\n",
    "                print('Consistency Cost :', consistency_cst/step)\n",
    "                print('Classification Cost :', classification_cst_student/step)\n",
    "                print('Consistency Weight is:', get_consistency_weight(global_step))\n",
    "        else:\n",
    "            if step % 200 == 0 and step!=0:\n",
    "                print ('train loss : ', total_train_loss/step)\n",
    "                print('Consistency Cost :', consistency_cst/step)\n",
    "                print('Classification Cost :', classification_cst_student/step)\n",
    "                print('Consistency Weight is:', get_consistency_weight(global_step))\n",
    "\n",
    "        \n",
    "        global_step+=1\n",
    "        \n",
    "    return (consistency_cst/len(train_dataloader), classification_cst_student/len(train_dataloader), total_train_loss/len(train_dataloader),global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def soft_frequency(logits, power=2, probs=False):\n",
    "#     \"\"\"\n",
    "#     Unsupervised Deep Embedding for Clustering Analysis\n",
    "#     https://arxiv.org/abs/1511.06335\n",
    "#     \"\"\"\n",
    "#     if not probs:\n",
    "#         softmax = torch.nn.Softmax(dim=1)\n",
    "#         y = softmax(logits.view(-1, logits.shape[-1])).view(logits.shape)\n",
    "#     else:\n",
    "#         y = logits\n",
    "#     f = torch.sum(y, dim=(0, 1))\n",
    "#     t = y**power / f\n",
    "#     p = t/torch.sum(t, dim=2, keepdim=True)\n",
    "\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = torch.tensor([[[0.3,0.7] , [0.2,0.8] , [0.5569,0.5]]])\n",
    "# f = torch.sum(logits, dim=(0,1))\n",
    "# print(f)\n",
    "# new_logits = soft_frequency(logits,probs = True)\n",
    "# # t = logits**2 / f\n",
    "# # print(t.shape)\n",
    "# # p = t/torch.sum(t, dim=2, keepdim=True)\n",
    "# # p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax = torch.nn.Softmax(dim=1)\n",
    "# y = softmax(new_logits.view(-1, new_logits.shape[-1])).view(new_logits.shape)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _confidence = y.max(dim=-1)[0]\n",
    "# _confidence[0]\n",
    "# # torch.where(_confidence[0]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    lst_active_preds = []\n",
    "    lst_active_labels = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in tqdm(test_loader,total = len(test_loader),position = 0 , leave = True):            \n",
    "            b_input_ids_eval = batch[0].cuda()\n",
    "            b_input_mask_eval = batch[1].cuda()\n",
    "            b_labels_eval = batch[2].cuda()\n",
    "            \n",
    "            _, output= model(b_input_ids_eval,attention_mask = b_input_mask_eval)\n",
    "            \n",
    "            classification_cost =  ClassificationCost(output,b_labels_eval,b_input_mask_eval)\n",
    "            test_loss+=classification_cost\n",
    "            \n",
    "            labels = b_labels_eval.view(-1) \n",
    "            active_logits = output.view(-1, 2)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "            active_accuracy = labels.view(-1) != -100\n",
    "            labels_tmp = torch.masked_select(labels, active_accuracy) \n",
    "            pred_tmp = torch.masked_select(flattened_predictions, active_accuracy) \n",
    "            lst_active_labels.extend(labels_tmp.tolist())\n",
    "            lst_active_preds.extend(pred_tmp.tolist())\n",
    "            \n",
    "    avg_f1_score_0=f1_score(lst_active_labels,lst_active_preds,average='binary',pos_label = 0)\n",
    "    avg_f1_score_1=f1_score(lst_active_labels,lst_active_preds,average='binary',pos_label = 1)\n",
    "    avg_accuracy_score=accuracy_score(lst_active_labels,lst_active_preds)\n",
    "    avg_mcc_score = matthews_corrcoef(lst_active_labels,lst_active_preds)\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    print('Overall validation loss:', test_loss)\n",
    "    print('Average F1 Validation score for whole sentence class 0 :' ,avg_f1_score_0)\n",
    "    print('Average F1 Validation score for whole sentence class 1 :' ,avg_f1_score_1)\n",
    "    print('Average Accuracy Validation score whole sentence  :' ,avg_accuracy_score)\n",
    "    print('Average mcc Validation score whole sentence :' ,avg_mcc_score)\n",
    "    print('Classification Report :'+'\\n', classification_report(lst_active_labels,lst_active_preds))\n",
    "\n",
    "    return (test_loss, avg_f1_score_0 , avg_f1_score_1, avg_accuracy_score, avg_mcc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MeanTeacher(train_dataloader, val_dataloader,len_labelled_data ,len_unlabelled_data, writer,early_stopping,experiment_name,model_name,dropout_layer = False, noise_layer=True):\n",
    "    \n",
    "    exp_name = experiment_name\n",
    "    model_name = model_name\n",
    "    \n",
    "    global_step = 0\n",
    "    best_mcc_teacher = -1\n",
    "    best_mcc_student = -1\n",
    "    # train losses\n",
    "    epochs_consistency_lst =[]\n",
    "    epochs_classification_lst = []\n",
    "    epochs_overall_lst = []\n",
    "    \n",
    "    #test metrices for student\n",
    "    epochs_f1_score_0_lst_student = []\n",
    "    epochs_f1_score_1_lst_student = []\n",
    "    epochs_accuracy_lst_student = []\n",
    "    epochs_mcc_lst_student = []\n",
    "    epochs_cost_lst_student=[]\n",
    "    \n",
    "    #test metrices for teacher\n",
    "    epochs_f1_score_0_lst_teacher= []\n",
    "    epochs_f1_score_1_lst_teacher = []\n",
    "    epochs_accuracy_lst_teacher = []\n",
    "    epochs_mcc_lst_teacher = []\n",
    "    epochs_cost_lst_teacher=[]\n",
    "    \n",
    "    set_seed()\n",
    "    #initialaize the language models\n",
    "    student = EntityModel(std_gaussian=config.gaussian_noise_std_student, with_noise_layer=noise_layer,dropout_layer=dropout_layer) \n",
    "    teacher = EntityModel(std_gaussian=config.gaussian_noise_std_teacher, with_noise_layer=noise_layer)\n",
    "#     student.load_state_dict(torch.load('../models/training_data/model_xlmrobertatokenclassificationmodel_verylessData_weightedlss.bin'))\n",
    "#     teacher.load_state_dict(torch.load('../models/training_data/model_xlmrobertatokenclassificationmodel_verylessData_weightedlss.bin'))\n",
    "    student.cuda() # take model to gpu\n",
    "    teacher.cuda()\n",
    "#     teacher.eval()\n",
    "    param_optimizer_student = list(student.named_parameters())\n",
    "    param_teacher = list(teacher.named_parameters())\n",
    "    \n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer_student if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer_student if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "    optimizer = AdamW(optimizer_parameters, lr=config.lr)\n",
    "    num_train_steps = int(len(train_dataloader) * config.EPOCHS)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "#         optimizer, T_max=num_train_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n",
    "    set_seed() # setting seed again before training\n",
    "    \n",
    "    with open(f'../Logs/{exp_name}.txt', 'w') as f:\n",
    "        f.write(f'{exp_name}'+'\\n')\n",
    "        for epoch in range(0,config.EPOCHS):\n",
    "            print(f'Current epoch is {epoch+1} of {config.EPOCHS}')\n",
    "\n",
    "            consistency_cost , classification_cost , overall_cost, global_step = train(train_dataloader, optimizer,scheduler,student,teacher,writer,global_step,epoch)\n",
    "\n",
    "            writer.add_scalar('Train_loss/Consistency_epoch :', consistency_cost,epoch )\n",
    "            writer.add_scalar('Train_loss/Classification_epoch', classification_cost,epoch)\n",
    "            writer.add_scalar('Train_loss/Overall_epoch',overall_cost,epoch)\n",
    "\n",
    "            epochs_consistency_lst.append(consistency_cost)\n",
    "            epochs_classification_lst.append(classification_cost)\n",
    "            epochs_overall_lst.append(overall_cost)\n",
    "\n",
    "        \n",
    "            print('---------Running validation for student -------------')\n",
    "            test_loss_student, avg_f1_score_0_student, avg_f1_score_1_student, avg_accuracy_score_student, avg_mcc_score_student = test(student,val_dataloader)\n",
    "\n",
    "            epochs_f1_score_0_lst_student.append(avg_f1_score_0_student)\n",
    "            epochs_f1_score_1_lst_student.append(avg_f1_score_1_student)\n",
    "            epochs_accuracy_lst_student.append(avg_accuracy_score_student)\n",
    "            epochs_mcc_lst_student.append(avg_mcc_score_student)\n",
    "            epochs_cost_lst_student.append(test_loss_student)\n",
    "\n",
    "            writer.add_scalar('mcc_score/Student',avg_mcc_score_student,epoch)\n",
    "            writer.add_scalar('Validation_loss/Student',test_loss_student,epoch)\n",
    "\n",
    "\n",
    "            for name, weight in student.named_parameters():\n",
    "\n",
    "                if name == 'bert.embeddings.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.0.attention.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.1.attention.output.dense.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.2.output.dense.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.5.attention.self.key.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.9.attention.self.key.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.10.attention.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bbert.encoder.layer.11.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'out_tag.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "\n",
    "            if float(\"{:.2f}\".format(avg_mcc_score_student)) >  best_mcc_student :\n",
    "                    torch.save(student.state_dict(), f'../models/MeanTeacher_models/StudentModels/studentModel_{model_name}.bin')\n",
    "                    best_mcc_student = float(\"{:.2f}\".format(avg_mcc_score_student))\n",
    "\n",
    "            print('---------Running validation for teacher -------------')\n",
    "\n",
    "            test_loss_teacher, avg_f1_score_0_teacher, avg_f1_score_1_teacher, avg_accuracy_score_teacher, avg_mcc_score_teacher=test(teacher,val_dataloader)\n",
    "\n",
    "            epochs_f1_score_0_lst_teacher.append(avg_f1_score_1_teacher)\n",
    "            epochs_f1_score_1_lst_teacher.append(avg_f1_score_0_teacher)\n",
    "            epochs_accuracy_lst_teacher.append(avg_accuracy_score_teacher)\n",
    "            epochs_mcc_lst_teacher.append(avg_mcc_score_teacher)\n",
    "            epochs_cost_lst_teacher.append(test_loss_teacher)\n",
    "\n",
    "            writer.add_scalar('mcc_score/Teacher',avg_mcc_score_teacher,epoch)\n",
    "            writer.add_scalar('Validation_loss/Teacher',test_loss_teacher,epoch)\n",
    "\n",
    "            f.write(f\"Consistency_loss {epoch+1} : {str(consistency_cost)}\" + '\\n')\n",
    "            f.write(f\"Classification_loss {epoch+1} : {str(classification_cost)}\" + '\\n')\n",
    "            f.write(f\"Overall_loss {epoch+1} : {str(overall_cost)}\" + '\\n')\n",
    "            f.write(f\"'mcc_score/Teacher {epoch+1} : {str(avg_mcc_score_teacher)}\" + '\\n')\n",
    "            f.write(f\"ValidationLoss/Teacher {epoch+1} : {str(test_loss_teacher)}\" + '\\n')\n",
    "            f.write(f\"'mcc_score/Student {epoch+1} : {str(avg_mcc_score_student)}\" + '\\n')\n",
    "            f.write(f\"ValidationLoss/Student {epoch+1} : {str(test_loss_student)}\" + '\\n')\n",
    "\n",
    "            for name, weight in teacher.named_parameters():\n",
    "                if name == 'bert.embeddings.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.0.attention.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.1.attention.output.dense.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.2.output.dense.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.5.attention.self.key.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.9.attention.self.key.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.10.attention.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bbert.encoder.layer.11.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'out_tag.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "\n",
    "\n",
    "            if float(\"{:.2f}\".format(avg_mcc_score_teacher)) >  best_mcc_teacher :\n",
    "                    torch.save(teacher.state_dict(), f'../models/MeanTeacher_models/TeacherModels/teacherModel_{model_name}.bin')\n",
    "                    best_mcc_teacher = float(\"{:.2f}\".format(avg_mcc_score_teacher))\n",
    "                    print(f'model saved for {epoch}th epoch')\n",
    "\n",
    "\n",
    "            if early_stopping.step(float(\"{:.2f}\".format(avg_mcc_score_teacher))): #mcc score for early stopping \"{:.2f}\".format(a_float)\n",
    "                      break \n",
    "\n",
    "   \n",
    "    return (epochs_consistency_lst,epochs_classification_lst,epochs_overall_lst,epochs_f1_score_0_lst_student,epochs_f1_score_1_lst_student,\n",
    "           epochs_accuracy_lst_student,epochs_mcc_lst_student,epochs_cost_lst_student,epochs_f1_score_0_lst_teacher,epochs_f1_score_1_lst_teacher,\n",
    "            epochs_accuracy_lst_teacher,epochs_mcc_lst_teacher,epochs_cost_lst_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = reload(config)\n",
    "# config.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_tokens = np.array(test_metrics[27])\n",
    "# print(len(np.where(check_tokens==0)[0]))\n",
    "# check_tokens_p = np.array(test_metrics[28])\n",
    "# print(len(np.where(check_tokens_p==0)[0]))\n",
    "# print(len(test_metrics[27]))\n",
    "# print(len(test_metrics[28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MeanTeacher_initWithsuptrainedmodel_withConsistencyRampup_for_5_epochs\n",
    "# MeanTeacher_withConsistencyRampup_for_1500_steps\n",
    "# teacherModel_v1_rampup_const_cost_1500_steps_withDropout\n",
    "# v1_initSupModel_rampup_const_cost_5_epochs_withDropout\n",
    "# MeanTeacher_withConsistencyRampup_for_500_steps_to_1_250_labeled_1750_unlabeled_noises_interchanged\n",
    "# v1_rampup_const_cost_500_steps_to_1_withDropout_250_labeled_1750_unlabeled_noises_interchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine = reload(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v1_with_250_labeled_1750_unlabeled_data_withdropout_alpha_resampledData2'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = f'semisupervised_with_{len(train_data)}_labeled_{unlabel_data_required}_unlabeled_data_withdropout_resampledData2'\n",
    "model_name = f'v1_with_{len(train_data)}_labeled_{unlabel_data_required}_unlabeled_data_withdropout_alpha_resampledData2'\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 1 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:10<00:17,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.43700134637067095\n",
      "Consistency Cost : 0.3392463060468435\n",
      "Classification Cost : 0.41870374232530594\n",
      "Consistency Weight is: 0.16529888822158656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:27<00:00,  2.85it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 16.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6018, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.354868456739897\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7671554711513988\n",
      "Average Accuracy Validation score whole sentence  : 0.6578144780757279\n",
      "Average mcc Validation score whole sentence : 0.2622192471066497\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.74      0.35      4418\n",
      "           1       0.94      0.65      0.77     30338\n",
      "\n",
      "    accuracy                           0.66     34756\n",
      "   macro avg       0.59      0.69      0.56     34756\n",
      "weighted avg       0.85      0.66      0.71     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 16.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6293, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.35310148705492034\n",
      "Average F1 Validation score for whole sentence class 1 : 0.792544601295765\n",
      "Average Accuracy Validation score whole sentence  : 0.6858384163885373\n",
      "Average mcc Validation score whole sentence : 0.2514408902219676\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.67      0.35      4418\n",
      "           1       0.94      0.69      0.79     30338\n",
      "\n",
      "    accuracy                           0.69     34756\n",
      "   macro avg       0.59      0.68      0.57     34756\n",
      "weighted avg       0.85      0.69      0.74     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved for 0th epoch\n",
      "Current epoch is 2 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:12<00:17,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.49557117765769365\n",
      "Consistency Cost : 0.17550245463848113\n",
      "Classification Cost : 0.3870862476527691\n",
      "Consistency Weight is: 0.951229424500714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:30<00:00,  2.76it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 16.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6112, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3594968410268086\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7833586816317886\n",
      "Average Accuracy Validation score whole sentence  : 0.6762285648521119\n",
      "Average mcc Validation score whole sentence : 0.26471436464941334\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.71      0.36      4418\n",
      "           1       0.94      0.67      0.78     30338\n",
      "\n",
      "    accuracy                           0.68     34756\n",
      "   macro avg       0.59      0.69      0.57     34756\n",
      "weighted avg       0.85      0.68      0.73     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 16.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6207, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3657071857527438\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8330031803725578\n",
      "Average Accuracy Validation score whole sentence  : 0.73561399470595\n",
      "Average mcc Validation score whole sentence : 0.26069066594775314\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.37      4418\n",
      "           1       0.93      0.76      0.83     30338\n",
      "\n",
      "    accuracy                           0.74     34756\n",
      "   macro avg       0.60      0.68      0.60     34756\n",
      "weighted avg       0.84      0.74      0.77     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved for 1th epoch\n",
      "Current epoch is 3 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:13<00:17,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.4754611954838037\n",
      "Consistency Cost : 0.12880889389663935\n",
      "Classification Cost : 0.34665230110287665\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:30<00:00,  2.75it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6427, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3689740916018288\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8620913314050311\n",
      "Average Accuracy Validation score whole sentence  : 0.7736505927034181\n",
      "Average mcc Validation score whole sentence : 0.2614453919516613\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.52      0.37      4418\n",
      "           1       0.92      0.81      0.86     30338\n",
      "\n",
      "    accuracy                           0.77     34756\n",
      "   macro avg       0.60      0.67      0.62     34756\n",
      "weighted avg       0.84      0.77      0.80     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6257, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.37581871565158476\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8525493962190329\n",
      "Average Accuracy Validation score whole sentence  : 0.7614512602140637\n",
      "Average mcc Validation score whole sentence : 0.2713024198912733\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.56      0.38      4418\n",
      "           1       0.93      0.79      0.85     30338\n",
      "\n",
      "    accuracy                           0.76     34756\n",
      "   macro avg       0.60      0.68      0.61     34756\n",
      "weighted avg       0.84      0.76      0.79     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved for 2th epoch\n",
      "Current epoch is 4 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:08<00:16,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.4462102504074574\n",
      "Consistency Cost : 0.12376986045390367\n",
      "Classification Cost : 0.3224403890967369\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:24<00:00,  2.95it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6419, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.370791844476055\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8599669351718316\n",
      "Average Accuracy Validation score whole sentence  : 0.7709172516975487\n",
      "Average mcc Validation score whole sentence : 0.2638854365549824\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.53      0.37      4418\n",
      "           1       0.92      0.81      0.86     30338\n",
      "\n",
      "    accuracy                           0.77     34756\n",
      "   macro avg       0.60      0.67      0.62     34756\n",
      "weighted avg       0.84      0.77      0.80     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6456, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.37290850836596656\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8790925938636831\n",
      "Average Accuracy Validation score whole sentence  : 0.7972724133962481\n",
      "Average mcc Validation score whole sentence : 0.2671855449299469\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.47      0.37      4418\n",
      "           1       0.92      0.84      0.88     30338\n",
      "\n",
      "    accuracy                           0.80     34756\n",
      "   macro avg       0.61      0.66      0.63     34756\n",
      "weighted avg       0.84      0.80      0.81     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 5 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:08<00:16,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.33673534329980614\n",
      "Consistency Cost : 0.11137923255562782\n",
      "Classification Cost : 0.2253561115078628\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:25<00:00,  2.92it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.7225, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.35170969993021634\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8906709705620283\n",
      "Average Accuracy Validation score whole sentence  : 0.8128956151455864\n",
      "Average mcc Validation score whole sentence : 0.24657946880906315\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.40      0.35      4418\n",
      "           1       0.91      0.87      0.89     30338\n",
      "\n",
      "    accuracy                           0.81     34756\n",
      "   macro avg       0.61      0.64      0.62     34756\n",
      "weighted avg       0.83      0.81      0.82     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6967, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3578158241312937\n",
      "Average F1 Validation score for whole sentence class 1 : 0.893714055767006\n",
      "Average Accuracy Validation score whole sentence  : 0.8176142248820347\n",
      "Average mcc Validation score whole sentence : 0.25479210354646925\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.40      0.36      4418\n",
      "           1       0.91      0.88      0.89     30338\n",
      "\n",
      "    accuracy                           0.82     34756\n",
      "   macro avg       0.62      0.64      0.63     34756\n",
      "weighted avg       0.84      0.82      0.83     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 6 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:10<00:17,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.2646125303953886\n",
      "Consistency Cost : 0.10537009075284004\n",
      "Classification Cost : 0.15924244049936534\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:27<00:00,  2.84it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 16.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.8337, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3123247592344264\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9079906702115513\n",
      "Average Accuracy Validation score whole sentence  : 0.8376970882725285\n",
      "Average mcc Validation score whole sentence : 0.22178526597820203\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.29      0.31      4418\n",
      "           1       0.90      0.92      0.91     30338\n",
      "\n",
      "    accuracy                           0.84     34756\n",
      "   macro avg       0.62      0.60      0.61     34756\n",
      "weighted avg       0.83      0.84      0.83     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.7606, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.34365156945802106\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8997927203382804\n",
      "Average Accuracy Validation score whole sentence  : 0.8261307400161123\n",
      "Average mcc Validation score whole sentence : 0.243894890569092\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.36      0.34      4418\n",
      "           1       0.91      0.89      0.90     30338\n",
      "\n",
      "    accuracy                           0.83     34756\n",
      "   macro avg       0.62      0.63      0.62     34756\n",
      "weighted avg       0.83      0.83      0.83     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 7 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:08<00:16,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.24616737317293882\n",
      "Consistency Cost : 0.10047351453453303\n",
      "Classification Cost : 0.14569385818205774\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:25<00:00,  2.92it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.8500, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.33846840812681406\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9021369356277043\n",
      "Average Accuracy Validation score whole sentence  : 0.8294970652549201\n",
      "Average mcc Validation score whole sentence : 0.24065559043625614\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.34      0.34      4418\n",
      "           1       0.90      0.90      0.90     30338\n",
      "\n",
      "    accuracy                           0.83     34756\n",
      "   macro avg       0.62      0.62      0.62     34756\n",
      "weighted avg       0.83      0.83      0.83     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.8605, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3292343387470998\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9050449977008472\n",
      "Average Accuracy Validation score whole sentence  : 0.8336402347796064\n",
      "Average mcc Validation score whole sentence : 0.2344433138147628\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.32      0.33      4418\n",
      "           1       0.90      0.91      0.91     30338\n",
      "\n",
      "    accuracy                           0.83     34756\n",
      "   macro avg       0.62      0.61      0.62     34756\n",
      "weighted avg       0.83      0.83      0.83     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 8 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:08<00:16,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.22554008647799492\n",
      "Consistency Cost : 0.09521294279024005\n",
      "Classification Cost : 0.13032714328728617\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:24<00:00,  2.94it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.0396, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.28959153209390687\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9157588143475532\n",
      "Average Accuracy Validation score whole sentence  : 0.849378524571297\n",
      "Average mcc Validation score whole sentence : 0.21439995480608978\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.24      0.29      4418\n",
      "           1       0.89      0.94      0.92     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.63      0.59      0.60     34756\n",
      "weighted avg       0.83      0.85      0.84     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.9719, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.31569796323894683\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9103481939472828\n",
      "Average Accuracy Validation score whole sentence  : 0.8414662216595695\n",
      "Average mcc Validation score whole sentence : 0.22839188871133675\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.29      0.32      4418\n",
      "           1       0.90      0.92      0.91     30338\n",
      "\n",
      "    accuracy                           0.84     34756\n",
      "   macro avg       0.62      0.60      0.61     34756\n",
      "weighted avg       0.83      0.84      0.83     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 9 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:09<00:16,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.20911877293139697\n",
      "Consistency Cost : 0.08930019930005073\n",
      "Classification Cost : 0.1198185740748886\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:26<00:00,  2.89it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.9902, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.29934469200524244\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9136097734397725\n",
      "Average Accuracy Validation score whole sentence  : 0.846184831396018\n",
      "Average mcc Validation score whole sentence : 0.21882666196970652\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.26      0.30      4418\n",
      "           1       0.90      0.93      0.91     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.63      0.60      0.61     34756\n",
      "weighted avg       0.83      0.85      0.84     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 17.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.9719, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.30675954592363264\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9129857512953369\n",
      "Average Accuracy Validation score whole sentence  : 0.8453792150995512\n",
      "Average mcc Validation score whole sentence : 0.2244390373153901\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.27      0.31      4418\n",
      "           1       0.90      0.93      0.91     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.63      0.60      0.61     34756\n",
      "weighted avg       0.83      0.85      0.84     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 10 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:12<00:17,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.16691393811255695\n",
      "Consistency Cost : 0.08387032335624099\n",
      "Classification Cost : 0.08304361493559555\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:30<00:00,  2.76it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1199, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.29460470085470086\n",
      "Average F1 Validation score for whole sentence class 1 : 0.914839416999871\n",
      "Average Accuracy Validation score whole sentence  : 0.8480262400736563\n",
      "Average mcc Validation score whole sentence : 0.21695142373742696\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.25      0.29      4418\n",
      "           1       0.90      0.94      0.91     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.63      0.59      0.60     34756\n",
      "weighted avg       0.83      0.85      0.84     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 16.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.0601, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.30104125477790966\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9143641501816714\n",
      "Average Accuracy Validation score whole sentence  : 0.8474220278513063\n",
      "Average mcc Validation score whole sentence : 0.22179638719780995\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.26      0.30      4418\n",
      "           1       0.90      0.93      0.91     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.63      0.60      0.61     34756\n",
      "weighted avg       0.83      0.85      0.84     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 11 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:13<00:17,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.16044422781094908\n",
      "Consistency Cost : 0.08276496617123484\n",
      "Classification Cost : 0.07767926155822352\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [01:31<00:00,  2.72it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.2429, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.2776682624612785\n",
      "Average F1 Validation score for whole sentence class 1 : 0.917801634353469\n",
      "Average Accuracy Validation score whole sentence  : 0.8523995856830475\n",
      "Average mcc Validation score whole sentence : 0.20864615974715908\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.22      0.28      4418\n",
      "           1       0.89      0.94      0.92     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.63      0.58      0.60     34756\n",
      "weighted avg       0.83      0.85      0.84     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:03<00:00, 16.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1232, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.29436997319034847\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9151679236769161\n",
      "Average Accuracy Validation score whole sentence  : 0.8485441362642422\n",
      "Average mcc Validation score whole sentence : 0.21741099450856566\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.25      0.29      4418\n",
      "           1       0.90      0.94      0.92     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.63      0.59      0.60     34756\n",
      "weighted avg       0.83      0.85      0.84     34756\n",
      "\n",
      "terminating because of early stopping!\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=8)\n",
    "# experiment_name = input('Enter Experiment name')\n",
    "# model_name = input('Enter name for the models')\n",
    "# exp_name = f'semisupervised_with_{len(train_data)}_labeled_{unlabel_data_required}_unlabeled_data_withdropout_alpha_0.99_noises_changed_t_0.5_s_0.3_retest'\n",
    "# model_name = f'v1_with_{len(train_data)}_labeled_{unlabel_data_required}_unlabeled_data_withdropout_alpha_0.99_noises_changed_t_0.5_s_0.3_retest'\n",
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer_semisupervised, early_stopping,exp_name,model_name,dropout_layer=True, noise_layer=True)\n",
    "# semisupervised_with_250_labeled_1750_unlabeled_data_withdropout\n",
    "# v1_with_250_labeled_1750_unlabeled_data_withdropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.268281227313873\n",
      "0.263273337759238\n"
     ]
    }
   ],
   "source": [
    "# def tensors_to_lst(lst):\n",
    "#     new_lst = []\n",
    "#     for items in lst:\n",
    "#         new_lst.append(items.item())\n",
    "#     return new_lst\n",
    "\n",
    "# def get_items(lst):\n",
    "#     new_lst = []\n",
    "#     for items in lst:\n",
    "#         new_lst.append(float(items))\n",
    "#     return new_lst\n",
    "\n",
    "\n",
    "# consistency_cost_lst = get_items(metrices[0])\n",
    "# classification_cost_lst = get_items(metrices[1])\n",
    "# overall_cost_lst = get_items(metrices[2])\n",
    "# f1_class0_student_test = metrices[3]\n",
    "# f1_class1_student_test= metrices[4]\n",
    "# accuracy_student = metrices[5]\n",
    "# mcc_cost_student = metrices[6]\n",
    "# test_cost_student = tensors_to_lst(metrices[7])\n",
    "# f1_class1_teacher_test=metrices[8]\n",
    "# f1_class0_teacher_test = metrices[9]\n",
    "# accuracy_teacher = metrices[10]\n",
    "# mcc_cost_teacher = metrices[11]\n",
    "# test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "# max_mcc_student = np.amax(metrices[6])\n",
    "# max_mcc_teacher = np.amax(mcc_cost_teacher)\n",
    "# print(max_mcc_student)\n",
    "# print(max_mcc_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Thesis/src/code/models/MeanTeacher_models/StudentModels/studentModel_v1_with_250_labeled_1750_unlabeled_data_withdropout_alpha_oldData.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v1_with_250_labeled_1750_unlabeled_data_withdropout_alpha_resampledData2'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name=f'v1_with_{label_data_required}_labeled_{unlabel_data_required}_unlabeled_data_withdropout_alpha_resampledData2'\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.37304724261246003\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7741673042838187\n",
      "Average Accuracy Validation score whole sentence  : 0.6679436058103104\n",
      "Average mcc Validation score whole sentence : 0.27993996378879654\n",
      "Average F1 Validation score for source sentence class 0 : 0.35814277570152653\n",
      "Average F1 Validation score for source sentence class 1 : 0.7181598197646927\n",
      "Average Accuracy Validation score source sentence  : 0.6083107846926943\n",
      "Average mcc Validation score source sentence : 0.23015406411587624\n",
      "Average F1 Validation score for target sentence class 0 : 0.39238149792352855\n",
      "Average F1 Validation score for target sentence class 1 : 0.620086554245635\n",
      "Average Accuracy Validation score target sentence  : 0.532486135086495\n",
      "Average mcc Validation score target sentence : 0.23090011862286192\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.0\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9865348761504543\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9734275535829002\n",
      "Average mcc Validation score gaps in target sentence : 0.0\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.38404036628667537\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8040893961008083\n",
      "Average Accuracy Validation score whole target sentence  : 0.702728297632469\n",
      "Average mcc Validation score whole target sentence : 0.3092285902991288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.27993996378879654"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = EntityModel(with_noise_layer=False, dropout_layer=False) \n",
    "# model.cuda()\n",
    "# Thesis/src/code/models/MeanTeacher_models/StudentModels/studentModel_v1_with_250_labeled_1750_unlabeled_data_withdropout_alpha_resampledData.bin\n",
    "model.load_state_dict(torch.load(f'../models/MeanTeacher_models/StudentModels/studentModel_{model_name}.bin'))\n",
    "model.eval() # for 1k, 1.0 k data- teacher model -- less seq len\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "student_mcc_test = test_metrics[4]# student\n",
    "student_mcc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:411: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.38945292527938064\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8521289957367014\n",
      "Average Accuracy Validation score whole sentence  : 0.7619196810025634\n",
      "Average mcc Validation score whole sentence : 0.2830861334619802\n",
      "Average F1 Validation score for source sentence class 0 : 0.3733573357335733\n",
      "Average F1 Validation score for source sentence class 1 : 0.8286487816884075\n",
      "Average Accuracy Validation score source sentence  : 0.7308851952068033\n",
      "Average mcc Validation score source sentence : 0.24083357876610945\n",
      "Average F1 Validation score for target sentence class 0 : 0.4119618132389201\n",
      "Average F1 Validation score for target sentence class 1 : 0.7592722002225846\n",
      "Average Accuracy Validation score target sentence  : 0.6583905681859918\n",
      "Average mcc Validation score target sentence : 0.24848986279792368\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.0\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9865348761504543\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9734275535829002\n",
      "Average mcc Validation score gaps in target sentence : 0.0\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.40044247787610615\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8653007124316563\n",
      "Average Accuracy Validation score whole target sentence  : 0.7800225479143179\n",
      "Average mcc Validation score whole target sentence : 0.30934649451011026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2830861334619802"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(f'../models/MeanTeacher_models/TeacherModels/teacherModel_{model_name}.bin'))\n",
    "model.eval() # for 1k, 1.0 k data- teacher model -- less seq len\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "# Thesis/src/code/models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_500_steps_to_1_withDropout_250_labeled_1750_unlabeled.bin\n",
    "teacher_mcc_test = test_metrics[4]\n",
    "teacher_mcc_test\n",
    "# Thesis/src/code/models/MeanTeacher_models/TeacherModels/teacherModel_v1_with_1000_labeled_1000_unlabeled_data_withdropout_alpha_0.995.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v1_with_500_labeled_1500_unlabeled_data_withdropout_alpha_0.99_noises_changed_t_0.5_s_0.3'"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "#       'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "#       'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "#       'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "#       'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "#       'accuracy_student :',accuracy_student,'\\n',\n",
    "#       'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "#       'test_cost_student :',test_cost_student,'\\n',\n",
    "#       'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "#       'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "#     'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "#       'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "#       'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer_semisupervised.add_hparams(\n",
    "                    { \"lr\": float(config.lr),  \n",
    "                     \"labelled_data\": len_labelled_data, \n",
    "                     \"validation_data\":len(eval_data_ssl),\n",
    "                     \"alpha\":config.alpha, \n",
    "                     \"teacher_noise_gaussian_std\":config.gaussian_noise_std_teacher,\n",
    "                     \"student_noise_gaussian_std\":config.gaussian_noise_std_student,\n",
    "                     \"unlabelled_data\":len_unlabelled_data, \n",
    "                    },\n",
    "                    {\n",
    "                    \"mcc_score_test\" : float(0),\n",
    "                    \"mcc_score_teacher\": float(student_mcc_test) ,\n",
    "                    \"mcc_score_student\" : float(teacher_mcc_test),\n",
    "                    },\n",
    "                )\n",
    "writer_semisupervised.add_text('text', f'Ramup from 0 to 1 in 500 steps. Also, noise used in teacher is more than student 0.5 and 0.3 respectively for teacher and student models. {label_data_required} labeled and {unlabel_data_required} unlabeled. Alpha is 0.99')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.gaussian_noise_std_teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-67-2b3a9e4e0103>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-67-2b3a9e4e0103>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Run till this point\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Run till this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Experiment name : MeanTeacher_withConsistencyRampup_for_600_steps_to_1_1000_labeled_1000_unlabeled_alpha_adjusted_check\n",
      "Enter name for saving the models with version : v1_rampup_const_cost_600_steps_to_1_withDropout_1000_labeled_1000_unlabeled_alpha_adjusted_check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 1 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /codebuild/output/src811146734/src/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  app.launch_new_instance()\n",
      "  4%|         | 11/250 [00:06<02:12,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|         | 21/250 [00:11<02:03,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|        | 31/250 [00:17<01:58,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967741935483871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:51<00:27,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6507706062775105\n",
      "Consistency Cost : 0.4398407321423292\n",
      "Classification Cost : 0.6353269508481025\n",
      "Consistency Weight is: 0.10836802322189582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:19<00:00,  1.80it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5888, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.34186596583442835\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7450157825068731\n",
      "Average Accuracy Validation score whole sentence  : 0.6324379862028475\n",
      "Average mcc Validation score whole sentence : 0.26285807458677524\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.79      0.34      4122\n",
      "           1       0.95      0.61      0.75     29943\n",
      "\n",
      "    accuracy                           0.63     34065\n",
      "   macro avg       0.59      0.70      0.54     34065\n",
      "weighted avg       0.87      0.63      0.70     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6231, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3331091915377851\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7357829374756645\n",
      "Average Accuracy Validation score whole sentence  : 0.6215176867752825\n",
      "Average mcc Validation score whole sentence : 0.2497578093538212\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.78      0.33      4122\n",
      "           1       0.95      0.60      0.74     29943\n",
      "\n",
      "    accuracy                           0.62     34065\n",
      "   macro avg       0.58      0.69      0.53     34065\n",
      "weighted avg       0.86      0.62      0.69     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 2 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:54<00:28,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6618445229530334\n",
      "Consistency Cost : 0.193541909083724\n",
      "Classification Cost : 0.5814238642156124\n",
      "Consistency Weight is: 0.7316156289466418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:22<00:00,  1.75it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5723, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3611275612933791\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7894777925220513\n",
      "Average Accuracy Validation score whole sentence  : 0.6833113166006165\n",
      "Average mcc Validation score whole sentence : 0.279773841430625\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.74      0.36      4122\n",
      "           1       0.95      0.68      0.79     29943\n",
      "\n",
      "    accuracy                           0.68     34065\n",
      "   macro avg       0.59      0.71      0.58     34065\n",
      "weighted avg       0.86      0.68      0.74     34065\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a6411e94364f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_MeanTeacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_labelled_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_unlabelled_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-74161f607cb0>\u001b[0m in \u001b[0;36mtrain_MeanTeacher\u001b[0;34m(train_dataloader, val_dataloader, len_labelled_data, len_unlabelled_data, writer, early_stopping, dropout_layer, noise_layer)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_mcc_score_student\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m  \u001b[0mbest_mcc_student\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'../models/MeanTeacher_models/StudentModels/studentModel_{model_name}.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                     \u001b[0mbest_mcc_student\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_mcc_score_student\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=8)\n",
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer, early_stopping,dropout_layer=True, noise_layer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Experiment name : MeanTeacher_withConsistencyRampup_for_600_steps_to_1_1000_labeled_1000_unlabeled_alpha_adjusted\n",
      "Enter name for saving the models with version : v1_rampup_const_cost_600_steps_to_1_withDropout_1000_labeled_1000_unlabeled_alpha_adjusted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 1 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:55<00:29,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6507706062775105\n",
      "Consistency Cost : 0.4398407321423292\n",
      "Classification Cost : 0.6353269508481025\n",
      "Consistency Weight is: 0.10836802322189582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:25<00:00,  1.72it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5888, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.34186596583442835\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7450157825068731\n",
      "Average Accuracy Validation score whole sentence  : 0.6324379862028475\n",
      "Average mcc Validation score whole sentence : 0.26285807458677524\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.79      0.34      4122\n",
      "           1       0.95      0.61      0.75     29943\n",
      "\n",
      "    accuracy                           0.63     34065\n",
      "   macro avg       0.59      0.70      0.54     34065\n",
      "weighted avg       0.87      0.63      0.70     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6231, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3331091915377851\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7357829374756645\n",
      "Average Accuracy Validation score whole sentence  : 0.6215176867752825\n",
      "Average mcc Validation score whole sentence : 0.2497578093538212\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.78      0.33      4122\n",
      "           1       0.95      0.60      0.74     29943\n",
      "\n",
      "    accuracy                           0.62     34065\n",
      "   macro avg       0.58      0.69      0.53     34065\n",
      "weighted avg       0.86      0.62      0.69     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 2 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [02:01<00:29,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6618445229530334\n",
      "Consistency Cost : 0.193541909083724\n",
      "Classification Cost : 0.5814238642156124\n",
      "Consistency Weight is: 0.7316156289466418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:31<00:00,  1.65it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5723, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3611275612933791\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7894777925220513\n",
      "Average Accuracy Validation score whole sentence  : 0.6833113166006165\n",
      "Average mcc Validation score whole sentence : 0.279773841430625\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.74      0.36      4122\n",
      "           1       0.95      0.68      0.79     29943\n",
      "\n",
      "    accuracy                           0.68     34065\n",
      "   macro avg       0.59      0.71      0.58     34065\n",
      "weighted avg       0.86      0.68      0.74     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5883, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.35459619546645404\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7759234358933798\n",
      "Average Accuracy Validation score whole sentence  : 0.6673418464699838\n",
      "Average mcc Validation score whole sentence : 0.27390460591384436\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.76      0.35      4122\n",
      "           1       0.95      0.66      0.78     29943\n",
      "\n",
      "    accuracy                           0.67     34065\n",
      "   macro avg       0.59      0.71      0.57     34065\n",
      "weighted avg       0.86      0.67      0.72     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 3 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:55<00:26,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6834059897065162\n",
      "Consistency Cost : 0.1498090098798275\n",
      "Classification Cost : 0.5370685669779778\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:22<00:00,  1.76it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5714, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.359741355074501\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7738206376005562\n",
      "Average Accuracy Validation score whole sentence  : 0.665727286070747\n",
      "Average mcc Validation score whole sentence : 0.28387618922460817\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.78      0.36      4122\n",
      "           1       0.95      0.65      0.77     29943\n",
      "\n",
      "    accuracy                           0.67     34065\n",
      "   macro avg       0.59      0.71      0.57     34065\n",
      "weighted avg       0.87      0.67      0.72     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5763, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3688155922038981\n",
      "Average F1 Validation score for whole sentence class 1 : 0.806147116380799\n",
      "Average Accuracy Validation score whole sentence  : 0.7033905768383972\n",
      "Average mcc Validation score whole sentence : 0.28587170143879026\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.72      0.37      4122\n",
      "           1       0.95      0.70      0.81     29943\n",
      "\n",
      "    accuracy                           0.70     34065\n",
      "   macro avg       0.60      0.71      0.59     34065\n",
      "weighted avg       0.86      0.70      0.75     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 4 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:49<00:26,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6329384277760982\n",
      "Consistency Cost : 0.13410346314311028\n",
      "Classification Cost : 0.49883496075868605\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:16<00:00,  1.84it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5521, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.39303991811668376\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8475354440608243\n",
      "Average Accuracy Validation score whole sentence  : 0.7562894466461177\n",
      "Average mcc Validation score whole sentence : 0.30688499722525686\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.65      0.39      4122\n",
      "           1       0.94      0.77      0.85     29943\n",
      "\n",
      "    accuracy                           0.76     34065\n",
      "   macro avg       0.61      0.71      0.62     34065\n",
      "weighted avg       0.86      0.76      0.79     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5594, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.384313184919705\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8334048227373603\n",
      "Average Accuracy Validation score whole sentence  : 0.7377660355203288\n",
      "Average mcc Validation score whole sentence : 0.2993655055140609\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.68      0.38      4122\n",
      "           1       0.94      0.75      0.83     29943\n",
      "\n",
      "    accuracy                           0.74     34065\n",
      "   macro avg       0.61      0.71      0.61     34065\n",
      "weighted avg       0.86      0.74      0.78     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 5 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:56<00:29,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.578609249740839\n",
      "Consistency Cost : 0.1259544885158539\n",
      "Classification Cost : 0.45265476159751417\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:26<00:00,  1.71it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5497, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4086652007492466\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8699933752305241\n",
      "Average Accuracy Validation score whole sentence  : 0.7868486716571261\n",
      "Average mcc Validation score whole sentence : 0.32101908556910497\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.61      0.41      4122\n",
      "           1       0.94      0.81      0.87     29943\n",
      "\n",
      "    accuracy                           0.79     34065\n",
      "   macro avg       0.62      0.71      0.64     34065\n",
      "weighted avg       0.86      0.79      0.81     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5622, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.40028155795401216\n",
      "Average F1 Validation score for whole sentence class 1 : 0.861448395490026\n",
      "Average Accuracy Validation score whole sentence  : 0.7749009247027742\n",
      "Average mcc Validation score whole sentence : 0.312232297079589\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.62      0.40      4122\n",
      "           1       0.94      0.80      0.86     29943\n",
      "\n",
      "    accuracy                           0.77     34065\n",
      "   macro avg       0.62      0.71      0.63     34065\n",
      "weighted avg       0.86      0.77      0.81     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 6 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:54<00:26,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.5105033388361335\n",
      "Consistency Cost : 0.11641626179218292\n",
      "Classification Cost : 0.3940870776027441\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:21<00:00,  1.77it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5565, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4083471662319184\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8650840858703294\n",
      "Average Accuracy Validation score whole sentence  : 0.7802730074856892\n",
      "Average mcc Validation score whole sentence : 0.32224119948520497\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.63      0.41      4122\n",
      "           1       0.94      0.80      0.87     29943\n",
      "\n",
      "    accuracy                           0.78     34065\n",
      "   macro avg       0.62      0.71      0.64     34065\n",
      "weighted avg       0.86      0.78      0.81     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5538, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.41576182136602446\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8823487921001587\n",
      "Average Accuracy Validation score whole sentence  : 0.8041391457507706\n",
      "Average mcc Validation score whole sentence : 0.32708248581371663\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.58      0.42      4122\n",
      "           1       0.93      0.84      0.88     29943\n",
      "\n",
      "    accuracy                           0.80     34065\n",
      "   macro avg       0.63      0.71      0.65     34065\n",
      "weighted avg       0.86      0.80      0.83     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 7 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:49<00:26,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.47228979177773\n",
      "Consistency Cost : 0.11324455369263887\n",
      "Classification Cost : 0.35904523827135565\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:15<00:00,  1.84it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5694, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.42196163985092267\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8886905074480562\n",
      "Average Accuracy Validation score whole sentence  : 0.8133274622046088\n",
      "Average mcc Validation score whole sentence : 0.333774732241063\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.56      0.42      4122\n",
      "           1       0.93      0.85      0.89     29943\n",
      "\n",
      "    accuracy                           0.81     34065\n",
      "   macro avg       0.64      0.71      0.66     34065\n",
      "weighted avg       0.86      0.81      0.83     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5710, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.42609365966467533\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8968693724892643\n",
      "Average Accuracy Validation score whole sentence  : 0.8251577865844708\n",
      "Average mcc Validation score whole sentence : 0.3380102405478781\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.54      0.43      4122\n",
      "           1       0.93      0.86      0.90     29943\n",
      "\n",
      "    accuracy                           0.83     34065\n",
      "   macro avg       0.64      0.70      0.66     34065\n",
      "weighted avg       0.86      0.83      0.84     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 8 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:50<00:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.4151100990176201\n",
      "Consistency Cost : 0.10775427658110857\n",
      "Classification Cost : 0.3073558236286044\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:17<00:00,  1.81it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6327, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4102850754611515\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9108726873363183\n",
      "Average Accuracy Validation score whole sentence  : 0.8451489798913842\n",
      "Average mcc Validation score whole sentence : 0.3231022588010173\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.45      0.41      4122\n",
      "           1       0.92      0.90      0.91     29943\n",
      "\n",
      "    accuracy                           0.85     34065\n",
      "   macro avg       0.65      0.67      0.66     34065\n",
      "weighted avg       0.86      0.85      0.85     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5871, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4320213749871544\n",
      "Average F1 Validation score for whole sentence class 1 : 0.905357968458364\n",
      "Average Accuracy Validation score whole sentence  : 0.8377513576985175\n",
      "Average mcc Validation score whole sentence : 0.3454380086870494\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.51      0.43      4122\n",
      "           1       0.93      0.88      0.91     29943\n",
      "\n",
      "    accuracy                           0.84     34065\n",
      "   macro avg       0.65      0.70      0.67     34065\n",
      "weighted avg       0.86      0.84      0.85     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 9 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [02:00<00:29,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.36140915922820566\n",
      "Consistency Cost : 0.10124831279739738\n",
      "Classification Cost : 0.26016084644943477\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:30<00:00,  1.66it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6364, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.41714846732846084\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9093838508895409\n",
      "Average Accuracy Validation score whole sentence  : 0.843152796125055\n",
      "Average mcc Validation score whole sentence : 0.3298248006538421\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.46      0.42      4122\n",
      "           1       0.92      0.90      0.91     29943\n",
      "\n",
      "    accuracy                           0.84     34065\n",
      "   macro avg       0.65      0.68      0.66     34065\n",
      "weighted avg       0.86      0.84      0.85     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6150, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.42143406171077197\n",
      "Average F1 Validation score for whole sentence class 1 : 0.910729715534622\n",
      "Average Accuracy Validation score whole sentence  : 0.845325113753119\n",
      "Average mcc Validation score whole sentence : 0.3350929373157651\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.47      0.42      4122\n",
      "           1       0.92      0.90      0.91     29943\n",
      "\n",
      "    accuracy                           0.85     34065\n",
      "   macro avg       0.65      0.68      0.67     34065\n",
      "weighted avg       0.86      0.85      0.85     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 10 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [02:02<00:29,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.32515245221555233\n",
      "Consistency Cost : 0.09873415146023035\n",
      "Classification Cost : 0.22641830025240778\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:31<00:00,  1.65it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.7178, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.40980225646002666\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9187636715814784\n",
      "Average Accuracy Validation score whole sentence  : 0.8571847937766035\n",
      "Average mcc Validation score whole sentence : 0.3285659325308531\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.41      0.41      4122\n",
      "           1       0.92      0.92      0.92     29943\n",
      "\n",
      "    accuracy                           0.86     34065\n",
      "   macro avg       0.66      0.66      0.66     34065\n",
      "weighted avg       0.86      0.86      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6542, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.41705282669138094\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9154257285959192\n",
      "Average Accuracy Validation score whole sentence  : 0.8522824012916483\n",
      "Average mcc Validation score whole sentence : 0.3331154400061646\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.44      0.42      4122\n",
      "           1       0.92      0.91      0.92     29943\n",
      "\n",
      "    accuracy                           0.85     34065\n",
      "   macro avg       0.66      0.67      0.67     34065\n",
      "weighted avg       0.86      0.85      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 11 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:57<00:26,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.30029949981719256\n",
      "Consistency Cost : 0.09844230867922306\n",
      "Classification Cost : 0.20185719151981174\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:24<00:00,  1.73it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.7548, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3965811965811966\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9175508842175509\n",
      "Average Accuracy Validation score whole sentence  : 0.8549244092176721\n",
      "Average mcc Validation score whole sentence : 0.31414497677364983\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.39      0.40      4122\n",
      "           1       0.92      0.92      0.92     29943\n",
      "\n",
      "    accuracy                           0.85     34065\n",
      "   macro avg       0.66      0.66      0.66     34065\n",
      "weighted avg       0.85      0.85      0.85     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.7018, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.40841494377947046\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9182579060792864\n",
      "Average Accuracy Validation score whole sentence  : 0.8563628357551739\n",
      "Average mcc Validation score whole sentence : 0.32667609614293824\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.41      0.41      4122\n",
      "           1       0.92      0.92      0.92     29943\n",
      "\n",
      "    accuracy                           0.86     34065\n",
      "   macro avg       0.66      0.66      0.66     34065\n",
      "weighted avg       0.86      0.86      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 12 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:50<00:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.2751480747386813\n",
      "Consistency Cost : 0.09618175240233541\n",
      "Classification Cost : 0.17896632244810462\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:17<00:00,  1.81it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.9175, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3817829457364341\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9266738909138674\n",
      "Average Accuracy Validation score whole sentence  : 0.8688976955819756\n",
      "Average mcc Validation score whole sentence : 0.3140109280596588\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.33      0.38      4122\n",
      "           1       0.91      0.94      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.64      0.65     34065\n",
      "weighted avg       0.85      0.87      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.7536, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.406288685318148\n",
      "Average F1 Validation score for whole sentence class 1 : 0.920135882235396\n",
      "Average Accuracy Validation score whole sentence  : 0.8592103331865552\n",
      "Average mcc Validation score whole sentence : 0.32655157633549337\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.40      0.41      4122\n",
      "           1       0.92      0.92      0.92     29943\n",
      "\n",
      "    accuracy                           0.86     34065\n",
      "   macro avg       0.67      0.66      0.66     34065\n",
      "weighted avg       0.86      0.86      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 13 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:58<00:28,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.24575058571994304\n",
      "Consistency Cost : 0.08938711406663061\n",
      "Classification Cost : 0.15636347279883922\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:26<00:00,  1.71it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.8412, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4022677490014173\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9231559243982839\n",
      "Average Accuracy Validation score whole sentence  : 0.8638191692352855\n",
      "Average mcc Validation score whole sentence : 0.32656505228941407\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.38      0.40      4122\n",
      "           1       0.92      0.93      0.92     29943\n",
      "\n",
      "    accuracy                           0.86     34065\n",
      "   macro avg       0.67      0.65      0.66     34065\n",
      "weighted avg       0.86      0.86      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 14 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:50<00:26,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.21835778195410968\n",
      "Consistency Cost : 0.08650215949863195\n",
      "Classification Cost : 0.13185562253464014\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:17<00:00,  1.82it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.0128, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.38831659929586654\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9224127950248922\n",
      "Average Accuracy Validation score whole sentence  : 0.8622926757669162\n",
      "Average mcc Validation score whole sentence : 0.3123356791186087\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.36      0.39      4122\n",
      "           1       0.91      0.93      0.92     29943\n",
      "\n",
      "    accuracy                           0.86     34065\n",
      "   macro avg       0.67      0.65      0.66     34065\n",
      "weighted avg       0.85      0.86      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.9391, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3920988981456598\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9254547851305035\n",
      "Average Accuracy Validation score whole sentence  : 0.8671950682518714\n",
      "Average mcc Validation score whole sentence : 0.3208743975375306\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.35      0.39      4122\n",
      "           1       0.91      0.94      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.65      0.66     34065\n",
      "weighted avg       0.86      0.87      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 15 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:55<00:29,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.21577567676082254\n",
      "Consistency Cost : 0.0838872840628028\n",
      "Classification Cost : 0.13188839299138636\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:24<00:00,  1.73it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1569, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.37494769144929563\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9264939879595151\n",
      "Average Accuracy Validation score whole sentence  : 0.8684573609276384\n",
      "Average mcc Validation score whole sentence : 0.3076112804224331\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.33      0.37      4122\n",
      "           1       0.91      0.94      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.63      0.65     34065\n",
      "weighted avg       0.85      0.87      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:07<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.0667, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.38393223117912284\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9258522306819491\n",
      "Average Accuracy Validation score whole sentence  : 0.8676354029062087\n",
      "Average mcc Validation score whole sentence : 0.3142628805414049\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.34      0.38      4122\n",
      "           1       0.91      0.94      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.64      0.65     34065\n",
      "weighted avg       0.85      0.87      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 16 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|  | 201/250 [01:51<00:26,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.19508064774796366\n",
      "Consistency Cost : 0.08055738933384418\n",
      "Classification Cost : 0.11452325810678303\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 250/250 [02:18<00:00,  1.81it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1754, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.364396999422966\n",
      "Average F1 Validation score for whole sentence class 1 : 0.92800418314324\n",
      "Average Accuracy Validation score whole sentence  : 0.8706590341993248\n",
      "Average mcc Validation score whole sentence : 0.3019851510238544\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.31      0.36      4122\n",
      "           1       0.91      0.95      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.63      0.65     34065\n",
      "weighted avg       0.85      0.87      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 63/63 [00:06<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1576, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.38059598059598065\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9266354756628087\n",
      "Average Accuracy Validation score whole sentence  : 0.8688096286511082\n",
      "Average mcc Validation score whole sentence : 0.3128832519403145\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.33      0.38      4122\n",
      "           1       0.91      0.94      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.64      0.65     34065\n",
      "weighted avg       0.85      0.87      0.86     34065\n",
      "\n",
      "terminating because of early stopping!\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=8)\n",
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer, early_stopping,dropout_layer=True, noise_layer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail hoga ya pe\n",
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer, early_stopping,dropout_layer=True, noise_layer=True) # alpha = 0.995 and full data w/o noise and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model= EntityModel()\n",
    "# optimizer_parameters_model = list(model.named_parameters())\n",
    "  \n",
    "# no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "# optimizer_parameters = [\n",
    "# {\n",
    "#     \"params\": [\n",
    "#         p for n, p in optimizer_parameters_model if not any(nd in n for nd in no_decay)\n",
    "#     ],\n",
    "#     \"weight_decay\": 0.001,\n",
    "# },\n",
    "# {\n",
    "#     \"params\": [\n",
    "#         p for n, p in optimizer_parameters_model if any(nd in n for nd in no_decay)\n",
    "#     ],\n",
    "#     \"weight_decay\": 0.0,\n",
    "# }]\n",
    "# optimizer = AdamW(optimizer_parameters, lr=config.lr)\n",
    "# num_train_steps = int(len(train_dataloader) * config.EPOCHS)\n",
    "# #     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "# #         optimizer, T_max=num_train_steps)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "# optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n",
    "# float(scheduler.get_last_lr()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        for item in items :\n",
    "            new_lst.append(float(item))\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensors_to_lst(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        new_lst.append(items.item())\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_against_epochs(matrix1,matrix2,label1 , label2 ,y_label , title):\n",
    "    \n",
    "    epochs = np.arange(1,config.EPOCHS+1)\n",
    "    # print(epochs)\n",
    "    plt.plot(epochs,matrix1,label=label1)\n",
    "    if matrix2 is not None :\n",
    "        plt.plot(epochs,matrix2,label=label2)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Running without Noise embeddings and dropout </h2> -- <h4> No weighted Loss </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,noise_layer=False) # alpha = 0.995 and full data w/o noise and dropout\n",
    "\n",
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plotting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_epochs(test_cost_teacher,test_cost_student,label1 = 'ValidationLoss_teacher', \n",
    "                    label2 = 'ValidationLoss_student', y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(mcc_cost_teacher,mcc_cost_student,label1 = 'mcc_teacher', \n",
    "                    label2 = 'mcc_student', y_label = 'mcc_score_test', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(classification_cost_lst,None,label1 = 'classification_cost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(consistency_cost_lst,None,label1 = 'Consistency_lost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    if 'classifier' not in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.add_text('Text','The Labelled data used in this experiment was 3200 and unlabelled used was 6400')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/MeanTeacherTraining/alpha_0.995_trail1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer, noise_layer=True) # alpha = 0.995 and full data w/o noise and dropout\n",
    "\n",
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_epochs(test_cost_teacher,test_cost_student,label1 = 'ValidationLoss_teacher', \n",
    "                    label2 = 'ValidationLoss_student', y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(mcc_cost_teacher,mcc_cost_student,label1 = 'mcc_teacher', \n",
    "                    label2 = 'mcc_student', y_label = 'mcc_score_test', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(classification_cost_lst,None,label1 = 'classification_cost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(consistency_cost_lst,None,label1 = 'Consistency_lost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
