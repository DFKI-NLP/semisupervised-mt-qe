{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Collecting tokenizers!=0.11.3,>=0.11.1\n",
      "  Using cached tokenizers-0.11.6-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.3.15-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Installing collected packages: regex, filelock, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.4.1 huggingface-hub-0.4.0 regex-2022.3.15 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.96-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.6/site-packages (from nltk) (2022.3.15)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.6.7\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-7.7.0-py2.py3-none-any.whl (123 kB)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (5.5.6)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (4.3.3)\n",
      "Collecting widgetsnbextension~=3.6.0\n",
      "  Using cached widgetsnbextension-3.6.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Using cached jupyterlab_widgets-1.1.0-py3-none-any.whl (245 kB)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (7.16.3)\n",
      "Collecting nbformat>=4.2.0\n",
      "  Using cached nbformat-5.1.3-py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Collecting jedi<=0.17.2,>=0.10\n",
      "  Using cached jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (59.3.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.28)\n",
      "Requirement already satisfied: pexpect in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Collecting parso<0.8.0,>=0.7.0\n",
      "  Using cached parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n",
      "Collecting jsonschema!=2.5.0,>=2.4\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Using cached pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Collecting notebook>=4.4.1\n",
      "  Using cached notebook-6.4.10-py3-none-any.whl (9.9 MB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.1.0)\n",
      "Collecting prometheus-client\n",
      "  Using cached prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
      "Collecting terminado>=0.8.3\n",
      "  Using cached terminado-0.12.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.4)\n",
      "Collecting argon2-cffi\n",
      "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Collecting Send2Trash>=1.8.0\n",
      "  Using cached Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting nbconvert>=5\n",
      "  Using cached nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting bleach\n",
      "  Using cached bleach-4.1.0-py2.py3-none-any.whl (157 kB)\n",
      "Collecting testpath\n",
      "  Using cached testpath-0.6.0-py3-none-any.whl (83 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Using cached nbclient-0.5.9-py3-none-any.whl (69 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
      "Collecting async-generator\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.6/site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10.0.0)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4.7)\n",
      "Installing collected packages: pyrsistent, parso, jsonschema, webencodings, nbformat, jedi, async-generator, testpath, pandocfilters, nbclient, mistune, jupyterlab-pygments, defusedxml, bleach, argon2-cffi-bindings, terminado, Send2Trash, prometheus-client, nbconvert, argon2-cffi, notebook, widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "  Attempting uninstall: parso\n",
      "    Found existing installation: parso 0.8.0\n",
      "    Uninstalling parso-0.8.0:\n",
      "      Successfully uninstalled parso-0.8.0\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.18.0\n",
      "    Uninstalling jedi-0.18.0:\n",
      "      Successfully uninstalled jedi-0.18.0\n",
      "Successfully installed Send2Trash-1.8.0 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 async-generator-1.10 bleach-4.1.0 defusedxml-0.7.1 ipywidgets-7.7.0 jedi-0.17.2 jsonschema-3.2.0 jupyterlab-pygments-0.1.2 jupyterlab-widgets-1.1.0 mistune-0.8.4 nbclient-0.5.9 nbconvert-6.0.7 nbformat-5.1.3 notebook-6.4.10 pandocfilters-1.5.0 parso-0.7.1 prometheus-client-0.13.1 pyrsistent-0.18.0 terminado-0.12.1 testpath-0.6.0 webencodings-0.5.1 widgetsnbextension-3.6.0\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting tensorboard\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting absl-py>=0.4\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (59.3.0)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Using cached grpcio-1.44.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (3.17.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.25.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.35.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from absl-py>=0.4->tensorboard) (1.16.0)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard) (0.8)\n",
      "Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\n",
      "Successfully installed absl-py-1.0.0 cachetools-4.2.4 google-auth-2.6.2 google-auth-oauthlib-0.4.6 grpcio-1.44.0 markdown-3.3.6 oauthlib-3.2.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install nltk\n",
    "!pip install ipywidgets\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval\n",
      "  Using cached seqeval-1.2.2-py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.6/site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval) (1.19.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-1.2.2\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.17.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.17.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: seqeval in /opt/conda/lib/python3.6/site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.6/site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.6/site-packages (from seqeval) (1.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.6/site-packages (from scikit-learn>=0.21.3->seqeval) (1.5.4)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.17.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.6.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.6/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "# from DataAugmentation \n",
    "from data_utils import loadDatafromFile,createTokenizedDf,CompDataset,createkfoldData,createDataloaders\n",
    "from data_utils_unlabelled import loadUnlabelledDatafromFile,createTokenizedDfUnlabelled,CompDatasetUnlabelled\n",
    "from DataAugmentation import DataAugmentation\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from importlib import reload\n",
    "import config\n",
    "from transformers import XLMRobertaForTokenClassification, XLMRobertaConfig ,BertModel, XLMRobertaTokenizer, XLMRobertaModel, BertForTokenClassification\n",
    "from seqeval.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import matthews_corrcoef,classification_report,f1_score\n",
    "import engine\n",
    "# from model_new import EntityModel\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data_utils\n",
    "# data_utils = reload(data_utils)\n",
    "# from data_utils import loadDatafromFile,createTokenizedDf,CompDataset,createkfoldData,createDataloaders\n",
    "# import data_utils_unlabelled\n",
    "# data_utils_unlabelled = reload(data_utils_unlabelled)\n",
    "# from data_utils_unlabelled import loadUnlabelledDatafromFile,createTokenizedDfUnlabelled,CompDatasetUnlabelled, createkfoldData,createDataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config= reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consistency_weight = 100.0 # max weights till you want a ramp-up, will be this value after rampup epoch is reached\n",
    "# consistency_rampup = 1000 # till what epochs rampup is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_rampup(current, rampup_length):\n",
    "    \"\"\"Exponential rampup from https://arxiv.org/abs/1610.02242\"\"\"\n",
    "    if rampup_length == 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        current = np.clip(current, 0.0, rampup_length)\n",
    "        phase = 1.0 - current / rampup_length\n",
    "        return float(np.exp(-5.0 * phase * phase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_consistency_weight(epoch):\n",
    "        # Consistency ramp-up from https://arxiv.org/abs/1610.02242\n",
    "        return config.consistency_weight * sigmoid_rampup(\n",
    "            epoch, config.consistency_rampup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = np.arange(0,1500,1)\n",
    "# for item in lst :\n",
    "#     if item==1000:\n",
    "#         print(get_consistency_weight(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting seed\n",
    "def set_seed():\n",
    "    \n",
    "    torch.manual_seed(config.random_seed)\n",
    "    np.random.seed(config.random_seed)\n",
    "    random.seed(config.random_seed)\n",
    "    torch.cuda.manual_seed(config.random_seed)\n",
    "set_seed()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.tensorboard.summary import hparams\n",
    "\n",
    "class SummaryWriter(SummaryWriter):\n",
    "    def add_hparams(self, hparam_dict, metric_dict):\n",
    "        torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n",
    "        if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n",
    "            raise TypeError('hparam_dict and metric_dict should be dictionary.')\n",
    "        exp, ssi, sei = hparams(hparam_dict, metric_dict)\n",
    "\n",
    "        logdir = self._get_file_writer().get_logdir()\n",
    "        \n",
    "        with SummaryWriter(log_dir=logdir) as w_hp:\n",
    "            w_hp.file_writer.add_summary(exp)\n",
    "            w_hp.file_writer.add_summary(ssi)\n",
    "            w_hp.file_writer.add_summary(sei)\n",
    "            for k, v in metric_dict.items():\n",
    "                w_hp.add_scalar(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_labelled(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags,\n",
    "                 filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval,train_data_needed,\n",
    "                          unlabel_data_needed,total_train_data=2000, model_type='xlm'):\n",
    "    \n",
    "    set_seed()\n",
    "    dataObjTrain = loadDatafromFile(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags)\n",
    "    df_train= dataObjTrain.createDf() # get dataframe from files    \n",
    " \n",
    "    dataObjEval = loadDatafromFile(filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval)\n",
    "    df_eval = dataObjEval.createDf()\n",
    "#     df_combined = df_train.append(df_eval, ignore_index=True)\n",
    "#     df_combined.reset_index(drop=True)\n",
    "    split_ratio_len = int(len(df_train) - config.test_split_ratio*len(df_train))\n",
    "   \n",
    "    df_train_splitted = df_train.iloc[:split_ratio_len,:]\n",
    "    df_eval_splitted = df_train.iloc[split_ratio_len:,:]\n",
    "    df_train_splitted = df_train_splitted[:total_train_data]#2000\n",
    "    df_train_splitted_ = df_train_splitted[:train_data_needed] # amount of labeled data needed for training out of 2000 for eg. 250\n",
    "    eval_data_needed = int(0.25 * (train_data_needed+unlabel_data_needed)) # 25 % reserve for validation -->500 for 2k data train\n",
    "    df_eval_splitted_ = df_eval_splitted[:eval_data_needed] # fix this 500 for all experiments\n",
    "    \n",
    "    \n",
    "#     df_train_splitted_ = df_train_splitted[:1000]\n",
    "    df_unlabel_splitted_train = df_train_splitted[train_data_needed:] # get remaining data in train df to be used as unlabeled\n",
    "    df_unlabel_splitted_train = df_unlabel_splitted_train.reset_index(drop=True)\n",
    "#     df_eval_splitted = df_eval_splitted[:500]\n",
    "\n",
    "#     df_unlabel_splitted_test = df_eval_splitted[eval_data_needed:]# get remaining data in eval df to use for unlabel\n",
    "#     df_unlabel_splitted_test=df_unlabel_splitted_test.reset_index(drop=True)\n",
    "    \n",
    "#     df_unlabeled = df_unlabel_splitted_train.append(df_unlabel_splitted_test, ignore_index = True) # combine both unlabel df's\n",
    "    \n",
    "    obj_tokenized_train = createTokenizedDf(df_train_splitted_,model_type)\n",
    "    obj_tokenized_eval = createTokenizedDf(df_eval_splitted_,model_type)\n",
    "    obj_tokenized_test = createTokenizedDf(df_eval,model_type)\n",
    "    \n",
    "    df_new_train = obj_tokenized_train.convertDf()\n",
    "    df_new_eval = obj_tokenized_eval.convertDf()\n",
    "    df_new_test = obj_tokenized_test.convertDf()\n",
    "    \n",
    "    train_data = CompDataset(df_new_train,model_type)\n",
    "    eval_data = CompDataset(df_new_eval,model_type)\n",
    "    test_data = CompDataset(df_new_test,model_type)\n",
    "    \n",
    "    return train_data, eval_data, test_data, df_unlabel_splitted_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the labelled data\n",
    "# def process_data_labelled(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags,\n",
    "#                  filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval,\n",
    "#                  model_type='xlm'):\n",
    "    \n",
    "    \n",
    "#     dataObjTrain = loadDatafromFile(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags)\n",
    "#     df_train= dataObjTrain.createDf() # get dataframe from files    \n",
    "#     df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "#     df_train=df_train.iloc[:500,:]\n",
    "#     dataObjEval = loadDatafromFile(filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval)\n",
    "#     df_eval = dataObjEval.createDf()\n",
    "#     obj_tokenized_train = createTokenizedDf(df_train,model_type)\n",
    "#     obj_tokenized_test = createTokenizedDf(df_eval,model_type)\n",
    "#     df_new_train = obj_tokenized_train.convertDf()\n",
    "#     df_new_eval = obj_tokenized_test.convertDf()\n",
    "#     train_data = CompDataset(df_new_train,model_type)\n",
    "#     test_data = CompDataset(df_new_eval,model_type)\n",
    "#     return train_data,test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter labeled data needed 250\n",
      "enter unlabeled data needed 1750\n",
      "Total training data needed 2000\n"
     ]
    }
   ],
   "source": [
    "total_train_data = 2000 \n",
    "label_data_required = int(input('enter labeled data needed'))\n",
    "unlabel_data_required = total_train_data - label_data_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()\n",
    "train_data , eval_data, test_data, df_unlabel = process_data_labelled(config.filePath_src,config.filePath_tar, config.filePath_srcTags,config.filePath_tarTags,\n",
    "                                                config.filePath_src_eval,config.filePath_tar_eval, config.filePath_srcTags_eval,\n",
    "                                                config.filePath_tarTags_eval,label_data_required,unlabel_data_required, total_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "500\n",
      "1750\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "len_labelled_data = len(train_data)\n",
    "len_eval_data = len(eval_data)\n",
    "print(len_labelled_data)\n",
    "print(len_eval_data)\n",
    "print(len(df_unlabel))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([     0,  17151,  12426,   2765,    113,    527, 110896,  36997,     71,\n",
      "         20387,   2189,    141,     99, 183124,     23,  58020,      6,      5,\n",
      "             2,      2,    656,  58020,    656, 138438,     13,    656,  17151,\n",
      "           656,  12426,   2765,    656,    113,    656,    527, 110896,    656,\n",
      "         20387,   2189,    141,    656,     23,    656, 183124,    656,      6,\n",
      "             5,    656,      2,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1])\n",
      "tensor([     0, 121220,  14432, 122273,      7,    450,   2412,    290,  27686,\n",
      "            98,   1155,     66,      6,      4,   3129,   5809,   3564,     70,\n",
      "         76755,      6,      5,      2,      2,    656, 121220,    656,    493,\n",
      "         65512,    656,  38985,    656,      6,      4,    656,   1421,    656,\n",
      "          1329,    656,   1155,     66,    656,   1600,  79556,    656,   1256,\n",
      "           656,      6,      4,    656,    509,    656,     68,    656,  93577,\n",
      "           656,   2809,    555,    656,  25482,    656,      6,      5,    656,\n",
      "             2,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_data))[0]) # 0,17151,12456,..\n",
    "print(next(iter(eval_data))[0])#121220,.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_unlabel['len_src'] = df_unlabel['source'].str.split().map(lambda x:len(x))\n",
    "# df_unlabel['len_tar'] = df_unlabel['target'].str.split().map(lambda x:len(x))\n",
    "# print('Source : Max length: {}, Min length: {}, Average Length :  {}'.format(max(df_unlabel['len_tar']),min(df_unlabel['len_tar']),df_unlabel['len_tar'].mean()))\n",
    "\n",
    "# df_unlabel['len_tar'].hist()\n",
    "# df_unlabel[df_unlabel['len_tar']==30].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_data_unlabelled(filePath_src,filePath_tar,len_train_data,df_unlabelled_train,model_type):\n",
    "    \n",
    "#     dataObj = loadUnlabelledDatafromFile(filePath_src,filePath_tar)\n",
    "#     df= dataObj.createDfUnlabelled() # get dataframe from files\n",
    "#     df['len_src'] = df['source'].str.split().map(lambda x:len(x))\n",
    "#     df['len_tar'] = df['target'].str.split().map(lambda x:len(x))\n",
    "    \n",
    "#     df = df[df.len_tar != 36]\n",
    "#     df = df[df.len_tar != 2]\n",
    "#     df = df[df.len_src != 1]\n",
    "    \n",
    "#     df = df.iloc[:,:-2]\n",
    "#     df = df.reset_index(drop=True)\n",
    "#     df_unlabelled_train = df_unlabelled_train.iloc[:,:-2]\n",
    "#     df_new = df.append(df_unlabelled_train, ignore_index = True)\n",
    "#     len_unlabelled_needed = config.fix_train_size - len_train_data\n",
    "#     df_new=df_new[:len_unlabelled_needed]\n",
    "# #     print(df_new)\n",
    "    \n",
    "#     obj_tokenized = createTokenizedDfUnlabelled(df_new,model_type)\n",
    "#     df_unlabelled= obj_tokenized.convertDf()\n",
    "# #     enc_label = preprocessing.LabelEncoder()\n",
    "# #     df_new['labels']= enc_label.fit_transform(df_new['labels'])\n",
    "#     train_data = CompDatasetUnlabelled(df_unlabelled,model_type)\n",
    "#     return df_new,train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_unlabelled(filePath_src,filePath_tar,df_unlabel, unlabel_data_needed, model_type):\n",
    "    \n",
    "    set_seed()\n",
    "    dataObj = loadUnlabelledDatafromFile(filePath_src,filePath_tar)\n",
    "    df= dataObj.createDfUnlabelled() # get dataframe from files\n",
    "    df['len_src'] = df['source'].str.split().map(lambda x:len(x))\n",
    "    df['len_tar'] = df['target'].str.split().map(lambda x:len(x))\n",
    "    \n",
    "    df = df[df.len_tar != 36]\n",
    "    df = df[df.len_tar != 2]\n",
    "    df = df[df.len_src != 1]\n",
    "    \n",
    "    df=df.iloc[:,:-2]\n",
    "#     df=df.iloc[:1000,:]\n",
    "#     df = df[:2000]\n",
    "    if unlabel_data_needed > len(df_unlabel):\n",
    "        \n",
    "        extra_data_needed = unlabel_data_needed - len(df_unlabel) # TAKE IT FROM THE BACKTRANSLATED DATASET\n",
    "        df = df[:extra_data_needed]\n",
    "        df_unlabel = df_unlabel.append(df,ignore_index=True)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        df_unlabel = df_unlabel[:unlabel_data_needed]\n",
    "        \n",
    "    obj_tokenized = createTokenizedDfUnlabelled(df_unlabel,model_type) # change to df\n",
    "    df_new = obj_tokenized.convertDf()\n",
    "#     enc_label = preprocessing.LabelEncoder()\n",
    "#     df_new['labels']= enc_label.fit_transform(df_new['labels'])\n",
    "    train_data = CompDatasetUnlabelled(df_new,model_type)\n",
    "    return df_new,train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([     0, 104431,     56,   1225,  80430,     10,    228,  32775,  35966,\n",
       "              6,      4,  12960, 123573,     31,   4527,      7,     10,  51876,\n",
       "           6967,    136,     10,   4989,  13986,    147,      6,      5,      2,\n",
       "              2,    656, 104431,     56,    656,  45786,    214,     18,    656,\n",
       "            599,    656,    228,  32775,  35966,    656,      6,      4,    656,\n",
       "          31005,    656, 123573,     31,    656,    909,    656,   8643,  16210,\n",
       "          36361,   1479,    656,    165,    656,   1918,    656,   1937,     33,\n",
       "            656,  26530,     56,    656, 190602,    656,      6,      5,    656,\n",
       "              2,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabelled_train, dataset_train_unlabelled = process_data_unlabelled(config.filePath_src_backtranslated,config.filePath_tar_backtranslated,df_unlabel,\n",
    "                                                                       unlabel_data_required, model_type = 'xlm')\n",
    "len_unlabelled_data = len(dataset_train_unlabelled)\n",
    "print(len_unlabelled_data)\n",
    "temp_val = next(iter(dataset_train_unlabelled)) # 31384,..\n",
    "temp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining 2 tuples --> labelled and unlabelled data \n",
    "combined_Data = train_data + dataset_train_unlabelled\n",
    "len(combined_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataloaders\n",
    "loader_obj = createDataloaders(combined_Data,config.TRAIN_BATCH_SIZE)\n",
    "train_dataloader = loader_obj.createDataloaders()\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = next(iter(test_dataloader))\n",
    "# in_id = batch[0].cuda()\n",
    "# att_mask = batch[1].cuda()\n",
    "# labels = batch[2].cuda()\n",
    "# print(in_id,att_mask,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_600_steps_to_1_withDropout_1000_labeled_1000_unlabeled_newTest_data_retest.bin'))\n",
    "# model.eval()\n",
    "# _,op = model(in_id,attention_mask = att_mask)\n",
    "# op.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(eval_data,config.VALID_BATCH_SIZE)\n",
    "val_dataloader = loader_obj.createDataloaders()\n",
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(test_data,config.VALID_BATCH_SIZE)\n",
    "test_dataloader = loader_obj.createDataloaders()\n",
    "len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-03-25 10:08:27.601 pytorch-1-6-gpu-py3-ml-g4dn-xlarge-c630bdb4e3ad8d68ab6e5727a214:31 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-03-25 10:08:27.628 pytorch-1-6-gpu-py3-ml-g4dn-xlarge-c630bdb4e3ad8d68ab6e5727a214:31 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([     0,  20204,    191,   1314,   1295,     70,  30839,    209,    927,\n",
       "         39076,   3089,  26783, 141117,   1799,    191,    613,  18280,   2822,\n",
       "            47,     70,    606,    330,  60636,  70069,      7,      6,      5,\n",
       "             2,      2,    656,   2206,  72450,     13,    656,    224,    656,\n",
       "          4068,    656,  39076,   3089,  26783,    656,  42173,  62339,      7,\n",
       "           656,      6,  65860,    656,    833,    656,    168,    656,   1248,\n",
       "         69418,  26316,    656,  62980,   9022,    656,   5122,    656,      6,\n",
       "             5,    656,      2,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dataloader))\n",
    "batch[0][1] # as seen, combination of labelled and unlabelled data in one training batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, mode='max', min_delta=0, patience=10, percentage=False):\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = 0\n",
    "        self.num_bad_epochs = 0\n",
    "        self.is_better = None\n",
    "        self._init_is_better(mode, min_delta, percentage)\n",
    "\n",
    "        if patience == 0:\n",
    "            self.is_better = lambda a, b: True\n",
    "            self.step = lambda a: False\n",
    "\n",
    "    def step(self, metrics):\n",
    "        if self.best is None:\n",
    "            self.best = metrics\n",
    "            return False\n",
    "\n",
    "        if np.isnan(metrics):\n",
    "            return True\n",
    "\n",
    "        if self.is_better(metrics, self.best):\n",
    "            self.num_bad_epochs = 0\n",
    "            self.best = metrics\n",
    "        else:\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            print('terminating because of early stopping!')\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _init_is_better(self, mode, min_delta, percentage):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError('mode ' + mode + ' is unknown!')\n",
    "        if not percentage:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best \n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best \n",
    "        else:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - (\n",
    "                            best * min_delta / 100)\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + (\n",
    "                            best * min_delta / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNoise(nn.Module):\n",
    "    \n",
    "    def __init__(self, stddev):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.stddev = stddev\n",
    "\n",
    "    def forward(self, din):\n",
    "        \n",
    "        if self.training:\n",
    "            return din + torch.autograd.Variable(torch.randn(din.size()).cuda() * self.stddev)\n",
    "        \n",
    "        return din"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_seed()\n",
    "# a = torch.tensor([[1,2],[3,4]])\n",
    "# a= a.cuda()\n",
    "# noise = GaussianNoise(0.7)\n",
    "# print(noise(a))\n",
    "# # print(torch.randn(a.size()) * 0.7 )\n",
    "# # print(torch.autograd.Variable(torch.randn(a.size()).cuda() * 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,std_gaussian=0.1,with_noise_layer = True, dropout_layer=False, dropout_prob = 0.3):\n",
    "        \n",
    "        super(EntityModel, self).__init__()\n",
    "        \n",
    "        self.std_gaussian = std_gaussian\n",
    "        self.with_noise_layer = with_noise_layer\n",
    "        self.bert = XLMRobertaModel.from_pretrained(config.BASE_MODEL,output_attentions = False, output_hidden_states = False) # , add_pooling_layer=False\n",
    "        self.dropout_layer = dropout_layer\n",
    "        self.dropout_prob = dropout_prob\n",
    "        if self.with_noise_layer:\n",
    "            self.noise = GaussianNoise(stddev=self.std_gaussian)\n",
    "        if self.dropout_layer:\n",
    "            self.bert_drop_1 = nn.Dropout(self.dropout_prob) # remove this or noise \n",
    "        self.out_tag = nn.Linear(768, 2)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "    \n",
    "    def forward(self, ids, attention_mask):\n",
    "        \n",
    "        outputs = self.bert(ids,\n",
    "                            attention_mask = attention_mask,\n",
    "                            return_dict=False)\n",
    "        \n",
    "        if (self.with_noise_layer):\n",
    "            \n",
    "            noise = self.noise(outputs[0]) # 256*768\n",
    "            \n",
    "            if self.dropout_layer:\n",
    "                bo_tag = self.bert_drop_1(noise)\n",
    "                tag = self.out_tag(bo_tag)\n",
    "            else:\n",
    "                tag = self.out_tag(noise)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            if self.dropout_layer:\n",
    "                bo_tag = self.bert_drop_1(outputs[0])\n",
    "                tag = self.out_tag(bo_tag)\n",
    "            \n",
    "            else :\n",
    "                tag = self.out_tag(outputs[0])\n",
    "#         tag = self.out_tag(bo_tag) # 256 * 2 \n",
    "       \n",
    "        softmax_prob = self.softmax(tag)\n",
    "        \n",
    "#         loss_tag = loss_fn(tag,labels,attention_mask)\n",
    "        \n",
    "        return softmax_prob,tag\n",
    "#         return outputs[0], outputs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EntityModel(std_gaussian=config.gaussian_noise_std_student, with_noise_layer=True )\n",
    "# model.cuda()# print(noise ,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs, outputs1 = model(batch[0].cuda(), attention_mask = batch[1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = EntityModel(std_gaussian=config.gaussian_noise_std_teacher)\n",
    "# model2.cuda()\n",
    "# outputs, outputs1 = model2(batch[0].cuda(), attention_mask = batch[1].cuda())\n",
    "# print(outputs,'\\n')\n",
    "# print(outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationCost(output,target,mask):\n",
    "    \n",
    "    \n",
    "    active_loss = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "    active_logits = output.view(-1,2)\n",
    "    \n",
    "    active_labels = torch.where( # just append -100 for the padded tokens so its ignored when computing loss , no need now\n",
    "        active_loss,             # since its handled in preprocessing only\n",
    "        target.view(-1),\n",
    "        torch.tensor(-100).type_as(target)    \n",
    "    )\n",
    "    try:\n",
    "        class_0_weights =1/len(torch.where(active_labels==0)[0]) # trying to weight the labels as its unbalanced mostly\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        class_0_weights = float(1)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        class_1_weights =1/len(torch.where(active_labels==1)[0])\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        class_1_weights = float(1)\n",
    "    \n",
    "    weights_tensor = torch.tensor([class_0_weights,class_1_weights]).cuda()\n",
    "    lfn = nn.CrossEntropyLoss(weight = weights_tensor)\n",
    "    loss = lfn(active_logits,active_labels)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([[0.2,0.5],[0.9,0.4],[0.9,0.2],[0.2,0.9],[0.7,0.4]])\n",
    "# b = torch.tensor([-100,-100,-100,-100,-100])\n",
    "# c = torch.tensor([1,1,1,1,1])\n",
    "# ClassificationCost(a,b,c).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConsistencyCost(student_output, teacher_output,mask,scale=10):\n",
    "    \n",
    "    assert len(student_output) == len(teacher_output)\n",
    "    \n",
    "    loss = nn.MSELoss()\n",
    "    active_outputs = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "    flattened_outputs_student = student_output.view(-1,2)\n",
    "    flatenned_outputs_teacher = teacher_output.view(-1,2)\n",
    "\n",
    "    active_outputs_teacher=flatenned_outputs_teacher[torch.where(mask.view(-1) == 1)]\n",
    "    active_outputs_student=flattened_outputs_student[torch.where(mask.view(-1) == 1)]\n",
    "    \n",
    "    return scale * loss(active_outputs_student.view(-1),active_outputs_teacher.view(-1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ConsistencyCost(student_output, teacher_output,mask):\n",
    "    \n",
    "#     assert len(student_output) == len(teacher_output)\n",
    "    \n",
    "#     loss = nn.MSELoss()\n",
    "#     active_outputs = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "#     flattened_outputs_student = student_output.view(-1,2)\n",
    "#     flatenned_outputs_teacher = teacher_output.view(-1,2)\n",
    "    \n",
    "#     # [0.2,0.8] , [0.3,0.7] , [0.9,0.1] -> s\n",
    "#     # [0.7,0.3] , [0.9,0.1] , [0.8,0.2] -> T \n",
    "    \n",
    "    \n",
    "    \n",
    "#     pseudo_label = torch.softmax(logits_u_w.detach()/args.T, dim=-1)\n",
    "#     max_probs, targets_u = torch.max(pseudo_label, dim=-1)\n",
    "#     mask = max_probs.ge(config.threshold).float()\n",
    "\n",
    "#     Lu = (F.cross_entropy(logits_u_s, targets_u,\n",
    "#                                   reduction='none') * mask)\n",
    "    \n",
    "#     active_outputs_teacher=flatenned_outputs_teacher[torch.where(active_outputs == 1)]\n",
    "#     active_outputs_student=flattened_outputs_student[torch.where(active_outputs == 1)]\n",
    "    \n",
    "#     return torch.sqrt(loss(active_outputs_student,active_outputs_teacher))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update teacher to be exponential moving average of student params.\n",
    "def update_teacher_params(student_model, teacher_model, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    \n",
    "    teacher_params = teacher_model.parameters()\n",
    "    student_params = student_model.parameters()\n",
    "    \n",
    "    assert sum(p.numel() for p in student_model.parameters()) == sum(p.numel() for p in teacher_model.parameters())\n",
    "    \n",
    "#     alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    \n",
    "#     if global_step == 10 or global_step==20 or global_step == 30:\n",
    "#         print(alpha)\n",
    "    \n",
    "    for teacher_param, student_param in zip(teacher_params, student_params):\n",
    "            teacher_param.data.mul_(alpha).add_(1 - alpha, student_param.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_train_accuracy():\n",
    "            \n",
    "            labels = b_labels_eval.view(-1) \n",
    "            active_logits = output.view(-1, 2)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "            active_accuracy = labels.view(-1) != -100\n",
    "            labels_tmp = torch.masked_select(labels, active_accuracy) \n",
    "            pred_tmp = torch.masked_select(flattened_predictions, active_accuracy) \n",
    "            lst_active_labels.extend(labels_tmp.tolist())\n",
    "            lst_active_preds.extend(pred_tmp.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, optimizer,scheduler, student_model, teacher_model ,writer, global_step, epoch):\n",
    "    \n",
    "    student_model.train() # put student model in training mode\n",
    "    teacher_model.train()\n",
    "    total_train_loss = 0\n",
    "    consistency_cst = 0\n",
    "    classification_cst_student=0\n",
    "    classification_cst_teacher=0\n",
    "    classification_cst_lst = []\n",
    "    consistency_cst_lst = []\n",
    "    overall_cst_lst = []\n",
    "#     global_step = 0\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(train_dataloader, total = len(train_dataloader),position = 0 , leave = True)):\n",
    "\n",
    "            \n",
    "        b_input_ids = batch[0].cuda()\n",
    "        b_input_mask = batch[1].cuda()\n",
    "        b_labels = batch[2].cuda()\n",
    "     \n",
    "        \n",
    "        output_student_softmax, output_student_logit = student_model( b_input_ids, attention_mask = b_input_mask )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "                output_teacher_softmax, output_teacher_logit = teacher_model( b_input_ids, attention_mask = b_input_mask )\n",
    "          \n",
    "        \n",
    "        classification_cost_student =  ClassificationCost(output_student_logit,b_labels,b_input_mask)\n",
    "        classification_cst_student+=classification_cost_student.item()\n",
    "        \n",
    "        classification_cost_teacher =  ClassificationCost(output_teacher_logit,b_labels,b_input_mask)\n",
    "        classification_cst_teacher+=classification_cost_teacher.item()\n",
    "        \n",
    "        writer.add_scalar('TrainingLoss/Classification', classification_cost_student.item(), global_step)\n",
    "        \n",
    "        consistency_cost = ConsistencyCost(output_student_softmax,output_teacher_softmax.detach(),b_input_mask,scale=10)\n",
    "        consistency_cst+=consistency_cost.item()\n",
    "        \n",
    "        writer.add_scalar('TrainingLoss/Consistency', consistency_cost.item(), global_step)\n",
    "        \n",
    "#         overall_cost = (config.ratio * classification_cost) + ((1 - config.ratio) * consistency_cost)\n",
    "        \n",
    "        overall_cost =  classification_cost_student + get_consistency_weight(global_step) * consistency_cost\n",
    "        \n",
    "        writer.add_scalar('TrainingLoss/Overall', overall_cost.item(), global_step)\n",
    "        \n",
    "        total_train_loss+=overall_cost.item()\n",
    "\n",
    "        overall_cost.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        update_teacher_params(student_model , teacher_model , config.alpha,global_step)\n",
    "\n",
    "        if (len(train_dataloader) < 200):\n",
    "            if step % 50 == 0 and step!=0:\n",
    "                print ('train loss : ', total_train_loss/step)\n",
    "                print('Consistency Cost :', consistency_cst/step)\n",
    "                print('Classification Cost :', classification_cst_student/step)\n",
    "                print('Consistency Weight is:', get_consistency_weight(global_step))\n",
    "        else:\n",
    "            if step % 200 == 0 and step!=0:\n",
    "                print ('train loss : ', total_train_loss/step)\n",
    "                print('Consistency Cost :', consistency_cst/step)\n",
    "                print('Classification Cost :', classification_cst_student/step)\n",
    "                print('Consistency Weight is:', get_consistency_weight(global_step))\n",
    "\n",
    "        \n",
    "        global_step+=1\n",
    "        \n",
    "    return (consistency_cst/len(train_dataloader), classification_cst_student/len(train_dataloader), total_train_loss/len(train_dataloader),global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def soft_frequency(logits, power=2, probs=False):\n",
    "#     \"\"\"\n",
    "#     Unsupervised Deep Embedding for Clustering Analysis\n",
    "#     https://arxiv.org/abs/1511.06335\n",
    "#     \"\"\"\n",
    "#     if not probs:\n",
    "#         softmax = torch.nn.Softmax(dim=1)\n",
    "#         y = softmax(logits.view(-1, logits.shape[-1])).view(logits.shape)\n",
    "#     else:\n",
    "#         y = logits\n",
    "#     f = torch.sum(y, dim=(0, 1))\n",
    "#     t = y**power / f\n",
    "#     p = t/torch.sum(t, dim=2, keepdim=True)\n",
    "\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = torch.tensor([[[0.3,0.7] , [0.2,0.8] , [0.5569,0.5]]])\n",
    "# f = torch.sum(logits, dim=(0,1))\n",
    "# print(f)\n",
    "# new_logits = soft_frequency(logits,probs = True)\n",
    "# # t = logits**2 / f\n",
    "# # print(t.shape)\n",
    "# # p = t/torch.sum(t, dim=2, keepdim=True)\n",
    "# # p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax = torch.nn.Softmax(dim=1)\n",
    "# y = softmax(new_logits.view(-1, new_logits.shape[-1])).view(new_logits.shape)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _confidence = y.max(dim=-1)[0]\n",
    "# _confidence[0]\n",
    "# # torch.where(_confidence[0]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    lst_active_preds = []\n",
    "    lst_active_labels = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in tqdm(test_loader,total = len(test_loader),position = 0 , leave = True):            \n",
    "            b_input_ids_eval = batch[0].cuda()\n",
    "            b_input_mask_eval = batch[1].cuda()\n",
    "            b_labels_eval = batch[2].cuda()\n",
    "            \n",
    "            _, output= model(b_input_ids_eval,attention_mask = b_input_mask_eval)\n",
    "            \n",
    "            classification_cost =  ClassificationCost(output,b_labels_eval,b_input_mask_eval)\n",
    "            test_loss+=classification_cost\n",
    "            \n",
    "            labels = b_labels_eval.view(-1) \n",
    "            active_logits = output.view(-1, 2)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "            active_accuracy = labels.view(-1) != -100\n",
    "            labels_tmp = torch.masked_select(labels, active_accuracy) \n",
    "            pred_tmp = torch.masked_select(flattened_predictions, active_accuracy) \n",
    "            lst_active_labels.extend(labels_tmp.tolist())\n",
    "            lst_active_preds.extend(pred_tmp.tolist())\n",
    "            \n",
    "    avg_f1_score_0=f1_score(lst_active_labels,lst_active_preds,average='binary',pos_label = 0)\n",
    "    avg_f1_score_1=f1_score(lst_active_labels,lst_active_preds,average='binary',pos_label = 1)\n",
    "    avg_accuracy_score=accuracy_score(lst_active_labels,lst_active_preds)\n",
    "    avg_mcc_score = matthews_corrcoef(lst_active_labels,lst_active_preds)\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    print('Overall validation loss:', test_loss)\n",
    "    print('Average F1 Validation score for whole sentence class 0 :' ,avg_f1_score_0)\n",
    "    print('Average F1 Validation score for whole sentence class 1 :' ,avg_f1_score_1)\n",
    "    print('Average Accuracy Validation score whole sentence  :' ,avg_accuracy_score)\n",
    "    print('Average mcc Validation score whole sentence :' ,avg_mcc_score)\n",
    "    print('Classification Report :'+'\\n', classification_report(lst_active_labels,lst_active_preds))\n",
    "\n",
    "    return (test_loss, avg_f1_score_0 , avg_f1_score_1, avg_accuracy_score, avg_mcc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MeanTeacher(train_dataloader, val_dataloader,len_labelled_data ,len_unlabelled_data, writer,early_stopping,dropout_layer = False, noise_layer=True):\n",
    "    \n",
    "    exp_name = input('Enter Experiment name :')\n",
    "    model_name = input('Enter name for saving the models with version :')\n",
    "    \n",
    "    global_step = 0\n",
    "    best_mcc_teacher = -1\n",
    "    best_mcc_student = -1\n",
    "    # train losses\n",
    "    epochs_consistency_lst =[]\n",
    "    epochs_classification_lst = []\n",
    "    epochs_overall_lst = []\n",
    "    \n",
    "    #test metrices for student\n",
    "    epochs_f1_score_0_lst_student = []\n",
    "    epochs_f1_score_1_lst_student = []\n",
    "    epochs_accuracy_lst_student = []\n",
    "    epochs_mcc_lst_student = []\n",
    "    epochs_cost_lst_student=[]\n",
    "    \n",
    "    #test metrices for teacher\n",
    "    epochs_f1_score_0_lst_teacher= []\n",
    "    epochs_f1_score_1_lst_teacher = []\n",
    "    epochs_accuracy_lst_teacher = []\n",
    "    epochs_mcc_lst_teacher = []\n",
    "    epochs_cost_lst_teacher=[]\n",
    "    \n",
    "    set_seed()\n",
    "    #initialaize the language models\n",
    "    student = EntityModel(std_gaussian=config.gaussian_noise_std_student, with_noise_layer=noise_layer,dropout_layer=dropout_layer) \n",
    "    teacher = EntityModel(std_gaussian=config.gaussian_noise_std_teacher, with_noise_layer=noise_layer)\n",
    "#     student.load_state_dict(torch.load('../models/training_data/model_xlmrobertatokenclassificationmodel_verylessData_weightedlss.bin'))\n",
    "#     teacher.load_state_dict(torch.load('../models/training_data/model_xlmrobertatokenclassificationmodel_verylessData_weightedlss.bin'))\n",
    "    student.cuda() # take model to gpu\n",
    "    teacher.cuda()\n",
    "#     teacher.eval()\n",
    "    param_optimizer_student = list(student.named_parameters())\n",
    "    param_teacher = list(teacher.named_parameters())\n",
    "    \n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer_student if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer_student if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "    optimizer = AdamW(optimizer_parameters, lr=config.lr)\n",
    "    num_train_steps = int(len(train_dataloader) * config.EPOCHS)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "#         optimizer, T_max=num_train_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n",
    "    set_seed() # setting seed again before training\n",
    "    \n",
    "    with open(f'../Logs/{exp_name}.txt', 'w') as f:\n",
    "        f.write(f'{exp_name}'+'\\n')\n",
    "        for epoch in range(0,config.EPOCHS):\n",
    "            print(f'Current epoch is {epoch+1} of {config.EPOCHS}')\n",
    "\n",
    "            consistency_cost , classification_cost , overall_cost, global_step = train(train_dataloader, optimizer,scheduler,student,teacher,writer,global_step,epoch)\n",
    "\n",
    "            writer.add_scalar('TrainingLoss/Consistency_epoch :', consistency_cost,epoch )\n",
    "            writer.add_scalar('TrainingLoss/Classification_epoch', classification_cost,epoch)\n",
    "            writer.add_scalar('TrainingLoss/Overall_epoch',overall_cost,epoch)\n",
    "\n",
    "            epochs_consistency_lst.append(consistency_cost)\n",
    "            epochs_classification_lst.append(classification_cost)\n",
    "            epochs_overall_lst.append(overall_cost)\n",
    "\n",
    "        \n",
    "            print('---------Running validation for student -------------')\n",
    "            test_loss_student, avg_f1_score_0_student, avg_f1_score_1_student, avg_accuracy_score_student, avg_mcc_score_student = test(student,val_dataloader)\n",
    "\n",
    "            epochs_f1_score_0_lst_student.append(avg_f1_score_0_student)\n",
    "            epochs_f1_score_1_lst_student.append(avg_f1_score_1_student)\n",
    "            epochs_accuracy_lst_student.append(avg_accuracy_score_student)\n",
    "            epochs_mcc_lst_student.append(avg_mcc_score_student)\n",
    "            epochs_cost_lst_student.append(test_loss_student)\n",
    "\n",
    "            writer.add_scalar('mcc_score/Student',avg_mcc_score_student,epoch)\n",
    "            writer.add_scalar('ValidationLoss/Student',test_loss_student,epoch)\n",
    "\n",
    "\n",
    "            for name, weight in student.named_parameters():\n",
    "\n",
    "                if name == 'bert.embeddings.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.0.attention.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.1.attention.output.dense.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.2.output.dense.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.5.attention.self.key.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.9.attention.self.key.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.10.attention.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bbert.encoder.layer.11.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'out_tag.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "\n",
    "            if float(\"{:.2f}\".format(avg_mcc_score_student)) >  best_mcc_student :\n",
    "                    torch.save(student.state_dict(), f'../models/MeanTeacher_models/StudentModels/studentModel_{model_name}.bin')\n",
    "                    best_mcc_student = float(\"{:.3f}\".format(avg_mcc_score_student))\n",
    "\n",
    "            print('---------Running validation for teacher -------------')\n",
    "\n",
    "            test_loss_teacher, avg_f1_score_0_teacher, avg_f1_score_1_teacher, avg_accuracy_score_teacher, avg_mcc_score_teacher=test(teacher,val_dataloader)\n",
    "\n",
    "            epochs_f1_score_0_lst_teacher.append(avg_f1_score_1_teacher)\n",
    "            epochs_f1_score_1_lst_teacher.append(avg_f1_score_0_teacher)\n",
    "            epochs_accuracy_lst_teacher.append(avg_accuracy_score_teacher)\n",
    "            epochs_mcc_lst_teacher.append(avg_mcc_score_teacher)\n",
    "            epochs_cost_lst_teacher.append(test_loss_teacher)\n",
    "\n",
    "            writer.add_scalar('mcc_score/Teacher',avg_mcc_score_teacher,epoch)\n",
    "            writer.add_scalar('ValidationLoss/Teacher',test_loss_teacher,epoch)\n",
    "\n",
    "            f.write(f\"Consistency_loss {epoch+1} : {str(consistency_cost)}\" + '\\n')\n",
    "            f.write(f\"Classification_loss {epoch+1} : {str(classification_cost)}\" + '\\n')\n",
    "            f.write(f\"Overall_loss {epoch+1} : {str(overall_cost)}\" + '\\n')\n",
    "            f.write(f\"'mcc_score/Teacher {epoch+1} : {str(avg_mcc_score_teacher)}\" + '\\n')\n",
    "            f.write(f\"ValidationLoss/Teacher {epoch+1} : {str(test_loss_teacher)}\" + '\\n')\n",
    "            f.write(f\"'mcc_score/Student {epoch+1} : {str(avg_mcc_score_student)}\" + '\\n')\n",
    "            f.write(f\"ValidationLoss/Student {epoch+1} : {str(test_loss_student)}\" + '\\n')\n",
    "\n",
    "            for name, weight in teacher.named_parameters():\n",
    "                if name == 'bert.embeddings.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.0.attention.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.1.attention.output.dense.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name =='bert.encoder.layer.2.output.dense.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.5.attention.self.key.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.9.attention.self.key.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bert.encoder.layer.10.attention.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'bbert.encoder.layer.11.output.LayerNorm.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "                if name == 'out_tag.weight':\n",
    "                    writer.add_histogram(name,weight, epoch)\n",
    "\n",
    "\n",
    "            if float(\"{:.2f}\".format(avg_mcc_score_teacher)) >  best_mcc_teacher :\n",
    "                    torch.save(teacher.state_dict(), f'../models/MeanTeacher_models/TeacherModels/teacherModel_{model_name}.bin')\n",
    "                    best_mcc_teacher = float(\"{:.3f}\".format(avg_mcc_score_teacher))        \n",
    "\n",
    "\n",
    "            if early_stopping.step(float(\"{:.2f}\".format(avg_mcc_score_teacher))): #mcc score for early stopping \"{:.2f}\".format(a_float)\n",
    "                      break \n",
    "\n",
    "           \n",
    "    writer.flush()  \n",
    "    writer.close()    \n",
    "    return (epochs_consistency_lst,epochs_classification_lst,epochs_overall_lst,epochs_f1_score_0_lst_student,epochs_f1_score_1_lst_student,\n",
    "           epochs_accuracy_lst_student,epochs_mcc_lst_student,epochs_cost_lst_student,epochs_f1_score_0_lst_teacher,epochs_f1_score_1_lst_teacher,\n",
    "            epochs_accuracy_lst_teacher,epochs_mcc_lst_teacher,epochs_cost_lst_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EntityModel()\n",
    "# model.cuda()\n",
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_600_steps_to_1_withDropout_500_labeled_1500_unlabeled_newTest_data.bin'))\n",
    "# model.eval()\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EntityModel() # with adjusted alpha val\n",
    "# model.cuda()\n",
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_600_steps_to_1_withDropout_500_labeled_1500_unlabeled_newTest_data_alpha_min_initialsteps.bin'))\n",
    "# model.eval()\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_600_steps_to_1_withDropout_500_labeled_1500_unlabeled_newTest_data_alpha_min_initialsteps.bin'))\n",
    "# model.eval()\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "# # StudentModels/studentModel_v1_rampup_const_cost_600_steps_to_1_withDropout_500_labeled_1500_unlabeled_newTest_data_alpha_min_initialsteps.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = EntityModel() # with adjusted alpha valuw : 500,500\n",
    "# # model.cuda()\n",
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_300_steps_to_1_withDropout_500_labeled_500_unlabeled_newTest_data_alpha_min_initialsteps.bin'))\n",
    "# model.eval()\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_450_steps_to_1_withDropout_500_labeled_1500_unlabeled_newTest_data_alpha_min_initialsteps.bin'))\n",
    "# model.eval()\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EntityModel() # with adjusted alpha valuw : 1000,1000\n",
    "# model.cuda()\n",
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_600_steps_to_1_withDropout_1000_labeled_1000_unlabeled_newTest_data.bin'))\n",
    "# model.eval()\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model = EntityModel() # : 1000,1000\n",
    "# # model.cuda()\n",
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_600_steps_to_1_withDropout_1000_labeled_1000_unlabeled_newTest_data.bin'))\n",
    "# model.eval()\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "# Thesis/src/code/models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_750_steps_to_1_withDropout_1000_labeled_1500_unlabeled_newTest_data.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_750_steps_to_1_withDropout_1000_labeled_1500_unlabeled_newTest_data.bin'))\n",
    "# model.eval() # for 1k, 1.5k data- teacher model\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_750_steps_to_1_withDropout_1000_labeled_1500_unlabeled_newTest_data.bin'))\n",
    "# model.eval()\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_900_steps_to_1_withDropout_1000_labeled_2000_unlabeled_newTest_data.bin'))\n",
    "# model.eval() # for 1k, 2.0 k data- teacher model\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "# # Thesis/src/code/models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_900_steps_to_1_withDropout_1000_labeled_2000_unlabeled_newTest_data.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_900_steps_to_1_withDropout_1000_labeled_2000_unlabeled_newTest_data.bin'))\n",
    "# model.eval()# STUDENT FOR 1K,2K SET\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_1200_steps_to_1_withDropout_2000_labeled_2000_unlabeled_newTest_data.bin'))\n",
    "# model.eval() # for 2k, 2.0 k data- teacher model\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "# # Thesis/src/code/models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_1200_steps_to_1_withDropout_2000_labeled_2000_unlabeled_newTest_data.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_1200_steps_to_1_withDropout_2000_labeled_2000_unlabeled_newTest_data.bin'))\n",
    "# model.eval()# STUDENT FOR 2K,2K SET\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "# # Thesis/src/code/models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_1200_steps_to_1_withDropout_2000_labeled_2000_unlabeled_newTest_data.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_1200_steps_to_1_withDropout_1000_labeled_3000_unlabeled_newTest_data_retest.bin'))\n",
    "# model.eval()# STUDENT FOR 2K,2K SET\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(test_metrics[26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(test_metrics[27],test_metrics[28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_900_steps_to_1_withDropout_2000_labeled_1000_unlabeled_newTest_data.bin'))\n",
    "# model.eval() # for 2k, 1.0 k data- teacher model\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_600_steps_to_1_withDropout_1000_labeled_1000_unlabeled_newTest_data_retest.bin'))\n",
    "# model.eval() # for 1k, 1.0 k data- teacher model -- less seq len\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_600_steps_to_1_withDropout_1000_labeled_1000_unlabeled_newTest_data_retest.bin'))\n",
    "# model.eval()# STUDENT FOR 2K,2K SET\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_600_steps_to_1_withDropout_1000_labeled_1000_unlabeled_newTest_data_retest.bin'))\n",
    "# model.eval()# STUDENT FOR 2K,2K SET\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_tokens = np.array(test_metrics[27])\n",
    "# print(len(np.where(check_tokens==0)[0]))\n",
    "# check_tokens_p = np.array(test_metrics[28])\n",
    "# print(len(np.where(check_tokens_p==0)[0]))\n",
    "# print(len(test_metrics[27]))\n",
    "# print(len(test_metrics[28]))\n",
    "# print(classification_report(test_metrics[27], test_metrics[28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # 1k , 1k again testing \n",
    "# model = EntityModel() # with adjusted alpha valuw : 1000,1000\n",
    "# model.cuda()\n",
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_600_steps_to_1_withDropout_1000_labeled_1000_unlabeled_newTest_data_retest_less_seq_len.bin'))\n",
    "# model.eval() # for 1k, 1.0 k data- teacher model -- less seq len\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_6750_steps_to_1_withDropout_1500_labeled_1000_unlabeled_newTest_data_retest_less_seq_len.bin'))\n",
    "# model.eval() # for 1k, 1.5 k data- teacher model -- less seq len\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_6750_steps_to_1_withDropout_1500_labeled_1000_unlabeled_newTest_data_retest_less_seq_len.bin'))\n",
    "# model.eval() # for 1k, 1.0 k data- teacher model -- less seq len\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_900_steps_to_1_withDropout_1000_labeled_2000_unlabeled_newTest_data_retest_less_seq_len.bin'))\n",
    "# model.eval() # for 1k, 2.0 k data- teacher model -- less seq len\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "# # Thesis/src/code/models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_900_steps_to_1_withDropout_1000_labeled_2000_unlabeled_newTest_data_retest_less_seq_len.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_900_steps_to_1_withDropout_1000_labeled_2000_unlabeled_newTest_data_retest_less_seq_len.bin'))\n",
    "# model.eval() # for 1k, 2.0 k data- teacher model -- less seq len\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_300_steps_to_1_withDropout_500_labeled_500_unlabeled_newTest_data_retest_less_seq_len.bin'))\n",
    "# model.eval() # for 0.5k, 0.5 k data- teacher model -- less seq len\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EntityModel() # with adjusted alpha val\n",
    "# model.cuda()\n",
    "# model.load_state_dict(torch.load('../models/MeanTeacher_models/StudentModels/studentModel_v1_rampup_const_cost_300_steps_to_1_withDropout_500_labeled_500_unlabeled_newTest_data_retest_less_seq_len.bin'))\n",
    "# model.eval() # for 1k, 1.0 k data- teacher model -- less seq len\n",
    "# test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_tokens = np.array(test_metrics[27])\n",
    "# print(len(np.where(check_tokens==0)[0]))\n",
    "# check_tokens_p = np.array(test_metrics[28])\n",
    "# print(len(np.where(check_tokens_p==0)[0]))\n",
    "# print(len(test_metrics[27]))\n",
    "# print(len(test_metrics[28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MeanTeacher_initWithsuptrainedmodel_withConsistencyRampup_for_5_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-5aca671afad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMeanTeacher_initWithsuptrainedmodel_withConsistencyRampup_for_5_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mMeanTeacher_withConsistencyRampup_for_1500_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mteacherModel_v1_rampup_const_cost_1500_steps_withDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mv1_initSupModel_rampup_const_cost_5_epochs_withDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mMeanTeacher_withConsistencyRampup_for_600_steps_to_1_1000_labeled_1000_unlabeled_alpha_adjusted_check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MeanTeacher_initWithsuptrainedmodel_withConsistencyRampup_for_5_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "MeanTeacher_initWithsuptrainedmodel_withConsistencyRampup_for_5_epochs\n",
    "MeanTeacher_withConsistencyRampup_for_1500_steps\n",
    "teacherModel_v1_rampup_const_cost_1500_steps_withDropout\n",
    "v1_initSupModel_rampup_const_cost_5_epochs_withDropout\n",
    "MeanTeacher_withConsistencyRampup_for_500_steps_to_1_250_labeled_1750_unlabeled\n",
    "v1_rampup_const_cost_500_steps_to_1_withDropout_250_labeled_1750_unlabeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/MeanTeacherTraining/with_250_labelled_and_1750_unlabeled_data_rampup_steps_dropout_0.995_v01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config = reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Experiment name : MeanTeacher_withConsistencyRampup_for_500_steps_to_1_250_labeled_1750_unlabeled\n",
      "Enter name for saving the models with version : v1_rampup_const_cost_500_steps_to_1_withDropout_250_labeled_1750_unlabeled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 1 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /codebuild/output/src811146734/src/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  app.launch_new_instance()\n",
      " 80%|████████  | 201/250 [01:12<00:18,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.43865190056851133\n",
      "Consistency Cost : 0.3676225742697716\n",
      "Classification Cost : 0.4190418979525566\n",
      "Consistency Weight is: 0.16529888822158656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:31<00:00,  2.74it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:03<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6065, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.34060410872005076\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7243313817091331\n",
      "Average Accuracy Validation score whole sentence  : 0.6112038209230061\n",
      "Average mcc Validation score whole sentence : 0.2506141155693589\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.79      0.34      4418\n",
      "           1       0.95      0.59      0.72     30338\n",
      "\n",
      "    accuracy                           0.61     34756\n",
      "   macro avg       0.58      0.69      0.53     34756\n",
      "weighted avg       0.86      0.61      0.68     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6440, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3297844715658271\n",
      "Average F1 Validation score for whole sentence class 1 : 0.809196421970873\n",
      "Average Accuracy Validation score whole sentence  : 0.7029577626884567\n",
      "Average mcc Validation score whole sentence : 0.21243783266017438\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.57      0.33      4418\n",
      "           1       0.92      0.72      0.81     30338\n",
      "\n",
      "    accuracy                           0.70     34756\n",
      "   macro avg       0.58      0.65      0.57     34756\n",
      "weighted avg       0.83      0.70      0.75     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 2 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:16<00:19,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.5324998285993934\n",
      "Consistency Cost : 0.20145253077149392\n",
      "Classification Cost : 0.4083194068074226\n",
      "Consistency Weight is: 0.951229424500714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:36<00:00,  2.60it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6195, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3556815654881032\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7750562844499651\n",
      "Average Accuracy Validation score whole sentence  : 0.6665323972839222\n",
      "Average mcc Validation score whole sentence : 0.2609889576833471\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.72      0.36      4418\n",
      "           1       0.94      0.66      0.78     30338\n",
      "\n",
      "    accuracy                           0.67     34756\n",
      "   macro avg       0.59      0.69      0.57     34756\n",
      "weighted avg       0.85      0.67      0.72     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6305, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3542329933077773\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8163559431643908\n",
      "Average Accuracy Validation score whole sentence  : 0.7140349867648751\n",
      "Average mcc Validation score whole sentence : 0.24737792915608364\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.62      0.35      4418\n",
      "           1       0.93      0.73      0.82     30338\n",
      "\n",
      "    accuracy                           0.71     34756\n",
      "   macro avg       0.59      0.67      0.59     34756\n",
      "weighted avg       0.84      0.71      0.76     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 3 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:19<00:19,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.5380629133805632\n",
      "Consistency Cost : 0.1597109493240714\n",
      "Classification Cost : 0.37835196435451507\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:38<00:00,  2.54it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6244, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3626969337624937\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8696149447197865\n",
      "Average Accuracy Validation score whole sentence  : 0.7835193923351363\n",
      "Average mcc Validation score whole sentence : 0.2537454418462365\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.48      0.36      4418\n",
      "           1       0.92      0.83      0.87     30338\n",
      "\n",
      "    accuracy                           0.78     34756\n",
      "   macro avg       0.60      0.66      0.62     34756\n",
      "weighted avg       0.84      0.78      0.81     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6221, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3656227239621267\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8438564411458894\n",
      "Average Accuracy Validation score whole sentence  : 0.7493957877776499\n",
      "Average mcc Validation score whole sentence : 0.2586744370747739\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.57      0.37      4418\n",
      "           1       0.93      0.78      0.84     30338\n",
      "\n",
      "    accuracy                           0.75     34756\n",
      "   macro avg       0.60      0.67      0.60     34756\n",
      "weighted avg       0.84      0.75      0.78     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 4 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:18<00:19,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.5195517300069332\n",
      "Consistency Cost : 0.1484193829074502\n",
      "Classification Cost : 0.3711323481798172\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:38<00:00,  2.55it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5984, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3725971961266079\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8440564716025435\n",
      "Average Accuracy Validation score whole sentence  : 0.7502014040741167\n",
      "Average mcc Validation score whole sentence : 0.268281227313873\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.37      4418\n",
      "           1       0.93      0.77      0.84     30338\n",
      "\n",
      "    accuracy                           0.75     34756\n",
      "   macro avg       0.60      0.68      0.61     34756\n",
      "weighted avg       0.84      0.75      0.78     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6150, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3704556670505017\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8665481047529379\n",
      "Average Accuracy Validation score whole sentence  : 0.7797790309586834\n",
      "Average mcc Validation score whole sentence : 0.263273337759238\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.51      0.37      4418\n",
      "           1       0.92      0.82      0.87     30338\n",
      "\n",
      "    accuracy                           0.78     34756\n",
      "   macro avg       0.61      0.66      0.62     34756\n",
      "weighted avg       0.84      0.78      0.80     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 5 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:18<00:19,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.4194068556651473\n",
      "Consistency Cost : 0.1377548038214445\n",
      "Classification Cost : 0.281652053296566\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:37<00:00,  2.55it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6105, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3686803607973925\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8521103002539108\n",
      "Average Accuracy Validation score whole sentence  : 0.760357923811716\n",
      "Average mcc Validation score whole sentence : 0.2617672460205885\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.55      0.37      4418\n",
      "           1       0.92      0.79      0.85     30338\n",
      "\n",
      "    accuracy                           0.76     34756\n",
      "   macro avg       0.60      0.67      0.61     34756\n",
      "weighted avg       0.84      0.76      0.79     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6179, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3629575669276998\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8804715530497181\n",
      "Average Accuracy Validation score whole sentence  : 0.7987110139256531\n",
      "Average mcc Validation score whole sentence : 0.25569180651412177\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.45      0.36      4418\n",
      "           1       0.91      0.85      0.88     30338\n",
      "\n",
      "    accuracy                           0.80     34756\n",
      "   macro avg       0.61      0.65      0.62     34756\n",
      "weighted avg       0.84      0.80      0.81     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 6 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:19<00:19,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.34454438094049694\n",
      "Consistency Cost : 0.12831309888511896\n",
      "Classification Cost : 0.21623128218576312\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:38<00:00,  2.54it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6757, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3306113440741558\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8996526054590571\n",
      "Average Accuracy Validation score whole sentence  : 0.825468983772586\n",
      "Average mcc Validation score whole sentence : 0.23043046965943706\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.34      0.33      4418\n",
      "           1       0.90      0.90      0.90     30338\n",
      "\n",
      "    accuracy                           0.83     34756\n",
      "   macro avg       0.61      0.62      0.62     34756\n",
      "weighted avg       0.83      0.83      0.83     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6324, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.36065251572327045\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8903532425508965\n",
      "Average Accuracy Validation score whole sentence  : 0.812809299113822\n",
      "Average mcc Validation score whole sentence : 0.25627602735689836\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.42      0.36      4418\n",
      "           1       0.91      0.87      0.89     30338\n",
      "\n",
      "    accuracy                           0.81     34756\n",
      "   macro avg       0.61      0.64      0.63     34756\n",
      "weighted avg       0.84      0.81      0.82     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 7 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:19<00:19,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.29665171425789594\n",
      "Consistency Cost : 0.11678505048155785\n",
      "Classification Cost : 0.17986666226759554\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:38<00:00,  2.54it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6679, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3275547445255475\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9029369155801396\n",
      "Average Accuracy Validation score whole sentence  : 0.8303602255725631\n",
      "Average mcc Validation score whole sentence : 0.23050741872995872\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33      4418\n",
      "           1       0.90      0.90      0.90     30338\n",
      "\n",
      "    accuracy                           0.83     34756\n",
      "   macro avg       0.62      0.61      0.62     34756\n",
      "weighted avg       0.83      0.83      0.83     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6547, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3499682808204694\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8976254704099643\n",
      "Average Accuracy Validation score whole sentence  : 0.8231096789043618\n",
      "Average mcc Validation score whole sentence : 0.2488268802923497\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.37      0.35      4418\n",
      "           1       0.91      0.89      0.90     30338\n",
      "\n",
      "    accuracy                           0.82     34756\n",
      "   macro avg       0.62      0.63      0.62     34756\n",
      "weighted avg       0.83      0.82      0.83     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 8 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:19<00:19,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.27762829571962355\n",
      "Consistency Cost : 0.11388053327798843\n",
      "Classification Cost : 0.16374776259995996\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [01:38<00:00,  2.54it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6759, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3433303039482985\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8909057357110503\n",
      "Average Accuracy Validation score whole sentence  : 0.8128956151455864\n",
      "Average mcc Validation score whole sentence : 0.23758561221687988\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.38      0.34      4418\n",
      "           1       0.91      0.88      0.89     30338\n",
      "\n",
      "    accuracy                           0.81     34756\n",
      "   macro avg       0.61      0.63      0.62     34756\n",
      "weighted avg       0.83      0.81      0.82     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:04<00:00, 14.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6969, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.33139664804469277\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9011921667051946\n",
      "Average Accuracy Validation score whole sentence  : 0.8278282886408103\n",
      "Average mcc Validation score whole sentence : 0.2326320755247104\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.34      0.33      4418\n",
      "           1       0.90      0.90      0.90     30338\n",
      "\n",
      "    accuracy                           0.83     34756\n",
      "   macro avg       0.62      0.62      0.62     34756\n",
      "weighted avg       0.83      0.83      0.83     34756\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 9 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 118/250 [00:46<00:51,  2.55it/s]"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=8)\n",
    "experiment_name = input('Enter Experiment name')\n",
    "model_name = input('Enter name for the models')\n",
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer, early_stopping,dropout_layer=True, noise_layer=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.268281227313873\n",
      "0.263273337759238\n"
     ]
    }
   ],
   "source": [
    "def tensors_to_lst(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        new_lst.append(items.item())\n",
    "    return new_lst\n",
    "\n",
    "def get_items(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        new_lst.append(float(items))\n",
    "    return new_lst\n",
    "\n",
    "\n",
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "max_mcc_student = np.amax(metrices[6])\n",
    "max_mcc_teacher = np.amax(mcc_cost_teacher)\n",
    "print(max_mcc_student)\n",
    "print(max_mcc_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 125/125 [00:07<00:00, 16.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.3836589698046181\n",
      "Average F1 Validation score for whole sentence class 1 : 0.841604983576038\n",
      "Average Accuracy Validation score whole sentence  : 0.747977784107092\n",
      "Average mcc Validation score whole sentence : 0.27684315059180087\n",
      "Average F1 Validation score for source sentence class 0 : 0.3621188894566513\n",
      "Average F1 Validation score for source sentence class 1 : 0.8127406370318517\n",
      "Average Accuracy Validation score source sentence  : 0.7104754541940471\n",
      "Average mcc Validation score source sentence : 0.22518634260307072\n",
      "Average F1 Validation score for target sentence class 0 : 0.40954226204892225\n",
      "Average F1 Validation score for target sentence class 1 : 0.7429490220886711\n",
      "Average Accuracy Validation score target sentence  : 0.6418261284754104\n",
      "Average mcc Validation score target sentence : 0.24549810296512026\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.0\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9865348761504543\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9734275535829002\n",
      "Average mcc Validation score gaps in target sentence : 0.0\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.3985622532555536\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8577005116480085\n",
      "Average Accuracy Validation score whole target sentence  : 0.7698534385569334\n",
      "Average mcc Validation score whole target sentence : 0.3090696381401978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "model = EntityModel() \n",
    "model.cuda()\n",
    "model.load_state_dict(torch.load(f'../models/MeanTeacher_models/StudentModels/studentModel_{model_name}.bin'))\n",
    "model.eval() # for 1k, 1.0 k data- teacher model -- less seq len\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "student_mcc_test = test_metrics[4]# student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_mcc_test = test_metrics[4]# student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 125/125 [00:07<00:00, 16.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.3827009061053298\n",
      "Average F1 Validation score for whole sentence class 1 : 0.864535847942553\n",
      "Average Accuracy Validation score whole sentence  : 0.7778268299629735\n",
      "Average mcc Validation score whole sentence : 0.27335920998423857\n",
      "Average F1 Validation score for source sentence class 0 : 0.362106513561671\n",
      "Average F1 Validation score for source sentence class 1 : 0.8452375234161102\n",
      "Average Accuracy Validation score source sentence  : 0.7509083880943177\n",
      "Average mcc Validation score source sentence : 0.2284687146093418\n",
      "Average F1 Validation score for target sentence class 0 : 0.4086708344658874\n",
      "Average F1 Validation score for target sentence class 1 : 0.7810156525240324\n",
      "Average Accuracy Validation score target sentence  : 0.680390788555478\n",
      "Average mcc Validation score target sentence : 0.24378727303754907\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.0\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9865348761504543\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9734275535829002\n",
      "Average mcc Validation score gaps in target sentence : 0.0\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.39641421132423704\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8754641025989747\n",
      "Average Accuracy Validation score whole target sentence  : 0.7935287485907554\n",
      "Average mcc Validation score whole target sentence : 0.3017531356578832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'../models/MeanTeacher_models/TeacherModels/teacherModel_{model_name}.bin'))\n",
    "model.eval() # for 1k, 1.0 k data- teacher model -- less seq len\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "# Thesis/src/code/models/MeanTeacher_models/TeacherModels/teacherModel_v1_rampup_const_cost_500_steps_to_1_withDropout_250_labeled_1750_unlabeled.bin\n",
    "teacher_mcc_test = test_metrics[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistency_lost_train : [0.3470084456205368, 0.19563110798597336, 0.1573659960925579, 0.14723503655195236, 0.1362940408885479, 0.12696716472506522, 0.11610708090662956, 0.11196214237809181, 0.10578019019961357, 0.10022171480953693, 0.08898133890330792] \n",
      " Classificataion_lost_train :  [0.40166912829875945, 0.3987017970085144, 0.37146323120594027, 0.36015333867073057, 0.27465154784917833, 0.2231963288038969, 0.17769851237535478, 0.15446169294789433, 0.12985116183385254, 0.1080430397063028, 0.09495176218729466] \n",
      " Overall_loss_train : [0.4289593249838799, 0.5319550320208073, 0.5288292275369167, 0.5073883743882179, 0.4109455869495869, 0.35016349324584006, 0.29380559420585634, 0.2664238353073597, 0.2356313513815403, 0.20826475366950034, 0.18393310165405274] \n",
      " f1_class0_student_test : [0.34060410872005076, 0.3556815654881032, 0.3626969337624937, 0.3725971961266079, 0.3686803607973925, 0.3306113440741558, 0.3275547445255475, 0.3433303039482985, 0.2856772856772857, 0.31479462013813164, 0.3189245567273149] \n",
      " f1_class1_student_test : [0.7243313817091331, 0.7750562844499651, 0.8696149447197865, 0.8440564716025435, 0.8521103002539108, 0.8996526054590571, 0.9029369155801396, 0.8909057357110503, 0.9107298915682149, 0.9076870337419808, 0.903470591133814] \n",
      " accuracy_student : [0.6112038209230061, 0.6665323972839222, 0.7835193923351363, 0.7502014040741167, 0.760357923811716, 0.825468983772586, 0.8303602255725631, 0.8128956151455864, 0.841293589596041, 0.8372942801242951, 0.8309068937737369] \n",
      " mcc_cost_student : [0.2506141155693589, 0.2609889576833471, 0.2537454418462365, 0.268281227313873, 0.2617672460205885, 0.23043046965943706, 0.23050741872995872, 0.23758561221687988, 0.20114452052999734, 0.22372295183300359, 0.22254203698259556] \n",
      " test_cost_student : [0.6064972281455994, 0.6195055246353149, 0.6244452595710754, 0.5984045267105103, 0.6104861497879028, 0.6757157444953918, 0.6679267287254333, 0.6759268045425415, 0.810613214969635, 0.7885249853134155, 0.8196290731430054] \n",
      " f1_class0_teacher_test : [0.3297844715658271, 0.3542329933077773, 0.3656227239621267, 0.3704556670505017, 0.3629575669276998, 0.36065251572327045, 0.3499682808204694, 0.33139664804469277, 0.3204891555145362, 0.3187061481745749, 0.3093802748975163] \n",
      " f1_class1_teacher_test : [0.809196421970873, 0.8163559431643908, 0.8438564411458894, 0.8665481047529379, 0.8804715530497181, 0.8903532425508965, 0.8976254704099643, 0.9011921667051946, 0.9031950562093222, 0.9062402828011717, 0.9064327485380117] \n",
      " accuracy_teacher : [0.7029577626884567, 0.7140349867648751, 0.7493957877776499, 0.7797790309586834, 0.7987110139256531, 0.812809299113822, 0.8231096789043618, 0.8278282886408103, 0.8305328576360916, 0.8351651513407757, 0.8351939233513638] \n",
      " mcc_cost_teacher [0.21243783266017438, 0.24737792915608364, 0.2586744370747739, 0.263273337759238, 0.25569180651412177, 0.25627602735689836, 0.2488268802923497, 0.2326320755247104, 0.22378061568972707, 0.22559782544598841, 0.21686361902636836] \n",
      " test_cost_teacher [0.6439549326896667, 0.6304762363433838, 0.62212735414505, 0.6149791479110718, 0.6178690195083618, 0.6323851346969604, 0.6547241806983948, 0.696919858455658, 0.7207509875297546, 0.7535403966903687, 0.7600182294845581]\n"
     ]
    }
   ],
   "source": [
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6064972281455994,\n",
       " 0.6195055246353149,\n",
       " 0.6244452595710754,\n",
       " 0.5984045267105103,\n",
       " 0.6104861497879028,\n",
       " 0.6757157444953918,\n",
       " 0.6679267287254333,\n",
       " 0.6759268045425415,\n",
       " 0.810613214969635,\n",
       " 0.7885249853134155,\n",
       " 0.8196290731430054]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item.item() for item in metrices[7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer.add_hparams(\n",
    "    { \"lr\": float(config.lr),  \n",
    "    \"alpha\":config.alpha, \n",
    "    \"teacher_noise_gaussian_std\":config.gaussian_noise_std_teacher,\n",
    "    \"student_noise_gaussian_std\":config.gaussian_noise_std_student,\n",
    "    \"labelled_data\": len_labelled_data, \n",
    "    \"unlabelled_data\":len_unlabelled_data \n",
    "\n",
    "    },\n",
    "    {\n",
    "    \"mcc_score_teacher\": float(max_mcc_teacher),\n",
    "    \"mcc_score_student\" : float(max_mcc_student),\n",
    "    },\n",
    "    )\n",
    "writer.add_text('text', 'Ramup from 0 to 1 in 500 steps. Also, noise used in teacher is more than student 0.5 and 0.3 respectively for teacher and student models. 250 labeled and 1750 unlabeled.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Experiment name : MeanTeacher_withConsistencyRampup_for_600_steps_to_1_1000_labeled_1000_unlabeled_alpha_adjusted_check\n",
      "Enter name for saving the models with version : v1_rampup_const_cost_600_steps_to_1_withDropout_1000_labeled_1000_unlabeled_alpha_adjusted_check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 1 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /codebuild/output/src811146734/src/torch/csrc/utils/python_arg_parser.cpp:766.)\n",
      "  app.launch_new_instance()\n",
      "  4%|▍         | 11/250 [00:06<02:12,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 21/250 [00:11<02:03,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9523809523809523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 31/250 [00:17<01:58,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.967741935483871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:51<00:27,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6507706062775105\n",
      "Consistency Cost : 0.4398407321423292\n",
      "Classification Cost : 0.6353269508481025\n",
      "Consistency Weight is: 0.10836802322189582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:19<00:00,  1.80it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5888, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.34186596583442835\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7450157825068731\n",
      "Average Accuracy Validation score whole sentence  : 0.6324379862028475\n",
      "Average mcc Validation score whole sentence : 0.26285807458677524\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.79      0.34      4122\n",
      "           1       0.95      0.61      0.75     29943\n",
      "\n",
      "    accuracy                           0.63     34065\n",
      "   macro avg       0.59      0.70      0.54     34065\n",
      "weighted avg       0.87      0.63      0.70     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6231, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3331091915377851\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7357829374756645\n",
      "Average Accuracy Validation score whole sentence  : 0.6215176867752825\n",
      "Average mcc Validation score whole sentence : 0.2497578093538212\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.78      0.33      4122\n",
      "           1       0.95      0.60      0.74     29943\n",
      "\n",
      "    accuracy                           0.62     34065\n",
      "   macro avg       0.58      0.69      0.53     34065\n",
      "weighted avg       0.86      0.62      0.69     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 2 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:54<00:28,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6618445229530334\n",
      "Consistency Cost : 0.193541909083724\n",
      "Classification Cost : 0.5814238642156124\n",
      "Consistency Weight is: 0.7316156289466418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:22<00:00,  1.75it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5723, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3611275612933791\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7894777925220513\n",
      "Average Accuracy Validation score whole sentence  : 0.6833113166006165\n",
      "Average mcc Validation score whole sentence : 0.279773841430625\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.74      0.36      4122\n",
      "           1       0.95      0.68      0.79     29943\n",
      "\n",
      "    accuracy                           0.68     34065\n",
      "   macro avg       0.59      0.71      0.58     34065\n",
      "weighted avg       0.86      0.68      0.74     34065\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-a6411e94364f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mearly_stopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_MeanTeacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_labelled_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen_unlabelled_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdropout_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-43-74161f607cb0>\u001b[0m in \u001b[0;36mtrain_MeanTeacher\u001b[0;34m(train_dataloader, val_dataloader, len_labelled_data, len_unlabelled_data, writer, early_stopping, dropout_layer, noise_layer)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_mcc_score_student\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m  \u001b[0mbest_mcc_student\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'../models/MeanTeacher_models/StudentModels/studentModel_{model_name}.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                     \u001b[0mbest_mcc_student\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_mcc_score_student\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=8)\n",
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer, early_stopping,dropout_layer=True, noise_layer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Experiment name : MeanTeacher_withConsistencyRampup_for_600_steps_to_1_1000_labeled_1000_unlabeled_alpha_adjusted\n",
      "Enter name for saving the models with version : v1_rampup_const_cost_600_steps_to_1_withDropout_1000_labeled_1000_unlabeled_alpha_adjusted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 1 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:55<00:29,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6507706062775105\n",
      "Consistency Cost : 0.4398407321423292\n",
      "Classification Cost : 0.6353269508481025\n",
      "Consistency Weight is: 0.10836802322189582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:25<00:00,  1.72it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5888, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.34186596583442835\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7450157825068731\n",
      "Average Accuracy Validation score whole sentence  : 0.6324379862028475\n",
      "Average mcc Validation score whole sentence : 0.26285807458677524\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.79      0.34      4122\n",
      "           1       0.95      0.61      0.75     29943\n",
      "\n",
      "    accuracy                           0.63     34065\n",
      "   macro avg       0.59      0.70      0.54     34065\n",
      "weighted avg       0.87      0.63      0.70     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6231, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3331091915377851\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7357829374756645\n",
      "Average Accuracy Validation score whole sentence  : 0.6215176867752825\n",
      "Average mcc Validation score whole sentence : 0.2497578093538212\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.78      0.33      4122\n",
      "           1       0.95      0.60      0.74     29943\n",
      "\n",
      "    accuracy                           0.62     34065\n",
      "   macro avg       0.58      0.69      0.53     34065\n",
      "weighted avg       0.86      0.62      0.69     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 2 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [02:01<00:29,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6618445229530334\n",
      "Consistency Cost : 0.193541909083724\n",
      "Classification Cost : 0.5814238642156124\n",
      "Consistency Weight is: 0.7316156289466418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:31<00:00,  1.65it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5723, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3611275612933791\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7894777925220513\n",
      "Average Accuracy Validation score whole sentence  : 0.6833113166006165\n",
      "Average mcc Validation score whole sentence : 0.279773841430625\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.74      0.36      4122\n",
      "           1       0.95      0.68      0.79     29943\n",
      "\n",
      "    accuracy                           0.68     34065\n",
      "   macro avg       0.59      0.71      0.58     34065\n",
      "weighted avg       0.86      0.68      0.74     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5883, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.35459619546645404\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7759234358933798\n",
      "Average Accuracy Validation score whole sentence  : 0.6673418464699838\n",
      "Average mcc Validation score whole sentence : 0.27390460591384436\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.76      0.35      4122\n",
      "           1       0.95      0.66      0.78     29943\n",
      "\n",
      "    accuracy                           0.67     34065\n",
      "   macro avg       0.59      0.71      0.57     34065\n",
      "weighted avg       0.86      0.67      0.72     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 3 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:55<00:26,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6834059897065162\n",
      "Consistency Cost : 0.1498090098798275\n",
      "Classification Cost : 0.5370685669779778\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:22<00:00,  1.76it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5714, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.359741355074501\n",
      "Average F1 Validation score for whole sentence class 1 : 0.7738206376005562\n",
      "Average Accuracy Validation score whole sentence  : 0.665727286070747\n",
      "Average mcc Validation score whole sentence : 0.28387618922460817\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.78      0.36      4122\n",
      "           1       0.95      0.65      0.77     29943\n",
      "\n",
      "    accuracy                           0.67     34065\n",
      "   macro avg       0.59      0.71      0.57     34065\n",
      "weighted avg       0.87      0.67      0.72     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5763, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3688155922038981\n",
      "Average F1 Validation score for whole sentence class 1 : 0.806147116380799\n",
      "Average Accuracy Validation score whole sentence  : 0.7033905768383972\n",
      "Average mcc Validation score whole sentence : 0.28587170143879026\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.72      0.37      4122\n",
      "           1       0.95      0.70      0.81     29943\n",
      "\n",
      "    accuracy                           0.70     34065\n",
      "   macro avg       0.60      0.71      0.59     34065\n",
      "weighted avg       0.86      0.70      0.75     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 4 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:49<00:26,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.6329384277760982\n",
      "Consistency Cost : 0.13410346314311028\n",
      "Classification Cost : 0.49883496075868605\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:16<00:00,  1.84it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5521, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.39303991811668376\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8475354440608243\n",
      "Average Accuracy Validation score whole sentence  : 0.7562894466461177\n",
      "Average mcc Validation score whole sentence : 0.30688499722525686\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.65      0.39      4122\n",
      "           1       0.94      0.77      0.85     29943\n",
      "\n",
      "    accuracy                           0.76     34065\n",
      "   macro avg       0.61      0.71      0.62     34065\n",
      "weighted avg       0.86      0.76      0.79     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5594, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.384313184919705\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8334048227373603\n",
      "Average Accuracy Validation score whole sentence  : 0.7377660355203288\n",
      "Average mcc Validation score whole sentence : 0.2993655055140609\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.68      0.38      4122\n",
      "           1       0.94      0.75      0.83     29943\n",
      "\n",
      "    accuracy                           0.74     34065\n",
      "   macro avg       0.61      0.71      0.61     34065\n",
      "weighted avg       0.86      0.74      0.78     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 5 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:56<00:29,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.578609249740839\n",
      "Consistency Cost : 0.1259544885158539\n",
      "Classification Cost : 0.45265476159751417\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:26<00:00,  1.71it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5497, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4086652007492466\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8699933752305241\n",
      "Average Accuracy Validation score whole sentence  : 0.7868486716571261\n",
      "Average mcc Validation score whole sentence : 0.32101908556910497\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.61      0.41      4122\n",
      "           1       0.94      0.81      0.87     29943\n",
      "\n",
      "    accuracy                           0.79     34065\n",
      "   macro avg       0.62      0.71      0.64     34065\n",
      "weighted avg       0.86      0.79      0.81     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5622, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.40028155795401216\n",
      "Average F1 Validation score for whole sentence class 1 : 0.861448395490026\n",
      "Average Accuracy Validation score whole sentence  : 0.7749009247027742\n",
      "Average mcc Validation score whole sentence : 0.312232297079589\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.62      0.40      4122\n",
      "           1       0.94      0.80      0.86     29943\n",
      "\n",
      "    accuracy                           0.77     34065\n",
      "   macro avg       0.62      0.71      0.63     34065\n",
      "weighted avg       0.86      0.77      0.81     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 6 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:54<00:26,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.5105033388361335\n",
      "Consistency Cost : 0.11641626179218292\n",
      "Classification Cost : 0.3940870776027441\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:21<00:00,  1.77it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5565, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4083471662319184\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8650840858703294\n",
      "Average Accuracy Validation score whole sentence  : 0.7802730074856892\n",
      "Average mcc Validation score whole sentence : 0.32224119948520497\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.63      0.41      4122\n",
      "           1       0.94      0.80      0.87     29943\n",
      "\n",
      "    accuracy                           0.78     34065\n",
      "   macro avg       0.62      0.71      0.64     34065\n",
      "weighted avg       0.86      0.78      0.81     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5538, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.41576182136602446\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8823487921001587\n",
      "Average Accuracy Validation score whole sentence  : 0.8041391457507706\n",
      "Average mcc Validation score whole sentence : 0.32708248581371663\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.58      0.42      4122\n",
      "           1       0.93      0.84      0.88     29943\n",
      "\n",
      "    accuracy                           0.80     34065\n",
      "   macro avg       0.63      0.71      0.65     34065\n",
      "weighted avg       0.86      0.80      0.83     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 7 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:49<00:26,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.47228979177773\n",
      "Consistency Cost : 0.11324455369263887\n",
      "Classification Cost : 0.35904523827135565\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:15<00:00,  1.84it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5694, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.42196163985092267\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8886905074480562\n",
      "Average Accuracy Validation score whole sentence  : 0.8133274622046088\n",
      "Average mcc Validation score whole sentence : 0.333774732241063\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.56      0.42      4122\n",
      "           1       0.93      0.85      0.89     29943\n",
      "\n",
      "    accuracy                           0.81     34065\n",
      "   macro avg       0.64      0.71      0.66     34065\n",
      "weighted avg       0.86      0.81      0.83     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5710, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.42609365966467533\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8968693724892643\n",
      "Average Accuracy Validation score whole sentence  : 0.8251577865844708\n",
      "Average mcc Validation score whole sentence : 0.3380102405478781\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.54      0.43      4122\n",
      "           1       0.93      0.86      0.90     29943\n",
      "\n",
      "    accuracy                           0.83     34065\n",
      "   macro avg       0.64      0.70      0.66     34065\n",
      "weighted avg       0.86      0.83      0.84     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 8 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:50<00:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.4151100990176201\n",
      "Consistency Cost : 0.10775427658110857\n",
      "Classification Cost : 0.3073558236286044\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:17<00:00,  1.81it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6327, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4102850754611515\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9108726873363183\n",
      "Average Accuracy Validation score whole sentence  : 0.8451489798913842\n",
      "Average mcc Validation score whole sentence : 0.3231022588010173\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.45      0.41      4122\n",
      "           1       0.92      0.90      0.91     29943\n",
      "\n",
      "    accuracy                           0.85     34065\n",
      "   macro avg       0.65      0.67      0.66     34065\n",
      "weighted avg       0.86      0.85      0.85     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.5871, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4320213749871544\n",
      "Average F1 Validation score for whole sentence class 1 : 0.905357968458364\n",
      "Average Accuracy Validation score whole sentence  : 0.8377513576985175\n",
      "Average mcc Validation score whole sentence : 0.3454380086870494\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.51      0.43      4122\n",
      "           1       0.93      0.88      0.91     29943\n",
      "\n",
      "    accuracy                           0.84     34065\n",
      "   macro avg       0.65      0.70      0.67     34065\n",
      "weighted avg       0.86      0.84      0.85     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 9 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [02:00<00:29,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.36140915922820566\n",
      "Consistency Cost : 0.10124831279739738\n",
      "Classification Cost : 0.26016084644943477\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:30<00:00,  1.66it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6364, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.41714846732846084\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9093838508895409\n",
      "Average Accuracy Validation score whole sentence  : 0.843152796125055\n",
      "Average mcc Validation score whole sentence : 0.3298248006538421\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.46      0.42      4122\n",
      "           1       0.92      0.90      0.91     29943\n",
      "\n",
      "    accuracy                           0.84     34065\n",
      "   macro avg       0.65      0.68      0.66     34065\n",
      "weighted avg       0.86      0.84      0.85     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6150, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.42143406171077197\n",
      "Average F1 Validation score for whole sentence class 1 : 0.910729715534622\n",
      "Average Accuracy Validation score whole sentence  : 0.845325113753119\n",
      "Average mcc Validation score whole sentence : 0.3350929373157651\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.47      0.42      4122\n",
      "           1       0.92      0.90      0.91     29943\n",
      "\n",
      "    accuracy                           0.85     34065\n",
      "   macro avg       0.65      0.68      0.67     34065\n",
      "weighted avg       0.86      0.85      0.85     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 10 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [02:02<00:29,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.32515245221555233\n",
      "Consistency Cost : 0.09873415146023035\n",
      "Classification Cost : 0.22641830025240778\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:31<00:00,  1.65it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.7178, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.40980225646002666\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9187636715814784\n",
      "Average Accuracy Validation score whole sentence  : 0.8571847937766035\n",
      "Average mcc Validation score whole sentence : 0.3285659325308531\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.41      0.41      4122\n",
      "           1       0.92      0.92      0.92     29943\n",
      "\n",
      "    accuracy                           0.86     34065\n",
      "   macro avg       0.66      0.66      0.66     34065\n",
      "weighted avg       0.86      0.86      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.6542, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.41705282669138094\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9154257285959192\n",
      "Average Accuracy Validation score whole sentence  : 0.8522824012916483\n",
      "Average mcc Validation score whole sentence : 0.3331154400061646\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.44      0.42      4122\n",
      "           1       0.92      0.91      0.92     29943\n",
      "\n",
      "    accuracy                           0.85     34065\n",
      "   macro avg       0.66      0.67      0.67     34065\n",
      "weighted avg       0.86      0.85      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 11 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:57<00:26,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.30029949981719256\n",
      "Consistency Cost : 0.09844230867922306\n",
      "Classification Cost : 0.20185719151981174\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:24<00:00,  1.73it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.7548, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3965811965811966\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9175508842175509\n",
      "Average Accuracy Validation score whole sentence  : 0.8549244092176721\n",
      "Average mcc Validation score whole sentence : 0.31414497677364983\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.39      0.40      4122\n",
      "           1       0.92      0.92      0.92     29943\n",
      "\n",
      "    accuracy                           0.85     34065\n",
      "   macro avg       0.66      0.66      0.66     34065\n",
      "weighted avg       0.85      0.85      0.85     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.7018, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.40841494377947046\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9182579060792864\n",
      "Average Accuracy Validation score whole sentence  : 0.8563628357551739\n",
      "Average mcc Validation score whole sentence : 0.32667609614293824\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.41      0.41      4122\n",
      "           1       0.92      0.92      0.92     29943\n",
      "\n",
      "    accuracy                           0.86     34065\n",
      "   macro avg       0.66      0.66      0.66     34065\n",
      "weighted avg       0.86      0.86      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 12 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:50<00:27,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.2751480747386813\n",
      "Consistency Cost : 0.09618175240233541\n",
      "Classification Cost : 0.17896632244810462\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:17<00:00,  1.81it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.9175, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3817829457364341\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9266738909138674\n",
      "Average Accuracy Validation score whole sentence  : 0.8688976955819756\n",
      "Average mcc Validation score whole sentence : 0.3140109280596588\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.33      0.38      4122\n",
      "           1       0.91      0.94      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.64      0.65     34065\n",
      "weighted avg       0.85      0.87      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.7536, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.406288685318148\n",
      "Average F1 Validation score for whole sentence class 1 : 0.920135882235396\n",
      "Average Accuracy Validation score whole sentence  : 0.8592103331865552\n",
      "Average mcc Validation score whole sentence : 0.32655157633549337\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.40      0.41      4122\n",
      "           1       0.92      0.92      0.92     29943\n",
      "\n",
      "    accuracy                           0.86     34065\n",
      "   macro avg       0.67      0.66      0.66     34065\n",
      "weighted avg       0.86      0.86      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 13 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:58<00:28,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.24575058571994304\n",
      "Consistency Cost : 0.08938711406663061\n",
      "Classification Cost : 0.15636347279883922\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:26<00:00,  1.71it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]9.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.8412, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4022677490014173\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9231559243982839\n",
      "Average Accuracy Validation score whole sentence  : 0.8638191692352855\n",
      "Average mcc Validation score whole sentence : 0.32656505228941407\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.38      0.40      4122\n",
      "           1       0.92      0.93      0.92     29943\n",
      "\n",
      "    accuracy                           0.86     34065\n",
      "   macro avg       0.67      0.65      0.66     34065\n",
      "weighted avg       0.86      0.86      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 14 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:50<00:26,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.21835778195410968\n",
      "Consistency Cost : 0.08650215949863195\n",
      "Classification Cost : 0.13185562253464014\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:17<00:00,  1.82it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.0128, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.38831659929586654\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9224127950248922\n",
      "Average Accuracy Validation score whole sentence  : 0.8622926757669162\n",
      "Average mcc Validation score whole sentence : 0.3123356791186087\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.36      0.39      4122\n",
      "           1       0.91      0.93      0.92     29943\n",
      "\n",
      "    accuracy                           0.86     34065\n",
      "   macro avg       0.67      0.65      0.66     34065\n",
      "weighted avg       0.85      0.86      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.9391, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.3920988981456598\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9254547851305035\n",
      "Average Accuracy Validation score whole sentence  : 0.8671950682518714\n",
      "Average mcc Validation score whole sentence : 0.3208743975375306\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.35      0.39      4122\n",
      "           1       0.91      0.94      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.65      0.66     34065\n",
      "weighted avg       0.86      0.87      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 15 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:55<00:29,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.21577567676082254\n",
      "Consistency Cost : 0.0838872840628028\n",
      "Classification Cost : 0.13188839299138636\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:24<00:00,  1.73it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1569, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.37494769144929563\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9264939879595151\n",
      "Average Accuracy Validation score whole sentence  : 0.8684573609276384\n",
      "Average mcc Validation score whole sentence : 0.3076112804224331\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.33      0.37      4122\n",
      "           1       0.91      0.94      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.63      0.65     34065\n",
      "weighted avg       0.85      0.87      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:07<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.0667, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.38393223117912284\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9258522306819491\n",
      "Average Accuracy Validation score whole sentence  : 0.8676354029062087\n",
      "Average mcc Validation score whole sentence : 0.3142628805414049\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.34      0.38      4122\n",
      "           1       0.91      0.94      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.64      0.65     34065\n",
      "weighted avg       0.85      0.87      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 16 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 201/250 [01:51<00:26,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.19508064774796366\n",
      "Consistency Cost : 0.08055738933384418\n",
      "Classification Cost : 0.11452325810678303\n",
      "Consistency Weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:18<00:00,  1.81it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1754, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.364396999422966\n",
      "Average F1 Validation score for whole sentence class 1 : 0.92800418314324\n",
      "Average Accuracy Validation score whole sentence  : 0.8706590341993248\n",
      "Average mcc Validation score whole sentence : 0.3019851510238544\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.31      0.36      4122\n",
      "           1       0.91      0.95      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.63      0.65     34065\n",
      "weighted avg       0.85      0.87      0.86     34065\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [00:06<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1576, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.38059598059598065\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9266354756628087\n",
      "Average Accuracy Validation score whole sentence  : 0.8688096286511082\n",
      "Average mcc Validation score whole sentence : 0.3128832519403145\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.33      0.38      4122\n",
      "           1       0.91      0.94      0.93     29943\n",
      "\n",
      "    accuracy                           0.87     34065\n",
      "   macro avg       0.68      0.64      0.65     34065\n",
      "weighted avg       0.85      0.87      0.86     34065\n",
      "\n",
      "terminating because of early stopping!\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=8)\n",
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer, early_stopping,dropout_layer=True, noise_layer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fail hoga ya pe\n",
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer, early_stopping,dropout_layer=True, noise_layer=True) # alpha = 0.995 and full data w/o noise and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model= EntityModel()\n",
    "# optimizer_parameters_model = list(model.named_parameters())\n",
    "  \n",
    "# no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "# optimizer_parameters = [\n",
    "# {\n",
    "#     \"params\": [\n",
    "#         p for n, p in optimizer_parameters_model if not any(nd in n for nd in no_decay)\n",
    "#     ],\n",
    "#     \"weight_decay\": 0.001,\n",
    "# },\n",
    "# {\n",
    "#     \"params\": [\n",
    "#         p for n, p in optimizer_parameters_model if any(nd in n for nd in no_decay)\n",
    "#     ],\n",
    "#     \"weight_decay\": 0.0,\n",
    "# }]\n",
    "# optimizer = AdamW(optimizer_parameters, lr=config.lr)\n",
    "# num_train_steps = int(len(train_dataloader) * config.EPOCHS)\n",
    "# #     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "# #         optimizer, T_max=num_train_steps)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "# optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n",
    "# float(scheduler.get_last_lr()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        for item in items :\n",
    "            new_lst.append(float(item))\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensors_to_lst(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        new_lst.append(items.item())\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_against_epochs(matrix1,matrix2,label1 , label2 ,y_label , title):\n",
    "    \n",
    "    epochs = np.arange(1,config.EPOCHS+1)\n",
    "    # print(epochs)\n",
    "    plt.plot(epochs,matrix1,label=label1)\n",
    "    if matrix2 is not None :\n",
    "        plt.plot(epochs,matrix2,label=label2)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Running without Noise embeddings and dropout </h2> -- <h4> No weighted Loss </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,noise_layer=False) # alpha = 0.995 and full data w/o noise and dropout\n",
    "\n",
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plotting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_epochs(test_cost_teacher,test_cost_student,label1 = 'ValidationLoss_teacher', \n",
    "                    label2 = 'ValidationLoss_student', y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(mcc_cost_teacher,mcc_cost_student,label1 = 'mcc_teacher', \n",
    "                    label2 = 'mcc_student', y_label = 'mcc_score_test', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(classification_cost_lst,None,label1 = 'classification_cost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(consistency_cost_lst,None,label1 = 'Consistency_lost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    if 'classifier' not in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.add_text('Text','The Labelled data used in this experiment was 3200 and unlabelled used was 6400')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/MeanTeacherTraining/alpha_0.995_trail1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer, noise_layer=True) # alpha = 0.995 and full data w/o noise and dropout\n",
    "\n",
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_epochs(test_cost_teacher,test_cost_student,label1 = 'ValidationLoss_teacher', \n",
    "                    label2 = 'ValidationLoss_student', y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(mcc_cost_teacher,mcc_cost_student,label1 = 'mcc_teacher', \n",
    "                    label2 = 'mcc_student', y_label = 'mcc_score_test', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(classification_cost_lst,None,label1 = 'classification_cost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(consistency_cost_lst,None,label1 = 'Consistency_lost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
