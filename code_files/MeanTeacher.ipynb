{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.18.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.6.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.6/site-packages (from nltk) (2022.3.15)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.6/site-packages (7.7.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (1.1.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (7.16.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (5.5.6)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (59.3.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: pexpect in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.28)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi<=0.17.2,>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from jedi<=0.17.2,>=0.10->ipython>=4.0.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.6/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.10)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.14.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.9)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.6/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.6/site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10.0.0)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4.7)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install nltk\n",
    "!pip install ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import torch\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "# from DataAugmentation \n",
    "from DataAugmentation_Unlabelled import DataAugmentation\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from importlib import reload\n",
    "import config\n",
    "from transformers import XLMRobertaForTokenClassification, XLMRobertaConfig ,BertModel, XLMRobertaTokenizer, XLMRobertaModel, BertForTokenClassification\n",
    "from data_utils import loadDatafromFile,createTokenizedDf,CompDataset,createkfoldData,createDataloaders\n",
    "from data_utils_unlabelled import loadUnlabelledDatafromFile,createTokenizedDfUnlabelled,CompDatasetUnlabelled\n",
    "from seqeval.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef,classification_report,f1_score\n",
    "import engine\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "def process_data(filePath_src,filePath_tar,model_type):\n",
    "    \n",
    "    dataObj = loadUnlabelledDatafromFile(filePath_src,filePath_tar)\n",
    "    df= dataObj.createDfUnlabelled() # get dataframe from files\n",
    "    df['len_src'] = df['source'].str.split().map(lambda x:len(x))\n",
    "    df['len_tar'] = df['target'].str.split().map(lambda x:len(x))\n",
    "    \n",
    "    df = df[df.len_tar != 36]\n",
    "    df = df[df.len_tar != 2]\n",
    "    df = df[df.len_src != 1]\n",
    "    \n",
    "    df=df.iloc[:,:-2]\n",
    "    obj_tokenized = createTokenizedDfUnlabelled(df,model_type)\n",
    "    df_new= obj_tokenized.convertDf()\n",
    "#     enc_label = preprocessing.LabelEncoder()\n",
    "#     df_new['labels']= enc_label.fit_transform(df_new['labels'])\n",
    "    train_data = CompDatasetUnlabelled(df_new,model_type)\n",
    "    return train_data,df,df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6997"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train,df,df_new = process_data(config.filePath_src_backtranslated,config.filePath_tar_backtranslated,model_type = 'xlm')\n",
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_eval(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags,model_type):\n",
    "    \n",
    "    dataObj = loadDatafromFile(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags)\n",
    "    df= dataObj.createDf() # get dataframe from files\n",
    "    obj_tokenized = createTokenizedDf(df,model_type)\n",
    "    df_new= obj_tokenized.convertDf()\n",
    "    \n",
    "    val_data = CompDataset(df_new,model_type)\n",
    "    return val_data,df,df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset_eval,df,df_new = process_data_eval(config.filePath_src_eval,config.filePath_tar_eval, config.filePath_srcTags_eval,config.filePath_tarTags_eval,model_type = 'xlm')\n",
    "# len(dataset_eval)\n",
    "dataset_train,df_train,df_new_train = process_data_eval(config.filePath_src,config.filePath_tar, config.filePath_srcTags,config.filePath_tarTags,model_type = 'xlm')\n",
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>▁José</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>▁Ort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ega</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>▁y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>▁G</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510514</th>\n",
       "      <td>6999</td>\n",
       "      <td>का</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510515</th>\n",
       "      <td>6999</td>\n",
       "      <td>▁</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510516</th>\n",
       "      <td>6999</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510517</th>\n",
       "      <td>6999</td>\n",
       "      <td>का</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510518</th>\n",
       "      <td>6999</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510519 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  words  labels\n",
       "0                 0  ▁José       1\n",
       "1                 0   ▁Ort       1\n",
       "2                 0    ega       1\n",
       "3                 0     ▁y       1\n",
       "4                 0     ▁G       1\n",
       "...             ...    ...     ...\n",
       "510514         6999     का       1\n",
       "510515         6999      ▁       1\n",
       "510516         6999      .       1\n",
       "510517         6999     का       1\n",
       "510518         6999   </s>    -100\n",
       "\n",
       "[510519 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>countofwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>131</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>761</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>774</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>778</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>833</th>\n",
       "      <td>833</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>896</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1065</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1097</th>\n",
       "      <td>1097</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>1248</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1560</th>\n",
       "      <td>1560</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>1660</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>1702</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1706</th>\n",
       "      <td>1706</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1868</th>\n",
       "      <td>1868</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>2075</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190</th>\n",
       "      <td>2190</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2301</th>\n",
       "      <td>2301</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>2370</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>2398</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>2401</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>2591</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>2599</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2813</th>\n",
       "      <td>2813</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2978</th>\n",
       "      <td>2978</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>3155</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3369</th>\n",
       "      <td>3369</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3558</th>\n",
       "      <td>3558</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3577</th>\n",
       "      <td>3577</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>3741</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>4310</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>4332</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4453</th>\n",
       "      <td>4453</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>4520</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4640</th>\n",
       "      <td>4640</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5019</th>\n",
       "      <td>5019</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362</th>\n",
       "      <td>5362</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5699</th>\n",
       "      <td>5699</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>5843</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5961</th>\n",
       "      <td>5961</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6085</th>\n",
       "      <td>6085</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6166</th>\n",
       "      <td>6166</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6805</th>\n",
       "      <td>6805</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6933</th>\n",
       "      <td>6933</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6957</th>\n",
       "      <td>6957</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id  countofwords\n",
       "70             70           144\n",
       "100           100           132\n",
       "131           131           155\n",
       "761           761           161\n",
       "774           774           130\n",
       "778           778           144\n",
       "833           833           144\n",
       "896           896           145\n",
       "1065         1065           129\n",
       "1097         1097           151\n",
       "1248         1248           153\n",
       "1560         1560           131\n",
       "1660         1660           130\n",
       "1702         1702           129\n",
       "1706         1706           148\n",
       "1868         1868           132\n",
       "2075         2075           147\n",
       "2190         2190           143\n",
       "2301         2301           129\n",
       "2370         2370           143\n",
       "2398         2398           132\n",
       "2401         2401           138\n",
       "2591         2591           129\n",
       "2599         2599           137\n",
       "2813         2813           133\n",
       "2978         2978           131\n",
       "3155         3155           145\n",
       "3369         3369           142\n",
       "3558         3558           132\n",
       "3577         3577           130\n",
       "3741         3741           130\n",
       "4310         4310           131\n",
       "4332         4332           132\n",
       "4453         4453           133\n",
       "4520         4520           140\n",
       "4640         4640           129\n",
       "5019         5019           154\n",
       "5362         5362           139\n",
       "5699         5699           137\n",
       "5843         5843           130\n",
       "5961         5961           130\n",
       "6085         6085           130\n",
       "6166         6166           135\n",
       "6805         6805           136\n",
       "6933         6933           140\n",
       "6957         6957           145"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['len_src'] = df['source'].str.split().map(lambda x:len(x))\n",
    "# df['len_tar'] = df['target'].str.split().map(lambda x:len(x))\n",
    "# print('Source : Max length: {}, Min length: {}, Average Length :  {}'.format(max(df['len_src']),min(df['len_src']),df['len_src'].mean()))\n",
    "# print('Source : Max length: {}, Min length: {}, Average Length :  {}'.format(max(df['len_tar']),min(df['len_tar']),df['len_tar'].mean()))\n",
    "# new = df_new.groupby('sentence_id')\n",
    "# new\n",
    "new_df = df_new_train.iloc[:,:-1].groupby('sentence_id')['words'].count().reset_index(name=\"countofwords\")\n",
    "# print(new_df[new_df.words > 128])\n",
    "new_df[new_df.countofwords>128]\n",
    "# d=df1.groupby(['col1','col2'])['col2'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_train = df_new_train.iloc[:,:-1].groupby('sentence_id')['words'].count().reset_index(name=\"countofwords\")\n",
    "# print(new_df[new_df.words > 128])\n",
    "len(new_df_train[new_df_train.countofwords>128])\n",
    "# new_df_train.countofwords.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>▁José</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>▁Ort</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>ega</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>▁y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>▁G</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510514</th>\n",
       "      <td>6999</td>\n",
       "      <td>का</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510515</th>\n",
       "      <td>6999</td>\n",
       "      <td>▁</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510516</th>\n",
       "      <td>6999</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510517</th>\n",
       "      <td>6999</td>\n",
       "      <td>का</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510518</th>\n",
       "      <td>6999</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>510519 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_id  words  labels\n",
       "0                 0  ▁José       1\n",
       "1                 0   ▁Ort       1\n",
       "2                 0    ega       1\n",
       "3                 0     ▁y       1\n",
       "4                 0     ▁G       1\n",
       "...             ...    ...     ...\n",
       "510514         6999     का       1\n",
       "510515         6999      ▁       1\n",
       "510516         6999      .       1\n",
       "510517         6999     का       1\n",
       "510518         6999   </s>    -100\n",
       "\n",
       "[510519 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : Max length: 39, Min length: 5, Average Length :  16.425714285714285\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train['len_source'] = df_train['source'].str.split().map(lambda x:len(x))\n",
    "df_train['len_target'] = df_train['target'].str.split().map(lambda x:len(x))\n",
    "print('Source : Max length: {}, Min length: {}, Average Length :  {}'.format(max(df_train['len_source']),min(df_train['len_source']),df_train['len_source'].mean()))\n",
    "\n",
    "# df_train['len_src'].hist()\n",
    "# df['len_tar'].hist()\n",
    "# df_train['len_src'].plot(kind='bar')\n",
    "plot=df_train['len_source'].plot.box(grid=True)\n",
    "fig = plot.get_figure()\n",
    "fig.savefig(\"figures/src_len.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['José Ortega y Gasset visited Husserl at Freiburg in 1934 .',\n",
       "        '1934 besuchte José Ortega y Gasset Husserl in Freiburg .',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK',\n",
       "        11, 10, 11, 10]], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tar_tokens</th>\n",
       "      <th>len_src</th>\n",
       "      <th>len_tar</th>\n",
       "      <th>len_source</th>\n",
       "      <th>len_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>\\ set Staff.midiInstrument = # \" string ensemb...</td>\n",
       "      <td>\\ set Staff.midiInstrument = # \" string ensemb...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2922</th>\n",
       "      <td>It ’ s just not quite right still . ” He added...</td>\n",
       "      <td>Es war einfach nicht ganz richtig noch . Er fü...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK BAD OK OK BAD BAD B...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "761   \\ set Staff.midiInstrument = # \" string ensemb...   \n",
       "2922  It ’ s just not quite right still . ” He added...   \n",
       "\n",
       "                                                 target  \\\n",
       "761   \\ set Staff.midiInstrument = # \" string ensemb...   \n",
       "2922  Es war einfach nicht ganz richtig noch . Er fü...   \n",
       "\n",
       "                                             src_tokens  \\\n",
       "761   OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...   \n",
       "2922  OK OK OK OK OK OK OK OK OK BAD OK OK BAD BAD B...   \n",
       "\n",
       "                                             tar_tokens  len_src  len_tar  \\\n",
       "761   OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...       39       39   \n",
       "2922  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...       38       33   \n",
       "\n",
       "      len_source  len_target  \n",
       "761           39          39  \n",
       "2922          38          33  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outliers\n",
    "df_train[df_train.len_source > 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source : Max length: 39, Min length: 3, Average Length :  16.04885714285714\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Source : Max length: {}, Min length: {}, Average Length :  {}'.format(max(df_train['len_target']),min(df_train['len_target']),df_train['len_target'].mean()))\n",
    "plot = df_train['len_target'].plot.box(grid=True)\n",
    "fig = plot.get_figure()\n",
    "fig.savefig(\"output.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_df_train = df_new_train.iloc[:,:-1].groupby('sentence_id')['words'].count().reset_index(name=\"total_tokens\")\n",
    "new_df_train # including token \n",
    "plot = new_df_train['total_tokens'].plot.box(grid=True) # after tokenization - including source and target\n",
    "fig = plot.get_figure()\n",
    "fig.savefig(\"figures/countofwords.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens : Max length: 161, Min length: 27, Average Length :  72.93128571428572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Tokens : Max length: {}, Min length: {}, Average Length :  {}'.format(max(new_df_train['total_tokens']),min(new_df_train['total_tokens']),new_df_train['total_tokens'].mean()))\n",
    "df_temp = new_df_train[new_df_train.total_tokens >128]\n",
    "len(df_temp[df_temp.sentence_id < 2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Musician Laura Marling hails originally from Hampshire .',\n",
       "        'Die Musikerin Laura Marling stammt ursprünglich aus Hampshire .',\n",
       "        'OK OK OK OK OK OK OK OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK', 8, 9],\n",
       "       ['Knute Nelson in MNopedia , the Minnesota Encyclopedia',\n",
       "        'Knute Nelson in MNopedia , der Minnesota Enzyklopädie',\n",
       "        'OK OK OK OK OK OK BAD BAD',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK BAD OK BAD OK', 8, 8],\n",
       "       ['Unicity and salvific universality of the Catholic Church',\n",
       "        'Unicity und heilbringende Universalität der katholischen Kirche',\n",
       "        'BAD OK OK OK OK OK OK OK',\n",
       "        'OK BAD OK OK OK OK OK OK OK OK OK OK OK OK OK', 8, 7],\n",
       "       ['Rachmaninoff toured between February and October 1918 .',\n",
       "        'Rachmaninoff tourte zwischen Februar und Oktober 1918 .',\n",
       "        'OK OK OK OK OK OK OK OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK', 8, 8],\n",
       "       ['It subsequently underwent numerous alterations and renovations .',\n",
       "        'In der Folge wurden zahlreiche Umbauten und Renovierungen durchgeführt .',\n",
       "        'OK OK OK OK OK OK OK OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK',\n",
       "        8, 10],\n",
       "       ['Wharton School of the University of Pennsylvania alumni',\n",
       "        'Absolvent der Wharton School der University of Pennsylvania',\n",
       "        'OK OK OK OK OK OK OK OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK', 8, 8],\n",
       "       ['Biographical dictionary of social and cultural anthropology .',\n",
       "        'Biographisches Wörterbuch der Sozial- und Kulturanthropologie .',\n",
       "        'OK OK OK OK OK OK OK OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK', 8, 7],\n",
       "       ['Public Lynching and Mob Violence under Modi Government',\n",
       "        'Public Lynching and Mob Violence under Modi Government',\n",
       "        'BAD BAD BAD BAD BAD BAD BAD BAD',\n",
       "        'OK BAD OK BAD OK BAD OK BAD OK BAD OK BAD OK BAD OK BAD OK', 8,\n",
       "        8],\n",
       "       ['Dieterich relocated to Sauk Village from Nebraska .',\n",
       "        'Dieterich zog von Nebraska nach Sauk Village um .',\n",
       "        'OK OK OK OK OK OK OK OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK', 8, 9],\n",
       "       ['Inconsistency with Old Testament conception of the afterlife',\n",
       "        'Unstimmigkeit mit dem alttestamentlichen Konzept des Jenseits',\n",
       "        'OK OK OK OK OK OK OK OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK', 8, 7],\n",
       "       ['Routledge encyclopedia of social and cultural anthropology .',\n",
       "        'Routledge Enzyklopädie der Sozial- und Kulturanthropologie .',\n",
       "        'OK BAD BAD BAD BAD BAD BAD OK',\n",
       "        'OK OK BAD BAD OK BAD OK BAD OK BAD OK BAD OK OK OK', 8, 7],\n",
       "       ['Alaskan embezzlement , forgeries , arrests and trial',\n",
       "        'Alaskan Veruntreuung , Fälschungen , Verhaftungen und Verfahren',\n",
       "        'BAD BAD OK OK OK OK OK BAD',\n",
       "        'OK BAD OK BAD OK OK OK OK OK OK OK OK OK OK BAD BAD OK', 8, 8],\n",
       "       ['Electrolytic capacitors age as the electrolyte evaporates .',\n",
       "        'Elektrolytkondensatoren altern , wenn der Elektrolyt verdampft .',\n",
       "        'OK OK OK OK OK OK OK OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK', 8, 8],\n",
       "       ['In October 2012 Argentinian authorities raided Sheik .',\n",
       "        'Im Oktober 2012 überfielen argentinische Behörden Scheich .',\n",
       "        'OK OK OK OK OK OK BAD OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK BAD OK OK OK', 8, 8],\n",
       "       ['Ceiler s sentences exceeded the mandatory minimums .',\n",
       "        'Die Urteile von Ceiler überstiegen die vorgeschriebenen Mindestsätze .',\n",
       "        'OK OK BAD OK OK OK OK OK',\n",
       "        'OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK', 8,\n",
       "        9]], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'] = df['source'].str.replace('\\'','')\n",
    "df[df['len_src']==8].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target : Max length: 37, Min length: 6, Average Length :  16.16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['On his return in 67 BC , he married Pompeia , a granddaughter of Sulla , whom he later divorced in 61 BC after her embroilment in the Bona Dea scandal .',\n",
       "        'Nach seiner Rückkehr im Jahr 67 v. Chr. heiratete er Pompeia , eine Enkelin von Sulla , die er später im Jahre 61 v. Chr. nach ihrer Embroilment in der Bona Dea Skandal geschieden .',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD OK OK BAD OK OK OK OK OK BAD OK BAD BAD BAD BAD OK',\n",
       "        'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD BAD OK OK BAD OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK BAD OK OK OK BAD OK BAD OK BAD OK BAD OK BAD OK OK OK',\n",
       "        32, 35],\n",
       "       ['One horse and rider , the \" header , \" lassos a running steer s horns , while the other horse and rider , the \" heeler , \" lassos the steer s two hind legs .',\n",
       "        'Ein Pferd und Reiter , der \" Header \" , lassos eine laufende Lenkung Hörner , während das andere Pferd und Reiter , der \" Heeler \" , lassos die beiden Hinterbeine des Lenkers .',\n",
       "        'OK OK OK OK OK OK BAD OK OK BAD BAD BAD BAD BAD OK BAD OK OK OK OK OK OK OK OK OK OK OK OK BAD BAD OK BAD OK OK OK OK OK',\n",
       "        'OK OK OK OK OK OK BAD OK OK OK OK OK OK BAD OK OK OK BAD OK OK BAD BAD OK BAD OK BAD OK BAD OK BAD OK OK OK OK OK OK OK OK OK OK OK OK BAD OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK BAD OK OK OK OK OK OK OK OK BAD BAD OK OK OK',\n",
       "        37, 35]], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Target : Max length: {}, Min length: {}, Average Length :  {}'.format(max(df['len_tar']),min(df['len_tar']),df['len_tar'].mean()))\n",
    "\n",
    "df[df['len_tar']==35].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(dataset_train,config.TRAIN_BATCH_SIZE)\n",
    "train_dataloader = loader_obj.createDataloaders()\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(dataset_eval,config.TRAIN_BATCH_SIZE)\n",
    "val_dataloader = loader_obj.createDataloaders()\n",
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(EntityModel, self).__init__()\n",
    "        self.bert = XLMRobertaForTokenClassification.from_pretrained(config.BASE_MODEL,output_attentions = False, output_hidden_states = False)\n",
    "#         self.bert_drop_1 = nn.Dropout(0.3)\n",
    "#         self.out_tag = nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, ids, attention_mask, labels):\n",
    "        \n",
    "        outputs = self.bert(ids,\n",
    "                                attention_mask = attention_mask,\n",
    "                                labels = labels,return_dict=False)\n",
    "#         bo_tag = self.bert_drop_1(output_1)\n",
    "        \n",
    "#         tag = self.out_tag(bo_tag)  \n",
    "        \n",
    "#         loss_tag = loss_fn(outputs[1],labels,attention_mask)\n",
    "        \n",
    "#         return bo_tag,loss\n",
    "        return outputs[0], outputs[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "student = EntityModel()\n",
    "meanteacher = EntityModel()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = '../models/training_data/model_xlmrobertatokenclassificationmodel_TrainData_earlystopping.bin'\n",
    "\n",
    "# student.load_state_dict(torch.load(PATH))\n",
    "# meanteacher.load_state_dict(torch.load(PATH))\n",
    "\n",
    "# print(student)\n",
    "# print(meanteacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ffa4f700bb8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(config.seed)\n",
    "np.random.seed(config.seed)\n",
    "torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(student.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "num_train_steps = int(len(dataset_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS) #10 is the batchsize\n",
    "optimizer = AdamW(optimizer_parameters, lr=3e-5) # used 3e-5\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 51/875 [00:29<07:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.2868057399988174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 101/875 [00:57<07:20,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.24330701753497125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 151/875 [01:25<06:55,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.21765226925412814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 201/875 [01:54<06:31,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.20112462677061557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 251/875 [02:23<05:53,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.18873231148719788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 301/875 [02:51<05:19,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.17811160723368327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 351/875 [03:19<04:50,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.16841384584350244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 401/875 [03:47<04:23,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.16284419071860612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 451/875 [04:14<03:55,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1597311253597339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 501/875 [04:42<03:28,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.15522374395281077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 551/875 [05:10<03:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.14957325905561447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 601/875 [05:38<02:34,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.14376139448955655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 651/875 [06:06<02:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13819561805862646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 701/875 [06:35<01:40,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.13321073691227606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 751/875 [07:04<01:11,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1294568473448356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 801/875 [07:32<00:41,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.12666103387717156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 851/875 [08:00<00:13,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.12391007421647801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 875/875 [08:13<00:00,  1.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# for epoch in range(config.EPOCHS):\n",
    "#             print(f'Epoch {epoch+1} of {config.EPOCHS}')\n",
    "total_train_loss=0\n",
    "total_val_loss_teacher = 0\n",
    "total_val_loss_student = 0\n",
    "\n",
    "for step, batch in enumerate(tqdm(train_dataloader, total = len(train_dataloader))):\n",
    "    \n",
    "    student.train()\n",
    "    \n",
    "    b_input_ids = batch[0].cuda()\n",
    "    b_input_mask = batch[1].cuda()\n",
    "    if step==874: # to change this, so that in self training all the labels are 0, manually doing for now! \n",
    "        labels_b = torch.from_numpy(np.full((5,256),0)).cuda()\n",
    "    else:\n",
    "        labels_b = torch.from_numpy(np.full((8,256),0)).cuda()\n",
    "    \n",
    "     # use confidence \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = student(b_input_ids,attention_mask=b_input_mask,labels=labels_b)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        mean_t_output = meanteacher(b_input_ids, \n",
    "            attention_mask=b_input_mask,labels=labels_b)\n",
    "        \n",
    "    const_loss = F.mse_loss(outputs[1], mean_t_output[1])\n",
    "    const_loss.backward()\n",
    "    total_train_loss = total_train_loss + const_loss.item()\n",
    "    \n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "    \n",
    "    alpha = 0.995\n",
    "    \n",
    "    for (t_name, t_param), (s_name, s_param) in zip(meanteacher.named_parameters(), student.named_parameters()):\n",
    "#                  param_new = s_param.data.to(t_param.device)\n",
    "        param_new = s_param.data\n",
    "        t_param.data.add_( (1-alpha)*(param_new-t_param.data) )\n",
    "    \n",
    "    if step % 50 == 0 and step!=0:\n",
    "        print ('train loss : ', float(total_train_loss/step))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:26<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teacher loss in prediction :  4.173631928920746\n",
      "validation loss in prediction ; 4.558810455799103\n",
      "f1 score for class 0 teacher: 0.0\n",
      "f1 score for class 1 teacher: 0.9465020576131687\n",
      "accuracy score teacher: 0.8984375\n",
      "mcc score teacher: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.90      1.00      0.95       460\n",
      "\n",
      "    accuracy                           0.90       512\n",
      "   macro avg       0.45      0.50      0.47       512\n",
      "weighted avg       0.81      0.90      0.85       512\n",
      "\n",
      "f1 score for class 0 student: 0.0\n",
      "f1 score for class 1 student: 0.9465020576131687\n",
      "accuracy score student: 0.8984375\n",
      "mcc score student: 0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        52\n",
      "           1       0.90      1.00      0.95       460\n",
      "\n",
      "    accuracy                           0.90       512\n",
      "   macro avg       0.45      0.50      0.47       512\n",
      "weighted avg       0.81      0.90      0.85       512\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for  batch in tqdm(val_dataloader,total=len(val_dataloader)):\n",
    "    b_input_ids_eval = batch[0].cuda()\n",
    "    b_input_mask_eval = batch[1].cuda()\n",
    "    b_labels_eval = batch[2].cuda()\n",
    "    \n",
    "    student.eval()\n",
    "    meanteacher.eval()\n",
    "    outputs_teacher_eval = meanteacher(b_input_ids_eval, \n",
    "            attention_mask=b_input_mask_eval,\n",
    "            labels=b_labels_eval)\n",
    "    \n",
    "    loss_teacher = outputs_teacher_eval[0]\n",
    "    total_val_loss_teacher=total_val_loss_teacher+loss_teacher.item()\n",
    "    \n",
    "    \n",
    "    outputs_students_eval = student(b_input_ids_eval, \n",
    "            attention_mask=b_input_mask_eval,\n",
    "            labels=b_labels_eval)\n",
    "    \n",
    "    loss_student = outputs_students_eval[0]\n",
    "    total_val_loss_student=total_val_loss_student+loss_student.item()\n",
    "    \n",
    "print('teacher loss in prediction : ',total_val_loss_teacher/len(val_dataloader))\n",
    "print('validation loss in prediction ;', total_val_loss_student/len(val_dataloader))\n",
    "labels = b_labels_eval.view(-1) \n",
    "active_logits = outputs_teacher_eval[1].view(-1, 2)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "active_accuracy = labels.view(-1) != -100\n",
    "labels_tmp_teacher = torch.masked_select(labels, active_accuracy) \n",
    "pred_tmp_teacher = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "print('f1 score for class 0 teacher:',f1_score(labels_tmp_teacher.tolist(),pred_tmp_teacher.tolist(),average='binary',pos_label = 0))\n",
    "print('f1 score for class 1 teacher:',f1_score(labels_tmp_teacher.tolist(),pred_tmp_teacher.tolist(),average='binary',pos_label = 1) )    \n",
    "print('accuracy score teacher:',accuracy_score(labels_tmp_teacher.tolist(),pred_tmp_teacher.tolist()))\n",
    "print('mcc score teacher:',matthews_corrcoef(labels_tmp_teacher.tolist(),pred_tmp_teacher.tolist()))\n",
    "print(classification_report(labels_tmp_teacher.tolist(),pred_tmp_teacher.tolist()))\n",
    "active_logits_student = outputs_students_eval[1].view(-1, 2)\n",
    "flattened_predictions_student = torch.argmax(active_logits_student, axis=1)\n",
    "active_accuracy_student = labels.view(-1) != -100\n",
    "labels_tmp_student = torch.masked_select(labels, active_accuracy_student) \n",
    "pred_tmp_student = torch.masked_select(flattened_predictions_student, active_accuracy_student)\n",
    "print('f1 score for class 0 student:',f1_score(labels_tmp_student.tolist(),pred_tmp_student.tolist(),average='binary',pos_label = 0))\n",
    "print('f1 score for class 1 student:',f1_score(labels_tmp_student.tolist(),pred_tmp_student.tolist(),average='binary',pos_label = 1) )    \n",
    "print('accuracy score student:',accuracy_score(labels_tmp_student.tolist(),pred_tmp_student.tolist()))\n",
    "print('mcc score student:',matthews_corrcoef(labels_tmp_student.tolist(),pred_tmp_student.tolist()))\n",
    "print(classification_report(labels_tmp_student.tolist(),pred_tmp_student.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/125 [00:00<00:55,  2.23it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.76 GiB total capacity; 13.72 GiB already allocated; 21.75 MiB free; 14.08 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-8b8ea4956b40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     outputs_teacher_eval = meanteacher(b_input_ids_eval, \n\u001b[1;32m      9\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             labels=b_labels_eval)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss_teacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs_teacher_eval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    752\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-16f2119a35a3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, ids, attention_mask, labels)\u001b[0m\n\u001b[1;32m     12\u001b[0m         outputs = self.bert(ids,\n\u001b[1;32m     13\u001b[0m                                 \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                                 labels = labels,return_dict=False)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#         bo_tag = self.bert_drop_1(output_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    752\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1402\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1404\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1405\u001b[0m         )\n\u001b[1;32m   1406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    752\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    859\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    752\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    531\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m                 )\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    752\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         )\n\u001b[1;32m    419\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    752\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         )\n\u001b[1;32m    348\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    752\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"relative_key_query\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.76 GiB total capacity; 13.72 GiB already allocated; 21.75 MiB free; 14.08 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "for  batch in tqdm(val_dataloader,total=len(val_dataloader)):\n",
    "    b_input_ids_eval = batch[0].cuda()\n",
    "    b_input_mask_eval = batch[1].cuda()\n",
    "    b_labels_eval = batch[2].cuda()\n",
    "    \n",
    "    student.eval()\n",
    "    \n",
    "    outputs_teacher_eval = meanteacher(b_input_ids_eval, \n",
    "            attention_mask=b_input_mask_eval,\n",
    "            labels=b_labels_eval)\n",
    "    \n",
    "    loss_teacher = outputs_teacher_eval[0]\n",
    "    total_val_loss_teacher=total_val_loss_teacher+loss_teacher.item()\n",
    "    \n",
    "    \n",
    "    outputs_students_eval = student(b_input_ids_eval, \n",
    "            attention_mask=b_input_mask_eval,\n",
    "            labels=b_labels_eval)\n",
    "    \n",
    "    loss_student = outputs_students_eval[0]\n",
    "    total_val_loss_student=total_val_loss_student+loss_student.item()\n",
    "    \n",
    "print('teacher loss in prediction : ',total_val_loss_teacher/len(val_dataloader))\n",
    "print('validation loss in prediction ;', total_val_loss_student/len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-9ec90314dd26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;36m8\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "def mt_update(t_params, s_params, average=\"exponential\", alpha=0.995, step=None):\n",
    "\n",
    "    for (t_name, t_param), (s_name, s_param) in zip(t_params, s_params):\n",
    "        if t_name != s_name:\n",
    "            logger.error(\"t_name != s_name: {} {}\".format(t_name, s_name))\n",
    "            raise ValueError\n",
    "        param_new = s_param.data.to(t_param.device)\n",
    "        if average == \"exponential\":\n",
    "            t_param.data.add_( (1-alpha)*(param_new-t_param.data) )\n",
    "        elif average == \"simple\":\n",
    "            virtual_decay = 1 / float(step)\n",
    "            diff = (param_new - t_param.data) * virtual_decay\n",
    "            t_param.data.add_(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args, model, mean_teacher, device, train_loader, test_loader, optimizer, epoch):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        ########################### CODE CHANGE HERE ######################################\n",
    "        # forward pass with mean teacher\n",
    "        # torch.no_grad() prevents gradients from being passed into mean teacher model\n",
    "        with torch.no_grad():\n",
    "            mean_t_output = mean_teacher(data)\n",
    "\n",
    "        ########################### CODE CHANGE HERE ######################################\n",
    "        # consistency loss (example with MSE, you can change)\n",
    "        const_loss = F.mse_loss(output, mean_t_output)\n",
    "\n",
    "        ########################### CODE CHANGE HERE ######################################\n",
    "        # set the consistency weight (should schedule)\n",
    "        weight = 0.5 # or 1 ?\n",
    "#         loss = F.nll_loss(output, target) + weight*const_loss\n",
    "        loss = weight*const_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        ########################### CODE CHANGE HERE ######################################\n",
    "        # update mean teacher, (should choose alpha somehow)\n",
    "        # Use the true average until the exponential average is more correct\n",
    "        alpha = 0.95\n",
    "        for mean_param, param in zip(mean_teacher.parameters(), model.parameters()):\n",
    "            mean_param.data.mul_(alpha).add_(1 - alpha, param.data)\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "            test(args, model, device, test_loader)\n",
    "            test(args, mean_teacher, device, test_loader)\n",
    "\n",
    "\n",
    "def test(args, model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    model.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask_b = batch[1].cuda()\n",
    "input_ids_b = batch[0].cuda()\n",
    "labels_b = batch[2].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_pred = student(input_ids_b, attention_mask = attention_mask_b,labels=labels_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.7898, device='cuda:0', grad_fn=<NllLossBackward>),\n",
       " tensor([[[-0.7516,  0.9833],\n",
       "          [-2.1403,  2.1222],\n",
       "          [-2.8458,  2.7934],\n",
       "          ...,\n",
       "          [-0.7905,  1.1940],\n",
       "          [-0.7905,  1.1940],\n",
       "          [-0.7905,  1.1940]],\n",
       " \n",
       "         [[-0.7823,  1.2177],\n",
       "          [-1.1539,  1.2850],\n",
       "          [-1.0655,  1.0356],\n",
       "          ...,\n",
       "          [-0.9113,  1.4899],\n",
       "          [-0.9113,  1.4899],\n",
       "          [-0.9113,  1.4899]],\n",
       " \n",
       "         [[-0.4266,  0.8377],\n",
       "          [-0.6776,  1.1314],\n",
       "          [ 1.1141, -1.2848],\n",
       "          ...,\n",
       "          [-0.4365,  1.0645],\n",
       "          [-0.4365,  1.0645],\n",
       "          [-0.4365,  1.0645]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-0.6543,  1.1550],\n",
       "          [-3.4233,  4.0548],\n",
       "          [-2.9863,  3.1163],\n",
       "          ...,\n",
       "          [-0.7607,  1.3873],\n",
       "          [-0.7607,  1.3873],\n",
       "          [-0.7607,  1.3873]],\n",
       " \n",
       "         [[-0.5817,  1.0901],\n",
       "          [-3.0265,  3.6205],\n",
       "          [-3.5847,  3.8294],\n",
       "          ...,\n",
       "          [-0.6869,  1.3540],\n",
       "          [-0.6869,  1.3540],\n",
       "          [-0.6869,  1.3540]],\n",
       " \n",
       "         [[-0.5686,  1.1144],\n",
       "          [-2.7724,  3.3495],\n",
       "          [-2.3184,  2.3509],\n",
       "          ...,\n",
       "          [-0.6605,  1.3522],\n",
       "          [-0.6605,  1.3522],\n",
       "          [-0.6605,  1.3522]]], device='cuda:0', grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([-1]*len(batch[1][0]),dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 256])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np.full((8,256),0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2352: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  warnings.warn(\"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(-0.4772)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "P = torch.Tensor([0.36, 0.48, 0.16])\n",
    "Q = torch.Tensor([0.333, 0.333, 0.333])\n",
    "out = F.kl_div(P, Q)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[    0, 17779,   933,  ...,     1,     1,     1],\n",
      "        [    0, 53295,    31,  ...,     1,     1,     1],\n",
      "        [    0,  1529,    44,  ...,     1,     1,     1],\n",
      "        [    0,  1529,    68,  ...,     1,     1,     1],\n",
      "        [    0,  3183,   107,  ...,     1,     1,     1]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])]\n"
     ]
    }
   ],
   "source": [
    "for i,item in enumerate(train_dataloader):\n",
    "    if i==874:\n",
    "        print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 256])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
