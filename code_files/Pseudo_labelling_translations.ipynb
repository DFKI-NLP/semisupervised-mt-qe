{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.6/site-packages (4.17.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers) (3.4.1)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.0.49)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (0.11.6)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.6/site-packages (3.6.7)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.6/site-packages (from nltk) (2022.3.15)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.6/site-packages (7.7.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (7.16.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (3.6.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (1.1.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (5.5.6)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: jedi<=0.17.2,>=0.10 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (59.3.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.28)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: pexpect in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from jedi<=0.17.2,>=0.10->ipython>=4.0.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.2)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.6/site-packages (from widgetsnbextension~=3.6.0->ipywidgets) (6.4.10)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (22.1.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.0.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.3.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.12.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.8.0)\n",
      "Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (6.0.7)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.4)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.13.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.9)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.6/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.6/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.10)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.6/site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.8)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (3.10.0.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (20.9)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.4.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->bleach->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets) (2.4.7)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.6/site-packages (2.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.25.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.44.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.6.2)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (3.17.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (59.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.35.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from absl-py>=0.4->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.6/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.10.0.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (1.25.11)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.0)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard) (0.8)\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install nltk\n",
    "!pip install ipywidgets\n",
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check (lst1 , lst2):\n",
    "    if lst1 == lst2:\n",
    "        return True\n",
    "    else :\n",
    "        return False\n",
    "# lst1 = ['a','b',\"\\\\\",'d','e','\\\\','f','\\\\','\\\\']\n",
    "lst1 = ['g','e','b','\\\\','t','b']\n",
    "# lst1 = ['a','b',\"\\\\\",'d','\\\\','\\\\']\n",
    "lst=[]\n",
    "# lst1 = ['a',\"\\\\\",\"\\\\\",\"\\\\\",\"\\\\\"]\n",
    "lst2 = ['g', 'e', 't', 'b']\n",
    "# lst2=[]\n",
    "indices= [ i for i,item in enumerate(lst1) if item == '\\\\']\n",
    "# print(indices)\n",
    "for i,item in enumerate(indices):\n",
    "    \n",
    "    if i == 0:\n",
    "        lst.extend(lst1[:item-1])\n",
    "        \n",
    "    else:\n",
    "        lst.extend(lst1[indices[i-1]+1:item-1])\n",
    "    if len(indices) == i+1:\n",
    "        lst.extend(lst1[item+1:])\n",
    "\n",
    "check(lst,lst2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(1, 'New item-1')])\n",
      "OrderedDict([(1, 'New item-1'), (2, 'New item-2')])\n",
      "OrderedDict([(2, 'New item-2'), (1, 'New item-1')])\n",
      "OrderedDict([(2, 'New item-2'), (1, 'New item-1'), (3, 'New item-3')])\n",
      "OrderedDict([(1, 'New item-1'), (3, 'New item-3'), (2, 'New item-2')])\n",
      "OrderedDict([(3, 'New item-3'), (2, 'New item-2'), (4, 'New item-4')])\n",
      "5 not in cache\n",
      "OrderedDict([(3, 'New item-3'), (2, 'New item-2'), (4, 'New item-4')])\n",
      "OrderedDict([(2, 'New item-2'), (4, 'New item-4'), (3, 'New item-3')])\n",
      "OrderedDict([(2, 'New item-2'), (3, 'New item-3'), (4, 'New item-4')])\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    " \n",
    "class LRUCache:\n",
    " \n",
    "    # initialising capacity\n",
    "    def __init__(self, capacity: int):\n",
    "        self.cache = OrderedDict()\n",
    "        self.capacity = capacity\n",
    " \n",
    "    # we return the value of the key\n",
    "    # that is queried in O(1) and return -1 if we\n",
    "    # don't find the key in out dict / cache.\n",
    "    # And also move the key to the end\n",
    "    # to show that it was recently used.\n",
    "    def get(self, key: int) -> int:\n",
    "        if key not in self.cache:\n",
    "            print(f'{key} not in cache')\n",
    "            return -1\n",
    "        else:\n",
    "            self.cache.move_to_end(key)\n",
    "            return self.cache[key]\n",
    " \n",
    "    # first, we add / update the key by conventional methods.\n",
    "    # And also move the key to the end to show that it was recently used.\n",
    "    # But here we will also check whether the length of our\n",
    "    # ordered dictionary has exceeded our capacity,\n",
    "    # If so we remove the first key (least recently used)\n",
    "    def put(self, key: int, value: str) -> None:\n",
    "        self.cache[key] = value\n",
    "        self.cache.move_to_end(key)\n",
    "        if len(self.cache) > self.capacity:\n",
    "            self.cache.popitem(last = False)\n",
    " \n",
    " \n",
    "# RUNNER\n",
    "# initializing our cache with the capacity of 2\n",
    "cache = LRUCache(3)\n",
    " \n",
    "cache.put(1, 'New item-1')\n",
    "print(cache.cache)\n",
    "cache.put(2, 'New item-2')\n",
    "print(cache.cache)\n",
    "cache.get(1)\n",
    "print(cache.cache)\n",
    "cache.put(3, 'New item-3')\n",
    "print(cache.cache)\n",
    "cache.get(2)\n",
    "print(cache.cache)\n",
    "cache.put(4, 'New item-4')\n",
    "print(cache.cache)\n",
    "cache.get(5)\n",
    "print(cache.cache)\n",
    "cache.get(3)\n",
    "print(cache.cache)\n",
    "cache.get(4)\n",
    "print(cache.cache)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "# from DataAugmentation \n",
    "from data_utils import loadDatafromFile,createTokenizedDf,CompDataset,createkfoldData,createDataloaders\n",
    "from data_utils_unlabelled import loadUnlabelledDatafromFile,createTokenizedDfUnlabelled,CompDatasetUnlabelled\n",
    "from DataAugmentation import DataAugmentation\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from importlib import reload\n",
    "import config\n",
    "from transformers import XLMRobertaForTokenClassification, XLMRobertaConfig ,BertModel, XLMRobertaTokenizer, XLMRobertaModel, BertForTokenClassification\n",
    "from seqeval.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import matthews_corrcoef,classification_report,f1_score\n",
    "import engine\n",
    "# from model_new import EntityModel\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from  loss_functions import ClassificationCost, ConsistencyCost, update_teacher_params\n",
    "from utils_functions import set_seed, sigmoid_rampup, get_consistency_weight, EarlyStopping\n",
    "from model_xlmroberta import EntityModel , GaussianNoise\n",
    "from DataAugmentation import DataAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data_utils\n",
    "# data_utils = reload(data_utils)\n",
    "# from data_utils import loadDatafromFile,createTokenizedDf,CompDataset,createkfoldData,createDataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consistency_weight = 100.0 # max weights till you want a ramp-up, will be this value after rampup epoch is reached\n",
    "# consistency_rampup = 1000 # till what epochs rampup is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lst = np.arange(0,1500,1)\n",
    "# for item in lst :\n",
    "#     if item==1000:\n",
    "#         print(get_consistency_weight(item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.tensorboard.summary import hparams\n",
    "\n",
    "class SummaryWriter(SummaryWriter):\n",
    "    def add_hparams(self, hparam_dict, metric_dict):\n",
    "        torch._C._log_api_usage_once(\"tensorboard.logging.add_hparams\")\n",
    "        if type(hparam_dict) is not dict or type(metric_dict) is not dict:\n",
    "            raise TypeError('hparam_dict and metric_dict should be dictionary.')\n",
    "        exp, ssi, sei = hparams(hparam_dict, metric_dict)\n",
    "\n",
    "        logdir = self._get_file_writer().get_logdir()\n",
    "        \n",
    "        with SummaryWriter(log_dir=logdir) as w_hp:\n",
    "            w_hp.file_writer.add_summary(exp)\n",
    "            w_hp.file_writer.add_summary(ssi)\n",
    "            w_hp.file_writer.add_summary(sei)\n",
    "            for k, v in metric_dict.items():\n",
    "                w_hp.add_scalar(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tar_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
       "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However , a disappointing ninth in China meant...</td>\n",
       "      <td>Eine enttäuschende Neunte in China bedeutete j...</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...</td>\n",
       "      <td>OK BAD OK BAD OK BAD OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his diary , Chase wrote that the release of...</td>\n",
       "      <td>In seinem Tagebuch , Chase schrieb , dass die ...</td>\n",
       "      <td>OK OK OK OK BAD BAD OK OK OK OK OK OK OK OK BA...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>OK BAD BAD OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK BAD BAD OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once North Pacific salmon die off after spawni...</td>\n",
       "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>OK OK OK OK BAD OK OK OK OK OK BAD OK BAD OK O...</td>\n",
       "      <td>OK OK OK BAD OK OK OK BAD OK OK OK OK OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6995</th>\n",
       "      <td>Some may also discourage or disallow unsanitar...</td>\n",
       "      <td>Einige können auch unhygienische Praktiken wie...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6996</th>\n",
       "      <td>In the late 1860s , the crinolines disappeared...</td>\n",
       "      <td>In den späten 1860er Jahren verschwanden die K...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK BAD BAD OK OK OK...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6997</th>\n",
       "      <td>Disco was criticized as mindless , consumerist...</td>\n",
       "      <td>Disco wurde als geistlos , konsumistisch , übe...</td>\n",
       "      <td>OK OK OK OK BAD OK BAD OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6998</th>\n",
       "      <td>Planters would then fill large hogsheads with ...</td>\n",
       "      <td>Die Pflanzer würden dann große Heuschrecken mi...</td>\n",
       "      <td>OK OK OK BAD OK BAD OK OK BAD BAD OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6999</th>\n",
       "      <td>He slew Krishna 's most dangerous enemy , Jara...</td>\n",
       "      <td>Er tötete Krishnas gefährlichsten Feind Jarasa...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK BAD OK OK ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "0     José Ortega y Gasset visited Husserl at Freibu...   \n",
       "1     However , a disappointing ninth in China meant...   \n",
       "2     In his diary , Chase wrote that the release of...   \n",
       "3     Heavy arquebuses mounted on wagons were called...   \n",
       "4     Once North Pacific salmon die off after spawni...   \n",
       "...                                                 ...   \n",
       "6995  Some may also discourage or disallow unsanitar...   \n",
       "6996  In the late 1860s , the crinolines disappeared...   \n",
       "6997  Disco was criticized as mindless , consumerist...   \n",
       "6998  Planters would then fill large hogsheads with ...   \n",
       "6999  He slew Krishna 's most dangerous enemy , Jara...   \n",
       "\n",
       "                                                 target  \\\n",
       "0     1934 besuchte José Ortega y Gasset Husserl in ...   \n",
       "1     Eine enttäuschende Neunte in China bedeutete j...   \n",
       "2     In seinem Tagebuch , Chase schrieb , dass die ...   \n",
       "3     Schwere Arquebuses auf Waggons montiert wurden...   \n",
       "4     Sobald der nordpazifische Lachs nach dem Laich...   \n",
       "...                                                 ...   \n",
       "6995  Einige können auch unhygienische Praktiken wie...   \n",
       "6996  In den späten 1860er Jahren verschwanden die K...   \n",
       "6997  Disco wurde als geistlos , konsumistisch , übe...   \n",
       "6998  Die Pflanzer würden dann große Heuschrecken mi...   \n",
       "6999  Er tötete Krishnas gefährlichsten Feind Jarasa...   \n",
       "\n",
       "                                             src_tokens  \\\n",
       "0                      OK OK OK OK OK OK OK OK OK OK OK   \n",
       "1     OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...   \n",
       "2     OK OK OK OK BAD BAD OK OK OK OK OK OK OK OK BA...   \n",
       "3                    OK BAD BAD OK OK OK OK OK OK OK OK   \n",
       "4     OK OK OK OK BAD OK OK OK OK OK BAD OK BAD OK O...   \n",
       "...                                                 ...   \n",
       "6995  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...   \n",
       "6996  OK OK OK OK OK OK OK OK OK OK BAD BAD OK OK OK...   \n",
       "6997              OK OK OK OK BAD OK BAD OK OK OK OK OK   \n",
       "6998   OK OK OK BAD OK BAD OK OK BAD BAD OK OK OK OK OK   \n",
       "6999  OK OK OK OK OK OK OK OK OK OK OK OK BAD OK OK ...   \n",
       "\n",
       "                                             tar_tokens  \n",
       "0     OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1     OK BAD OK BAD OK BAD OK OK OK OK OK OK OK OK O...  \n",
       "2     OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...  \n",
       "3     OK OK OK BAD OK OK OK OK BAD BAD OK OK OK OK O...  \n",
       "4     OK OK OK BAD OK OK OK BAD OK OK OK OK OK OK OK...  \n",
       "...                                                 ...  \n",
       "6995  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "6996  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "6997  OK OK OK OK OK OK OK BAD OK OK OK BAD OK OK OK...  \n",
       "6998  OK OK OK OK OK BAD OK OK OK OK OK BAD OK OK OK...  \n",
       "6999  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "\n",
       "[7000 rows x 4 columns]"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataObj = loadDatafromFile(config.filePath_src,config.filePath_tar, config.filePath_srcTags,config.filePath_tarTags)\n",
    "df= dataObj.createDf() \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tar_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>José y Gasset visited Husserl at in .</td>\n",
       "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However disappointing ninth in China meant he ...</td>\n",
       "      <td>Eine enttäuschende Neunte in China bedeutete j...</td>\n",
       "      <td>OK BAD OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK BAD OK BAD OK BAD OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his diary , Chase wrote that the release of...</td>\n",
       "      <td>In seinem Tagebuch , Chase schrieb , dass die ...</td>\n",
       "      <td>OK OK OK OK BAD BAD OK OK OK OK OK OK OK BAD O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy arquebuses mounted on were arquebus à cr...</td>\n",
       "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>OK BAD BAD OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK BAD BAD OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once North Pacific salmon off after spawning ,...</td>\n",
       "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...</td>\n",
       "      <td>OK OK OK BAD OK OK OK BAD OK OK OK OK OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Marcus Valerius M. f . n Maximus Corvinus , co...</td>\n",
       "      <td>Marcus Valerius M. f. M. n. Maximus Corvinus ,...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>During the making , describes Vyjayanthimala \"...</td>\n",
       "      <td>Während der Entstehung des Führers beschreibt ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK BAD OK OK OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>defeating the attackers , he a designated rend...</td>\n",
       "      <td>Nachdem er die Angreifer besiegt hatte , ging ...</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Finally , dear friend and defender , the Elect...</td>\n",
       "      <td>Schließlich starb 1714 sein lieber Freund und ...</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK BAD OK BAD OK BAD OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>West Hertfordshire → Watford Storm → Edmonton ...</td>\n",
       "      <td>West Hertfordshire Warriors → Watford Storm → ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                source  \\\n",
       "0                José y Gasset visited Husserl at in .   \n",
       "1    However disappointing ninth in China meant he ...   \n",
       "2    In his diary , Chase wrote that the release of...   \n",
       "3    Heavy arquebuses mounted on were arquebus à cr...   \n",
       "4    Once North Pacific salmon off after spawning ,...   \n",
       "..                                                 ...   \n",
       "995  Marcus Valerius M. f . n Maximus Corvinus , co...   \n",
       "996  During the making , describes Vyjayanthimala \"...   \n",
       "997  defeating the attackers , he a designated rend...   \n",
       "998  Finally , dear friend and defender , the Elect...   \n",
       "999  West Hertfordshire → Watford Storm → Edmonton ...   \n",
       "\n",
       "                                                target  \\\n",
       "0    1934 besuchte José Ortega y Gasset Husserl in ...   \n",
       "1    Eine enttäuschende Neunte in China bedeutete j...   \n",
       "2    In seinem Tagebuch , Chase schrieb , dass die ...   \n",
       "3    Schwere Arquebuses auf Waggons montiert wurden...   \n",
       "4    Sobald der nordpazifische Lachs nach dem Laich...   \n",
       "..                                                 ...   \n",
       "995  Marcus Valerius M. f. M. n. Maximus Corvinus ,...   \n",
       "996  Während der Entstehung des Führers beschreibt ...   \n",
       "997  Nachdem er die Angreifer besiegt hatte , ging ...   \n",
       "998  Schließlich starb 1714 sein lieber Freund und ...   \n",
       "999  West Hertfordshire Warriors → Watford Storm → ...   \n",
       "\n",
       "                                            src_tokens  \\\n",
       "0                              OK OK OK OK OK OK OK OK   \n",
       "1                 OK BAD OK OK OK OK OK OK OK OK OK OK   \n",
       "2    OK OK OK OK BAD BAD OK OK OK OK OK OK OK BAD O...   \n",
       "3                         OK BAD BAD OK OK OK OK OK OK   \n",
       "4    OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...   \n",
       "..                                                 ...   \n",
       "995             OK OK OK OK OK OK OK OK OK OK OK OK OK   \n",
       "996                OK OK OK OK OK OK OK OK OK OK OK OK   \n",
       "997               OK OK OK OK OK OK OK BAD OK OK OK OK   \n",
       "998         OK OK OK BAD OK OK OK OK OK OK OK OK OK OK   \n",
       "999                      OK OK OK OK OK OK OK OK OK OK   \n",
       "\n",
       "                                            tar_tokens  \n",
       "0    OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1    OK BAD OK BAD OK BAD OK OK OK OK OK OK OK OK O...  \n",
       "2    OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...  \n",
       "3    OK OK OK BAD OK OK OK OK BAD BAD OK OK OK OK O...  \n",
       "4    OK OK OK BAD OK OK OK BAD OK OK OK OK OK OK OK...  \n",
       "..                                                 ...  \n",
       "995  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "996  OK OK OK OK OK OK OK BAD OK BAD OK OK OK OK OK...  \n",
       "997  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "998  OK OK OK OK OK OK OK BAD OK BAD OK BAD OK OK O...  \n",
       "999  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_type='xlm'\n",
    "dataaug_obj = DataAugmentation(df,swap_words=2,syn_words=4,del_words_prob=0.2,num_sentences=1)  \n",
    "# swapDataset = dataaug_obj.random_swap()\n",
    "# del_augDataset = dataaug_obj.random_deletion()\n",
    "# del_augDataset = del_augDataset[7000:]\n",
    "syn_dataset = dataaug_obj.random_deletion()\n",
    "syn_dataset = syn_dataset[7000:8000]\n",
    "syn_dataset =syn_dataset.reset_index(drop=True)\n",
    "obj_tokenized_train = createTokenizedDf(syn_dataset,model_type)\n",
    "df_new_syn = obj_tokenized_train.convertDf()\n",
    "train_data_syn = CompDataset(df_new_syn,model_type)\n",
    "syn_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['José y Gasset visited Husserl at in .',\n",
       "       '1934 besuchte José Ortega y Gasset Husserl in Freiburg .',\n",
       "       'OK OK OK OK OK OK OK OK',\n",
       "       'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn_dataset.iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_labelled(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags,\n",
    "                 filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval,train_data_needed,\n",
    "                          unlabel_data_needed ,aug_data_needed=1000,total_train_data=2000, data_aug = False, model_type='xlm'):\n",
    "    \n",
    "    set_seed()\n",
    "    dataObjTrain = loadDatafromFile(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags)\n",
    "    df_train= dataObjTrain.createDf() # get dataframe from files    \n",
    " \n",
    "    dataObjEval = loadDatafromFile(filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval)\n",
    "    df_test = dataObjEval.createDf()\n",
    "    \n",
    "    if data_aug:\n",
    "    \n",
    "        dataaug_obj = DataAugmentation(df_train,swap_words=2,syn_words=4,del_words_prob=0.2,num_sentences=1) \n",
    "        syn_dataset = dataaug_obj.random_deletion()\n",
    "        syn_dataset = syn_dataset[7000:7000+aug_data_needed]\n",
    "        syn_dataset =syn_dataset.reset_index(drop=True)\n",
    "        print('aug data needed:',aug_data_needed)\n",
    "        \n",
    "    else:\n",
    "         aug_data_needed=0\n",
    "#     df_combined = df_train.append(df_eval, ignore_index=True)\n",
    "#     df_combined.reset_index(drop=True)\n",
    "    split_ratio_len = int(len(df_train) - config.test_split_ratio*len(df_train))\n",
    "   \n",
    "    df_train_splitted = df_train.iloc[:split_ratio_len,:]\n",
    "    df_eval_splitted = df_train.iloc[split_ratio_len:,:]\n",
    "    df_train_splitted = df_train_splitted[:total_train_data]#2000\n",
    "    df_train_splitted_ = df_train_splitted[:train_data_needed] # amount of labeled data needed for training out of 2000 for eg. 250\n",
    "    eval_data_needed_ssl = int(0.25 * (unlabel_data_needed)) # 25 % reserve for validation -->500 for 2k data train\n",
    "    \n",
    "    eval_data_needed_sl = int(0.25*(train_data_needed+aug_data_needed))\n",
    "    df_eval_splitted_ssl = df_eval_splitted[:eval_data_needed_ssl] # fix this 500 for all experiments\n",
    "    df_eval_splitted_sl = df_eval_splitted[:eval_data_needed_sl] \n",
    "    \n",
    "#     df_train_splitted_ = df_train_splitted[:1000]\n",
    "    df_unlabel_splitted_train = df_train_splitted[train_data_needed:] # get remaining data in train df to be used as unlabeled\n",
    "    df_unlabel_splitted_train = df_unlabel_splitted_train.reset_index(drop=True)\n",
    "#     df_eval_splitted = df_eval_splitted[:500]\n",
    "\n",
    "#     df_unlabel_splitted_test = df_eval_splitted[eval_data_needed:]# get remaining data in eval df to use for unlabel\n",
    "#     df_unlabel_splitted_test=df_unlabel_splitted_test.reset_index(drop=True)\n",
    "    \n",
    "#     df_unlabeled = df_unlabel_splitted_train.append(df_unlabel_splitted_test, ignore_index = True) # combine both unlabel df's\n",
    "    if data_aug :\n",
    "        df_combined = df_train_splitted_.append(syn_dataset,ignore_index = True)\n",
    "    else :\n",
    "        df_combined = df_train_splitted_.copy()\n",
    "    \n",
    "    obj_tokenized_train = createTokenizedDf(df_combined,model_type)\n",
    "    obj_tokenized_eval_ssl = createTokenizedDf(df_eval_splitted_ssl,model_type)\n",
    "    obj_tokenized_eval_sl = createTokenizedDf(df_eval_splitted_sl,model_type)\n",
    "    obj_tokenized_test = createTokenizedDf(df_test,model_type)\n",
    "    \n",
    "    \n",
    "    df_new_train = obj_tokenized_train.convertDf()\n",
    "    df_new_eval_ssl = obj_tokenized_eval_ssl.convertDf()\n",
    "    df_new_eval_sl = obj_tokenized_eval_sl.convertDf()\n",
    "    df_new_test = obj_tokenized_test.convertDf()\n",
    "    \n",
    "    train_data = CompDataset(df_new_train,model_type)\n",
    "    eval_data_ssl = CompDataset(df_new_eval_ssl,model_type)\n",
    "    eval_data_sl = CompDataset(df_new_eval_sl,model_type)\n",
    "    test_data = CompDataset(df_new_test,model_type)\n",
    "    \n",
    "    return df_combined, train_data, eval_data_ssl, eval_data_sl, test_data, df_unlabel_splitted_train   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter labeled data needed 1250\n",
      "augmented data needed 0\n"
     ]
    }
   ],
   "source": [
    "total_train_data = 2000 \n",
    "label_data_required = int(input('enter labeled data needed'))\n",
    "aug_data_needed = int(input('augmented data needed'))\n",
    "unlabel_data_required = total_train_data - label_data_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_data_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>src_tokens</th>\n",
       "      <th>tar_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>José Ortega y Gasset visited Husserl at Freibu...</td>\n",
       "      <td>1934 besuchte José Ortega y Gasset Husserl in ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>However , a disappointing ninth in China meant...</td>\n",
       "      <td>Eine enttäuschende Neunte in China bedeutete j...</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...</td>\n",
       "      <td>OK BAD OK BAD OK BAD OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In his diary , Chase wrote that the release of...</td>\n",
       "      <td>In seinem Tagebuch , Chase schrieb , dass die ...</td>\n",
       "      <td>OK OK OK OK BAD BAD OK OK OK OK OK OK OK OK BA...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Heavy arquebuses mounted on wagons were called...</td>\n",
       "      <td>Schwere Arquebuses auf Waggons montiert wurden...</td>\n",
       "      <td>OK BAD BAD OK OK OK OK OK OK OK OK</td>\n",
       "      <td>OK OK OK BAD OK OK OK OK BAD BAD OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once North Pacific salmon die off after spawni...</td>\n",
       "      <td>Sobald der nordpazifische Lachs nach dem Laich...</td>\n",
       "      <td>OK OK OK OK BAD OK OK OK OK OK BAD OK BAD OK O...</td>\n",
       "      <td>OK OK OK BAD OK OK OK BAD OK OK OK OK OK OK OK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>Music theorist and musicologist Joseph Yasser ...</td>\n",
       "      <td>Schon 1951 entdeckte der Musiktheoretiker und ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>The Rolleiflex Automat combined the two , wher...</td>\n",
       "      <td>Die Rolleiflex Automat kombinierte die beiden ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK BAD BAD BAD OK BAD OK ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>In 2014 Nolan Burch , 18 , of 20 Kappa Sigma d...</td>\n",
       "      <td>Im Jahr 2014 starb Nolan Burch , 18 , von 20 K...</td>\n",
       "      <td>OK OK BAD BAD OK BAD OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK BAD OK BAD OK BAD O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>Cod , haddock , whiting , saithe , plaice , so...</td>\n",
       "      <td>Kabeljau , Schellfisch , Wittling , Seelachs ,...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>White sometimes plays 3.Nc3 , which usually tr...</td>\n",
       "      <td>Weiß spielt manchmal 3.Nc3 , die in der Regel ...</td>\n",
       "      <td>OK OK OK OK OK BAD OK BAD BAD OK OK OK BAD OK ...</td>\n",
       "      <td>OK OK OK OK OK OK OK OK OK OK BAD BAD OK BAD O...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 source  \\\n",
       "0     José Ortega y Gasset visited Husserl at Freibu...   \n",
       "1     However , a disappointing ninth in China meant...   \n",
       "2     In his diary , Chase wrote that the release of...   \n",
       "3     Heavy arquebuses mounted on wagons were called...   \n",
       "4     Once North Pacific salmon die off after spawni...   \n",
       "...                                                 ...   \n",
       "1245  Music theorist and musicologist Joseph Yasser ...   \n",
       "1246  The Rolleiflex Automat combined the two , wher...   \n",
       "1247  In 2014 Nolan Burch , 18 , of 20 Kappa Sigma d...   \n",
       "1248  Cod , haddock , whiting , saithe , plaice , so...   \n",
       "1249  White sometimes plays 3.Nc3 , which usually tr...   \n",
       "\n",
       "                                                 target  \\\n",
       "0     1934 besuchte José Ortega y Gasset Husserl in ...   \n",
       "1     Eine enttäuschende Neunte in China bedeutete j...   \n",
       "2     In seinem Tagebuch , Chase schrieb , dass die ...   \n",
       "3     Schwere Arquebuses auf Waggons montiert wurden...   \n",
       "4     Sobald der nordpazifische Lachs nach dem Laich...   \n",
       "...                                                 ...   \n",
       "1245  Schon 1951 entdeckte der Musiktheoretiker und ...   \n",
       "1246  Die Rolleiflex Automat kombinierte die beiden ...   \n",
       "1247  Im Jahr 2014 starb Nolan Burch , 18 , von 20 K...   \n",
       "1248  Kabeljau , Schellfisch , Wittling , Seelachs ,...   \n",
       "1249  Weiß spielt manchmal 3.Nc3 , die in der Regel ...   \n",
       "\n",
       "                                             src_tokens  \\\n",
       "0                      OK OK OK OK OK OK OK OK OK OK OK   \n",
       "1     OK OK OK BAD OK OK OK OK OK OK OK OK OK OK OK ...   \n",
       "2     OK OK OK OK BAD BAD OK OK OK OK OK OK OK OK BA...   \n",
       "3                    OK BAD BAD OK OK OK OK OK OK OK OK   \n",
       "4     OK OK OK OK BAD OK OK OK OK OK BAD OK BAD OK O...   \n",
       "...                                                 ...   \n",
       "1245  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...   \n",
       "1246  OK OK OK OK OK OK OK OK BAD BAD BAD OK BAD OK ...   \n",
       "1247  OK OK BAD BAD OK BAD OK OK OK OK OK OK OK OK O...   \n",
       "1248  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...   \n",
       "1249  OK OK OK OK OK BAD OK BAD BAD OK OK OK BAD OK ...   \n",
       "\n",
       "                                             tar_tokens  \n",
       "0     OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1     OK BAD OK BAD OK BAD OK OK OK OK OK OK OK OK O...  \n",
       "2     OK OK OK OK OK OK OK OK OK BAD OK BAD OK OK OK...  \n",
       "3     OK OK OK BAD OK OK OK OK BAD BAD OK OK OK OK O...  \n",
       "4     OK OK OK BAD OK OK OK BAD OK OK OK OK OK OK OK...  \n",
       "...                                                 ...  \n",
       "1245  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1246  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1247  OK OK OK OK OK OK OK OK OK BAD OK BAD OK BAD O...  \n",
       "1248  OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK O...  \n",
       "1249  OK OK OK OK OK OK OK OK OK OK BAD BAD OK BAD O...  \n",
       "\n",
       "[1250 rows x 4 columns]"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed()\n",
    "df, train_data , eval_data_ssl,eval_data_sl, test_data, df_unlabel = process_data_labelled(config.filePath_src,config.filePath_tar, config.filePath_srcTags,config.filePath_tarTags,\n",
    "                                                config.filePath_src_eval,config.filePath_tar_eval, config.filePath_srcTags_eval,\n",
    "                                                config.filePath_tarTags_eval,label_data_required,unlabel_data_required, aug_data_needed,total_train_data,data_aug=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['José Ortega y Gasset visited Husserl at Freiburg in 1934 .',\n",
       "       '1934 besuchte José Ortega y Gasset Husserl in Freiburg .',\n",
       "       'OK OK OK OK OK OK OK OK OK OK OK',\n",
       "       'OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK OK'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.iloc[1000].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled data 1250\n",
      "ssl eval data 187\n",
      "sl eval data 312\n",
      "unlabel data 750\n",
      "test data 1000\n"
     ]
    }
   ],
   "source": [
    "len_labelled_data = len(train_data)\n",
    "len_eval_data_ssl = len(eval_data_ssl)\n",
    "print('labeled data',len_labelled_data)\n",
    "print('ssl eval data',len_eval_data_ssl)\n",
    "print('sl eval data',len(eval_data_sl))\n",
    "print('unlabel data',len(df_unlabel))\n",
    "print('test data',len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([     0,  17151,  12426,   2765,    113,    527, 110896,  36997,     71,\n",
      "         20387,   2189,    141,     99, 183124,     23,  58020,      6,      5,\n",
      "             2,      2,    656,  58020,    656, 138438,     13,    656,  17151,\n",
      "           656,  12426,   2765,    656,    113,    656,    527, 110896,    656,\n",
      "         20387,   2189,    141,    656,     23,    656, 183124,    656,      6,\n",
      "             5,    656,      2,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1])\n",
      "tensor([     0, 121220,  14432, 122273,      7,    450,   2412,    290,  27686,\n",
      "            98,   1155,     66,      6,      4,   3129,   5809,   3564,     70,\n",
      "         76755,      6,      5,      2,      2,    656, 121220,    656,    493,\n",
      "         65512,    656,  38985,    656,      6,      4,    656,   1421,    656,\n",
      "          1329,    656,   1155,     66,    656,   1600,  79556,    656,   1256,\n",
      "           656,      6,      4,    656,    509,    656,     68,    656,  93577,\n",
      "           656,   2809,    555,    656,  25482,    656,      6,      5,    656,\n",
      "             2,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_data))[0]) # 0,17151,12456,..\n",
    "print(next(iter(eval_data_ssl))[0])#121220,.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n",
      "39\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(train_data,config.TRAIN_BATCH_SIZE)\n",
    "train_dataloader = loader_obj.createDataloaders()\n",
    "print(len(train_dataloader))\n",
    "loader_obj = createDataloaders(eval_data_sl,config.TRAIN_BATCH_SIZE)\n",
    "val_dataloader = loader_obj.createDataloaders()\n",
    "print(len(val_dataloader))\n",
    "loader_obj = createDataloaders(test_data,config.TRAIN_BATCH_SIZE)\n",
    "test_dataloader = loader_obj.createDataloaders()\n",
    "len(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'augsupervised_del_with_1000_labeled_data_1000_aug_data'"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name_supervised =f'augsupervised_del_{label_data_required}_labeled_data_{aug_data_needed}_aug_data'\n",
    "model_name_supervised = f'augsupervised_del_with_{label_data_required}_labeled_data_{aug_data_needed}_aug_data'\n",
    "#augsupervised_1000_labeled_data_1000_aug_data\n",
    "#augsupervised_with_1000_labeled_data_1000_aug_data\n",
    "model_name_supervised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_supervised = SummaryWriter(f\"runs/AugSupervised_and_PseudoLabelingTraining/augsupervised_del_{label_data_required}_labeled_data_{aug_data_needed}_aug_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EntityModel(with_noise_layer = False, dropout_layer=True)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "num_train_steps = int(len(train_data) / config.TRAIN_BATCH_SIZE * config.EPOCHS) #10 is the batchsize\n",
    "optimizer = AdamW(optimizer_parameters, lr=2e-5) # used 3e-5\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    ")\n",
    "early_stopping = EarlyStopping(patience=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 250/250 [01:09<00:00,  3.58it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.78      0.35     17706\n",
      "           1       0.95      0.60      0.73    119610\n",
      "\n",
      "    accuracy                           0.62    137316\n",
      "   macro avg       0.59      0.69      0.54    137316\n",
      "weighted avg       0.86      0.62      0.68    137316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.3818100530114326\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8202766688329776\n",
      "Average Accuracy Validation score whole sentence  : 0.7215157095177811\n",
      "Average mcc Validation score whole sentence : 0.2881328338782766\n",
      "Average F1 Validation score for source sentence class 0 : 0.3620488940628638\n",
      "Average F1 Validation score for source sentence class 1 : 0.7672294786025273\n",
      "Average Accuracy Validation score source sentence  : 0.6589123161907726\n",
      "Average mcc Validation score source sentence : 0.2386415841112184\n",
      "Average F1 Validation score for target sentence class 0 : 0.40799625906008885\n",
      "Average F1 Validation score for target sentence class 1 : 0.7251411202778985\n",
      "Average Accuracy Validation score target sentence  : 0.6245829935503002\n",
      "Average mcc Validation score target sentence : 0.2603111175561542\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.0\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.986081822016027\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9725457570715474\n",
      "Average mcc Validation score gaps in target sentence : -0.0025791331593380687\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.39726807057484353\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8488050027126581\n",
      "Average Accuracy Validation score whole target sentence  : 0.7582522942062732\n",
      "Average mcc Validation score whole target sentence : 0.3187456403841941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.68      0.38      4418\n",
      "           1       0.94      0.73      0.82     30338\n",
      "\n",
      "    accuracy                           0.72     34756\n",
      "   macro avg       0.60      0.70      0.60     34756\n",
      "weighted avg       0.85      0.72      0.76     34756\n",
      "\n",
      "Train Loss = 0.5896503734588623 Valid Loss = 0.6010127890677679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved for this epoch!\n",
      "Epoch 2 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 250/250 [01:11<00:00,  3.50it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.80      0.45     17706\n",
      "           1       0.96      0.74      0.84    119610\n",
      "\n",
      "    accuracy                           0.75    137316\n",
      "   macro avg       0.64      0.77      0.64    137316\n",
      "weighted avg       0.88      0.75      0.79    137316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 63/63 [00:03<00:00, 15.98it/s]\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.3839417494834203\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8945053834099985\n",
      "Average Accuracy Validation score whole sentence  : 0.8198584417079066\n",
      "Average mcc Validation score whole sentence : 0.28386720240769864\n",
      "Average F1 Validation score for source sentence class 0 : 0.3622011727559766\n",
      "Average F1 Validation score for source sentence class 1 : 0.8670552839413314\n",
      "Average Accuracy Validation score source sentence  : 0.7799735470318213\n",
      "Average mcc Validation score source sentence : 0.23901611909589845\n",
      "Average F1 Validation score for target sentence class 0 : 0.4183412495432955\n",
      "Average F1 Validation score for target sentence class 1 : 0.8519345238095237\n",
      "Average Accuracy Validation score target sentence  : 0.7639558158499518\n",
      "Average mcc Validation score target sentence : 0.2782979191071731\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.023529411764705882\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9849755626621612\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9704064654147849\n",
      "Average mcc Validation score gaps in target sentence : 0.0301678409301577\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.4007680223424681\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9098405861806339\n",
      "Average Accuracy Validation score whole target sentence  : 0.8432634798885997\n",
      "Average mcc Validation score whole target sentence : 0.31367857429702567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.44      0.38      4418\n",
      "           1       0.91      0.87      0.89     30338\n",
      "\n",
      "    accuracy                           0.82     34756\n",
      "   macro avg       0.63      0.66      0.64     34756\n",
      "weighted avg       0.84      0.82      0.83     34756\n",
      "\n",
      "Train Loss = 0.49648559594154357 Valid Loss = 0.7142696319118379\n",
      "Epoch 3 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 250/250 [01:12<00:00,  3.43it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.85      0.55     17706\n",
      "           1       0.97      0.82      0.89    119610\n",
      "\n",
      "    accuracy                           0.82    137316\n",
      "   macro avg       0.69      0.83      0.72    137316\n",
      "weighted avg       0.90      0.82      0.85    137316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 63/63 [00:03<00:00, 15.98it/s]\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.389030612244898\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9043657660055903\n",
      "Average Accuracy Validation score whole sentence  : 0.8346184831396017\n",
      "Average mcc Validation score whole sentence : 0.29453319250893334\n",
      "Average F1 Validation score for source sentence class 0 : 0.36465210766886746\n",
      "Average F1 Validation score for source sentence class 1 : 0.8850606394707827\n",
      "Average Accuracy Validation score source sentence  : 0.8053372753442776\n",
      "Average mcc Validation score source sentence : 0.251087990422567\n",
      "Average F1 Validation score for target sentence class 0 : 0.4318360914105595\n",
      "Average F1 Validation score for target sentence class 1 : 0.8683225276230481\n",
      "Average Accuracy Validation score target sentence  : 0.7861961598339388\n",
      "Average mcc Validation score target sentence : 0.3022823642050631\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.08121827411167512\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9779724960447853\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9569764677917756\n",
      "Average mcc Validation score gaps in target sentence : 0.06062902568526503\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.40658135283363805\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9153276293823038\n",
      "Average Accuracy Validation score whole target sentence  : 0.8518011231338173\n",
      "Average mcc Validation score whole target sentence : 0.32289675798675244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.41      0.39      4418\n",
      "           1       0.91      0.90      0.90     30338\n",
      "\n",
      "    accuracy                           0.83     34756\n",
      "   macro avg       0.64      0.66      0.65     34756\n",
      "weighted avg       0.84      0.83      0.84     34756\n",
      "\n",
      "Train Loss = 0.3891817507147789 Valid Loss = 0.8919012104234998\n",
      "Epoch 4 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 250/250 [01:13<00:00,  3.41it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.89      0.65     17706\n",
      "           1       0.98      0.87      0.92    119610\n",
      "\n",
      "    accuracy                           0.88    137316\n",
      "   macro avg       0.75      0.88      0.79    137316\n",
      "weighted avg       0.92      0.88      0.89    137316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 63/63 [00:04<00:00, 15.71it/s]\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.3495814869522403\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9139245455137812\n",
      "Average Accuracy Validation score whole sentence  : 0.8479686960524802\n",
      "Average mcc Validation score whole sentence : 0.26556218766552747\n",
      "Average F1 Validation score for source sentence class 0 : 0.32815704658658074\n",
      "Average F1 Validation score for source sentence class 1 : 0.8971426008163997\n",
      "Average Accuracy Validation score source sentence  : 0.8215980704893799\n",
      "Average mcc Validation score source sentence : 0.2268991450484691\n",
      "Average F1 Validation score for target sentence class 0 : 0.3898617511520737\n",
      "Average F1 Validation score for target sentence class 1 : 0.8830285360897606\n",
      "Average Accuracy Validation score target sentence  : 0.8036918971013418\n",
      "Average mcc Validation score target sentence : 0.27521820226172583\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.07547169811320754\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9791578051892811\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.959234608985025\n",
      "Average mcc Validation score gaps in target sentence : 0.05747255284967772\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.36510295054128633\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9234940529479473\n",
      "Average Accuracy Validation score whole target sentence  : 0.8634433639227503\n",
      "Average mcc Validation score whole target sentence : 0.2910355848991788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.32      0.35      4418\n",
      "           1       0.90      0.92      0.91     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.64      0.62      0.63     34756\n",
      "weighted avg       0.84      0.85      0.84     34756\n",
      "\n",
      "Train Loss = 0.2962724798321724 Valid Loss = 1.2019189492104545\n",
      "Epoch 5 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 250/250 [01:13<00:00,  3.41it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.91      0.71     17706\n",
      "           1       0.99      0.90      0.94    119610\n",
      "\n",
      "    accuracy                           0.90    137316\n",
      "   macro avg       0.78      0.91      0.83    137316\n",
      "weighted avg       0.93      0.90      0.91    137316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 63/63 [00:03<00:00, 15.81it/s]\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.3734884782112708\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9095907549468278\n",
      "Average Accuracy Validation score whole sentence  : 0.8419841178501554\n",
      "Average mcc Validation score whole sentence : 0.2830976492293232\n",
      "Average F1 Validation score for source sentence class 0 : 0.35699152542372886\n",
      "Average F1 Validation score for source sentence class 1 : 0.8892840857273142\n",
      "Average Accuracy Validation score source sentence  : 0.81109468606551\n",
      "Average mcc Validation score source sentence : 0.24648538629763728\n",
      "Average F1 Validation score for target sentence class 0 : 0.4097371822490306\n",
      "Average F1 Validation score for target sentence class 1 : 0.8773280802292263\n",
      "Average Accuracy Validation score target sentence  : 0.7968715249462525\n",
      "Average mcc Validation score target sentence : 0.28712500495251303\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.06896551724137931\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9803398058252427\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9614927501782743\n",
      "Average mcc Validation score gaps in target sentence : 0.05419495922383606\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.38597194388777556\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9210634789777412\n",
      "Average Accuracy Validation score whole target sentence  : 0.8601104871478793\n",
      "Average mcc Validation score whole target sentence : 0.3073659971754024\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.37      0.37      4418\n",
      "           1       0.91      0.91      0.91     30338\n",
      "\n",
      "    accuracy                           0.84     34756\n",
      "   macro avg       0.64      0.64      0.64     34756\n",
      "weighted avg       0.84      0.84      0.84     34756\n",
      "\n",
      "Train Loss = 0.23513282497227192 Valid Loss = 1.37883309428654\n",
      "Epoch 6 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 250/250 [01:12<00:00,  3.43it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.76     17706\n",
      "           1       0.99      0.92      0.95    119610\n",
      "\n",
      "    accuracy                           0.92    137316\n",
      "   macro avg       0.81      0.93      0.86    137316\n",
      "weighted avg       0.94      0.92      0.93    137316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 63/63 [00:03<00:00, 15.99it/s]\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.3484156995696962\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9191986158498132\n",
      "Average Accuracy Validation score whole sentence  : 0.8562262630912648\n",
      "Average mcc Validation score whole sentence : 0.2737217279123472\n",
      "Average F1 Validation score for source sentence class 0 : 0.338660110633067\n",
      "Average F1 Validation score for source sentence class 1 : 0.9041510778549796\n",
      "Average Accuracy Validation score source sentence  : 0.8325682719987552\n",
      "Average mcc Validation score source sentence : 0.24738118719697247\n",
      "Average F1 Validation score for target sentence class 0 : 0.37753587333003463\n",
      "Average F1 Validation score for target sentence class 1 : 0.8903034530868504\n",
      "Average Accuracy Validation score target sentence  : 0.813477648454296\n",
      "Average mcc Validation score target sentence : 0.2763599575256956\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.11796246648793565\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9800060771801884\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9608985024958403\n",
      "Average mcc Validation score gaps in target sentence : 0.10182618922037644\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.3556058890147225\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9277753801629813\n",
      "Average Accuracy Validation score whole target sentence  : 0.8701091174724923\n",
      "Average mcc Validation score whole target sentence : 0.2907939194678886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.30      0.35      4418\n",
      "           1       0.90      0.94      0.92     30338\n",
      "\n",
      "    accuracy                           0.86     34756\n",
      "   macro avg       0.66      0.62      0.63     34756\n",
      "weighted avg       0.84      0.86      0.85     34756\n",
      "\n",
      "Train Loss = 0.19199871738255023 Valid Loss = 1.8924762275483873\n",
      "Epoch 7 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 250/250 [01:13<00:00,  3.42it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.94      0.80     17706\n",
      "           1       0.99      0.94      0.96    119610\n",
      "\n",
      "    accuracy                           0.94    137316\n",
      "   macro avg       0.84      0.94      0.88    137316\n",
      "weighted avg       0.95      0.94      0.94    137316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 63/63 [00:03<00:00, 16.01it/s]\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.3781204926217686\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9073538405593481\n",
      "Average Accuracy Validation score whole sentence  : 0.8387328806537001\n",
      "Average mcc Validation score whole sentence : 0.2855880860151614\n",
      "Average F1 Validation score for source sentence class 0 : 0.36681928359816857\n",
      "Average F1 Validation score for source sentence class 1 : 0.8931023507479653\n",
      "Average Accuracy Validation score source sentence  : 0.8170855053294951\n",
      "Average mcc Validation score source sentence : 0.25995167388132046\n",
      "Average F1 Validation score for target sentence class 0 : 0.4143611404435058\n",
      "Average F1 Validation score for target sentence class 1 : 0.8753315649867374\n",
      "Average Accuracy Validation score target sentence  : 0.794425087108014\n",
      "Average mcc Validation score target sentence : 0.2897104001449521\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.14867256637168144\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9704236610711432\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9428333729498455\n",
      "Average mcc Validation score gaps in target sentence : 0.12256275714732817\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.38603773584905654\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9154936892951748\n",
      "Average Accuracy Validation score whole target sentence  : 0.8514358763639684\n",
      "Average mcc Validation score whole target sentence : 0.3017347458614705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.39      0.38      4418\n",
      "           1       0.91      0.90      0.91     30338\n",
      "\n",
      "    accuracy                           0.84     34756\n",
      "   macro avg       0.64      0.65      0.64     34756\n",
      "weighted avg       0.84      0.84      0.84     34756\n",
      "\n",
      "Train Loss = 0.15879942828416824 Valid Loss = 1.7201806614323267\n",
      "Epoch 8 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 250/250 [01:13<00:00,  3.42it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83     17706\n",
      "           1       0.99      0.95      0.97    119610\n",
      "\n",
      "    accuracy                           0.95    137316\n",
      "   macro avg       0.86      0.95      0.90    137316\n",
      "weighted avg       0.96      0.95      0.95    137316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 63/63 [00:03<00:00, 15.90it/s]\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.34191222180778313\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9138915550928111\n",
      "Average Accuracy Validation score whole sentence  : 0.8477097479571872\n",
      "Average mcc Validation score whole sentence : 0.2583559320944871\n",
      "Average F1 Validation score for source sentence class 0 : 0.3277511961722488\n",
      "Average F1 Validation score for source sentence class 1 : 0.8994723191127806\n",
      "Average Accuracy Validation score source sentence  : 0.8250991986306698\n",
      "Average mcc Validation score source sentence : 0.22985839005477063\n",
      "Average F1 Validation score for target sentence class 0 : 0.3752645191629438\n",
      "Average F1 Validation score for target sentence class 1 : 0.8830803080308031\n",
      "Average Accuracy Validation score target sentence  : 0.8030246867818223\n",
      "Average mcc Validation score target sentence : 0.2619454295005045\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.13004484304932734\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9763154681968014\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9538863798431186\n",
      "Average mcc Validation score gaps in target sentence : 0.10641857504679199\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.35198978506065115\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9221367018692306\n",
      "Average Accuracy Validation score whole target sentence  : 0.8609779482262704\n",
      "Average mcc Validation score whole target sentence : 0.27663660832262527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.31      0.34      4418\n",
      "           1       0.90      0.93      0.91     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.64      0.62      0.63     34756\n",
      "weighted avg       0.84      0.85      0.84     34756\n",
      "\n",
      "Train Loss = 0.1357577053308487 Valid Loss = 1.9934496444369119\n",
      "Epoch 9 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 250/250 [01:13<00:00,  3.42it/s]\n",
      "  0%|          | 0/63 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86     17706\n",
      "           1       0.99      0.96      0.98    119610\n",
      "\n",
      "    accuracy                           0.96    137316\n",
      "   macro avg       0.89      0.96      0.92    137316\n",
      "weighted avg       0.97      0.96      0.96    137316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 63/63 [00:03<00:00, 15.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.34809272660370416\n",
      "Average F1 Validation score for whole sentence class 1 : 0.9133786404602423\n",
      "Average Accuracy Validation score whole sentence  : 0.847076763724249\n",
      "Average mcc Validation score whole sentence : 0.26334581109778266\n",
      "Average F1 Validation score for source sentence class 0 : 0.32965064198268135\n",
      "Average F1 Validation score for source sentence class 1 : 0.8995840229011048\n",
      "Average Accuracy Validation score source sentence  : 0.8253326071734225\n",
      "Average mcc Validation score source sentence : 0.23179505645661336\n",
      "Average F1 Validation score for target sentence class 0 : 0.38518863530507685\n",
      "Average F1 Validation score for target sentence class 1 : 0.8836184094515958\n",
      "Average Accuracy Validation score target sentence  : 0.8042849729409148\n",
      "Average mcc Validation score target sentence : 0.27178945108148667\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.1568627450980392\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9736487314621891\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9488946993106727\n",
      "Average mcc Validation score gaps in target sentence : 0.13152249589048165\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.36094920899250627\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9212860878929285\n",
      "Average Accuracy Validation score whole target sentence  : 0.8598365520704926\n",
      "Average mcc Validation score whole target sentence : 0.28370355007897335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.32      0.35      4418\n",
      "           1       0.90      0.92      0.91     30338\n",
      "\n",
      "    accuracy                           0.85     34756\n",
      "   macro avg       0.64      0.62      0.63     34756\n",
      "weighted avg       0.84      0.85      0.84     34756\n",
      "\n",
      "Train Loss = 0.10718645237386226 Valid Loss = 2.271095497267587\n",
      "terminating because of early stopping!\n"
     ]
    }
   ],
   "source": [
    "set_seed()\n",
    "best_accuracy = -1\n",
    "train_loss_lst = []\n",
    "val_loss_lst = []\n",
    "with open(f'../Logs/AugSupervised_logs/{experiment_name_supervised}', 'w') as f:\n",
    "    f.write(f'{experiment_name_supervised}'+'\\n')\n",
    "    for epoch in range(config.EPOCHS):\n",
    "            print(f'Epoch {epoch+1} of {config.EPOCHS}')\n",
    "            train_metrics = engine.train_fn(train_dataloader, model, optimizer, scheduler)\n",
    "            print(classification_report(train_metrics[21],train_metrics[22]))\n",
    "            test_metrics = engine.eval_fn(val_dataloader, model)\n",
    "            print(classification_report(test_metrics[21],test_metrics[22]))\n",
    "#             print('For gaps : ',classification_report(test_metrics[27],test_metrics[28]) )\n",
    "#             print('For tar :',classification_report(test_metrics[25],test_metrics[26]) )\n",
    "#             print('For source : ',classification_report(test_metrics[23],test_metrics[24]) )\n",
    "            print(f\"Train Loss = {train_metrics[0]} Valid Loss = {test_metrics[0]}\")\n",
    "            writer_supervised.add_scalar('Train_loss/Supervised',train_metrics[0], epoch)\n",
    "            writer_supervised.add_scalar('Validation_loss/Supervised',test_metrics[0],epoch)\n",
    "            writer_supervised.add_scalar('mcc_score/Supervised_validation',test_metrics[4],epoch)\n",
    "            writer_supervised.add_scalar('mcc_score/Supervised_train',train_metrics[4],epoch)\n",
    "            train_loss_lst.append(train_metrics[:-14])\n",
    "            val_loss_lst.append(test_metrics[:-14])\n",
    "            f.write(f\"Train_loss {epoch+1} : {str(train_loss_lst)}\" + '\\n')\n",
    "            f.write(f\"val_loss {epoch+1} : {str(val_loss_lst)}\" + '\\n')\n",
    "            \n",
    "            if early_stopping.step(float(\"{:.2f}\".format(test_metrics[4]))): #mcc score for early stopping \"{:.2f}\".format(a_float)\n",
    "                  break  # early stop criterion is met, we can stop now\n",
    "            if float(\"{:.2f}\".format(test_metrics[4])) >  best_accuracy:\n",
    "                torch.save(model.state_dict(), f'../models/augmented_data/{model_name_supervised}.bin')\n",
    "                best_accuracy = float(\"{:.2f}\".format(test_metrics[4]))\n",
    "                print('Model saved for this epoch!')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the labelled data\n",
    "# def process_data_labelled(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags,\n",
    "#                  filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval,\n",
    "#                  model_type='xlm'):\n",
    "    \n",
    "    \n",
    "#     dataObjTrain = loadDatafromFile(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags)\n",
    "#     df_train= dataObjTrain.createDf() # get dataframe from files    \n",
    "#     df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
    "#     df_train=df_train.iloc[:500,:]\n",
    "#     dataObjEval = loadDatafromFile(filePath_src_eval,filePath_tar_eval, filePath_srcTags_eval,filePath_tarTags_eval)\n",
    "#     df_eval = dataObjEval.createDf()\n",
    "#     obj_tokenized_train = createTokenizedDf(df_train,model_type)\n",
    "#     obj_tokenized_test = createTokenizedDf(df_eval,model_type)\n",
    "#     df_new_train = obj_tokenized_train.convertDf()\n",
    "#     df_new_eval = obj_tokenized_test.convertDf()\n",
    "#     train_data = CompDataset(df_new_train,model_type)\n",
    "#     test_data = CompDataset(df_new_eval,model_type)\n",
    "#     return train_data,test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 125/125 [00:07<00:00, 16.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.39738322482776056\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8247394253570838\n",
      "Average Accuracy Validation score whole sentence  : 0.7284534320706352\n",
      "Average mcc Validation score whole sentence : 0.3013759352012734\n",
      "Average F1 Validation score for source sentence class 0 : 0.38081458438833826\n",
      "Average F1 Validation score for source sentence class 1 : 0.7742701163066699\n",
      "Average Accuracy Validation score source sentence  : 0.6691534596057209\n",
      "Average mcc Validation score source sentence : 0.2571879817264198\n",
      "Average F1 Validation score for target sentence class 0 : 0.4210647614657755\n",
      "Average F1 Validation score for target sentence class 1 : 0.7291498193972721\n",
      "Average Accuracy Validation score target sentence  : 0.6309545671576009\n",
      "Average mcc Validation score target sentence : 0.26634415636998077\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.004319654427645789\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9863540834147352\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9730771476960813\n",
      "Average mcc Validation score gaps in target sentence : 0.013231395314939014\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.4102362646613166\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8517374190544716\n",
      "Average Accuracy Validation score whole target sentence  : 0.76304396843292\n",
      "Average mcc Validation score whole target sentence : 0.32822644594566774\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'../models/augmented_data/{model_name_supervised}.bin'))\n",
    "model.eval()\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "mcc_score_supervised = test_metrics[4]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer_supervised.add_hparams(\n",
    "                    { \"lr\": float(config.lr),  \n",
    "                     \"labelled_data\": float(len(train_data)), \n",
    "                     \"validation_data\": float(len(eval_data_sl)),\n",
    "                     \"alpha\":0.0, \n",
    "                     \"teacher_noise_gaussian_std\":0.0,\n",
    "                     \"student_noise_gaussian_std\":0.0,\n",
    "                     \"unlabelled_data\":0.0, \n",
    "                    },\n",
    "                    {\n",
    "                    \"mcc_score_test\" : float(mcc_score_supervised),\n",
    "                    \"mcc_score_teacher\": float(0) ,\n",
    "                    \"mcc_score_student\" : float(0),\n",
    "                    },\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_unlabelled(filePath_src,filePath_tar,df_unlabel, unlabel_data_needed, model_type):\n",
    "    \n",
    "    set_seed()\n",
    "    dataObj = loadUnlabelledDatafromFile(filePath_src,filePath_tar)\n",
    "    df= dataObj.createDfUnlabelled() # get dataframe from files\n",
    "    df['len_src'] = df['source'].str.split().map(lambda x:len(x))\n",
    "    df['len_tar'] = df['target'].str.split().map(lambda x:len(x))\n",
    "    \n",
    "    df = df[df.len_tar != 36]\n",
    "    df = df[df.len_tar != 2]\n",
    "    df = df[df.len_src != 1]\n",
    "    \n",
    "    df=df.iloc[:,:-2]\n",
    "#     df=df.iloc[:1000,:]\n",
    "#     df = df[:2000]\n",
    "    if unlabel_data_needed > len(df_unlabel):\n",
    "        \n",
    "        extra_data_needed = unlabel_data_needed - len(df_unlabel) # TAKE IT FROM THE BACKTRANSLATED DATASET\n",
    "        df = df[:extra_data_needed]\n",
    "        df_unlabel = df_unlabel.append(df,ignore_index=True)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        df_unlabel = df_unlabel[:unlabel_data_needed]\n",
    "        \n",
    "    obj_tokenized = createTokenizedDfUnlabelled(df_unlabel,model_type) # change to df\n",
    "    df_new = obj_tokenized.convertDf()\n",
    "#     enc_label = preprocessing.LabelEncoder()\n",
    "#     df_new['labels']= enc_label.fit_transform(df_new['labels'])\n",
    "    train_data = CompDatasetUnlabelled(df_new,model_type)\n",
    "    return df_new,train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([     0,  10660,  90254,     33,    297,   2363,  61475,  84616,    678,\n",
       "            158,   1916,  35066,   1295, 105355,   1174,      6,      4,   1172,\n",
       "            408,   3390,      6,      4,   5631,     73,    927,      6,      4,\n",
       "            136,  26842,    219,      6,      5,      2,      2,    656,    727,\n",
       "            656,      6,  43999,    510,    656,   9047,    656,    142,    420,\n",
       "          20954,  12512,    656, 227144,    656,    491,    656,  42990,   6475,\n",
       "            510,    656,   1312,    656, 105355,   1174,    656,      6,      4,\n",
       "            656,   1172,    408,   3390,    656,      6,      4,    656,   3970,\n",
       "             73,    927,    656,    165,    656,  26842,    219,    656,      6,\n",
       "              5,    656,      2,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100]))"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unlabelled_train, dataset_train_unlabelled = process_data_unlabelled(config.filePath_src_backtranslated,config.filePath_tar_backtranslated,df_unlabel,\n",
    "                                                                       unlabel_data_required, model_type = 'xlm')\n",
    "len_unlabelled_data = len(dataset_train_unlabelled)\n",
    "print(len_unlabelled_data)\n",
    "temp_val = next(iter(dataset_train_unlabelled)) # 31384,..\n",
    "temp_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_data_unlabelled(filePath_src,filePath_tar,len_train_data,df_unlabelled_train,model_type):\n",
    "    \n",
    "#     dataObj = loadUnlabelledDatafromFile(filePath_src,filePath_tar)\n",
    "#     df= dataObj.createDfUnlabelled() # get dataframe from files\n",
    "#     df['len_src'] = df['source'].str.split().map(lambda x:len(x))\n",
    "#     df['len_tar'] = df['target'].str.split().map(lambda x:len(x))\n",
    "    \n",
    "#     df = df[df.len_tar != 36]\n",
    "#     df = df[df.len_tar != 2]\n",
    "#     df = df[df.len_src != 1]\n",
    "    \n",
    "#     df = df.iloc[:,:-2]\n",
    "#     df = df.reset_index(drop=True)\n",
    "#     df_unlabelled_train = df_unlabelled_train.iloc[:,:-2]\n",
    "#     df_new = df.append(df_unlabelled_train, ignore_index = True)\n",
    "#     len_unlabelled_needed = config.fix_train_size - len_train_data\n",
    "#     df_new=df_new[:len_unlabelled_needed]\n",
    "# #     print(df_new)\n",
    "    \n",
    "#     obj_tokenized = createTokenizedDfUnlabelled(df_new,model_type)\n",
    "#     df_unlabelled= obj_tokenized.convertDf()\n",
    "# #     enc_label = preprocessing.LabelEncoder()\n",
    "# #     df_new['labels']= enc_label.fit_transform(df_new['labels'])\n",
    "#     train_data = CompDatasetUnlabelled(df_unlabelled,model_type)\n",
    "#     return df_new,train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabel_data_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combining 2 tuples --> labelled and unlabelled data \n",
    "combined_Data =  dataset_train_unlabelled\n",
    "len(combined_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataloaders\n",
    "loader_obj = createDataloaders(combined_Data,config.TRAIN_BATCH_SIZE)\n",
    "train_dataloader = loader_obj.createDataloaders()\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(eval_data_ssl,config.VALID_BATCH_SIZE)\n",
    "val_dataloader = loader_obj.createDataloaders()\n",
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noise = GaussianNoise(0.7)\n",
    "# print(noise(a))\n",
    "# print(torch.randn(a.size()) * 0.7 )\n",
    "# print(torch.autograd.Variable(torch.randn(a.size()).cuda() * 0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = EntityModel(std_gaussian=config.gaussian_noise_std_student, with_noise_layer=True )\n",
    "# model.cuda()# print(noise ,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs, outputs1 = model(batch[0].cuda(), attention_mask = batch[1].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2 = EntityModel(std_gaussian=config.gaussian_noise_std_teacher)\n",
    "# model2.cuda()\n",
    "# outputs, outputs1 = model2(batch[0].cuda(), attention_mask = batch[1].cuda())\n",
    "# print(outputs,'\\n')\n",
    "# print(outputs1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationCost(output,hard_labels_pseudo,mask,label_mask):\n",
    "    \n",
    "    \n",
    "    active_loss = label_mask.view(-1) & mask.view(-1)#loss calculation for non padded tokens only (mask =1)\n",
    "    active_loss = active_loss.bool()\n",
    "    \n",
    "    active_logits = output.view(-1,2)\n",
    "    \n",
    "    active_labels = torch.where( # just append -100 for the padded tokens so its ignored when computing loss , no need now\n",
    "        active_loss,             # since its handled in preprocessing only\n",
    "        hard_labels_pseudo.view(-1),\n",
    "        torch.tensor(-100).type_as(hard_labels_pseudo)    \n",
    "    )\n",
    "    try:\n",
    "        class_0_weights =1/len(torch.where(active_labels==0)[0]) # trying to weight the labels as its unbalanced mostly\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        class_0_weights = float(1)\n",
    "\n",
    "    try:\n",
    "        class_1_weights =1/len(torch.where(active_labels==1)[0])\n",
    "    \n",
    "    except:\n",
    "        class_1_weights = float(1)\n",
    "    \n",
    "    weights_tensor = torch.tensor([class_0_weights,class_1_weights]).cuda()\n",
    "    lfn = nn.CrossEntropyLoss(weight = weights_tensor)\n",
    "    loss = lfn(active_logits,active_labels)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ClassificationCost_eval(output,target,mask):\n",
    "    \n",
    "    \n",
    "    active_loss = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "    active_logits = output.view(-1,2)\n",
    "    \n",
    "    active_labels = torch.where( # just append -100 for the padded tokens so its ignored when computing loss , no need now\n",
    "        active_loss,             # since its handled in preprocessing only\n",
    "        target.view(-1),\n",
    "        torch.tensor(-100).type_as(target)    \n",
    "    )\n",
    "    try:\n",
    "        class_0_weights =1/len(torch.where(active_labels==0)[0]) # trying to weight the labels as its unbalanced mostly\n",
    "    \n",
    "    except ZeroDivisionError:\n",
    "        class_0_weights = 1e-8\n",
    "\n",
    "    try:\n",
    "        class_1_weights =1/len(torch.where(active_labels==1)[0])\n",
    "    \n",
    "    except:\n",
    "        class_1_weights = 1e-8\n",
    "    \n",
    "    weights_tensor = torch.tensor([class_0_weights,class_1_weights]).cuda()\n",
    "    lfn = nn.CrossEntropyLoss(weight = weights_tensor)\n",
    "    loss = lfn(active_logits,active_labels)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.tensor([[0.2,0.5],[0.9,0.4],[0.9,0.2],[0.2,0.9],[0.7,0.4]])\n",
    "# b = torch.tensor([-100,-100,-100,-100,-100])\n",
    "# c = torch.tensor([1,1,1,1,1])\n",
    "# ClassificationCost(a,b,c).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConsistencyCost(student_output, teacher_output,mask,scale=10):\n",
    "    \n",
    "    assert len(student_output) == len(teacher_output)\n",
    "    \n",
    "    loss = nn.MSELoss()\n",
    "    active_outputs = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "    flattened_outputs_student = student_output.view(-1,2)\n",
    "    flatenned_outputs_teacher = teacher_output.view(-1,2)\n",
    "\n",
    "    active_outputs_teacher=flatenned_outputs_teacher[torch.where(mask.view(-1) == 1)]\n",
    "    active_outputs_student=flattened_outputs_student[torch.where(mask.view(-1) == 1)]\n",
    "    \n",
    "    return scale * loss(active_outputs_student.view(-1),active_outputs_teacher.view(-1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ConsistencyCost(student_output, teacher_output,mask):\n",
    "    \n",
    "#     assert len(student_output) == len(teacher_output)\n",
    "    \n",
    "#     loss = nn.MSELoss()\n",
    "#     active_outputs = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "#     flattened_outputs_student = student_output.view(-1,2)\n",
    "#     flatenned_outputs_teacher = teacher_output.view(-1,2)\n",
    "    \n",
    "#     # [0.2,0.8] , [0.3,0.7] , [0.9,0.1] -> s\n",
    "#     # [0.7,0.3] , [0.9,0.1] , [0.8,0.2] -> T \n",
    "    \n",
    "    \n",
    "    \n",
    "#     pseudo_label = torch.softmax(logits_u_w.detach()/args.T, dim=-1)\n",
    "#     max_probs, targets_u = torch.max(pseudo_label, dim=-1)\n",
    "#     mask = max_probs.ge(config.threshold).float()\n",
    "\n",
    "#     Lu = (F.cross_entropy(logits_u_s, targets_u,\n",
    "#                                   reduction='none') * mask)\n",
    "    \n",
    "#     active_outputs_teacher=flatenned_outputs_teacher[torch.where(active_outputs == 1)]\n",
    "#     active_outputs_student=flattened_outputs_student[torch.where(active_outputs == 1)]\n",
    "    \n",
    "#     return torch.sqrt(loss(active_outputs_student,active_outputs_teacher))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update teacher to be exponential moving average of student params.\n",
    "def update_teacher_params(student_model, teacher_model, alpha, global_step):\n",
    "    # Use the true average until the exponential average is more correct\n",
    "    \n",
    "    teacher_params = teacher_model.parameters()\n",
    "    student_params = student_model.parameters()\n",
    "    \n",
    "    assert sum(p.numel() for p in student_model.parameters()) == sum(p.numel() for p in teacher_model.parameters())\n",
    "    \n",
    "#     alpha = min(1 - 1 / (global_step + 1), alpha)\n",
    "    \n",
    "    for teacher_param, student_param in zip(teacher_params, student_params):\n",
    "            teacher_param.data.mul_(config.alpha).add_(1 - config.alpha, student_param.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_labels(teacher_softmax):\n",
    "    \n",
    "#             pseudo_label = torch.softmax(logits_u_w.detach()/args.T, dim=-1)\n",
    "#             print(torch.softmax(logits, dim=-1))\n",
    "            max_probs, targets_hard = torch.max(teacher_softmax, dim=-1)\n",
    "            mask = max_probs.ge(config.threshold).int()\n",
    "            \n",
    "    \n",
    "            return mask, targets_hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6858, 0.3142],\n",
      "         [0.2972, 0.7028],\n",
      "         [0.3639, 0.6361]],\n",
      "\n",
      "        [[0.5825, 0.4175],\n",
      "         [0.8339, 0.1661],\n",
      "         [0.6150, 0.3850]]], device='cuda:0')\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 1, 0]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([[0, 1, 1],\n",
      "        [0, 0, 0]], device='cuda:0')\n",
      "tensor([False, False, False, False,  True, False], device='cuda:0')\n",
      "tensor([-100, -100, -100, -100,    0, -100], device='cuda:0')\n",
      "tensor([[ 0.6353, -0.1454],\n",
      "        [ 0.4254,  0.1340],\n",
      "        [-0.3240,  0.2343],\n",
      "        [-0.4565,  0.6533],\n",
      "        [ 0.6570,  0.1564],\n",
      "        [-0.3240,  0.2343]], device='cuda:0')\n",
      "0.4738504886627197\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn \n",
    "# import config\n",
    "lfn = nn.CrossEntropyLoss()\n",
    "logits_t = torch.tensor([[[0.435345,-0.3454],[-0.4254,0.4354],[-0.324,0.23434]],[[0.456546,0.12334],[0.657,-0.9564],[0.234,-0.23443]]]).cuda()\n",
    "logits_st = torch.tensor([[[0.635345,-0.1454],[0.4254,0.134],[-0.324,0.23434]],[[-0.456546,0.65334],[0.657,0.1564],[-0.324,0.23434]]]).cuda()\n",
    "att_mask=torch.tensor([[1,1,0],[1,1,0]]).cuda()\n",
    "softmax_teacher = torch.softmax(logits_t, dim=-1)\n",
    "print(softmax_teacher)\n",
    "label_mask,hard_labels_pseudo = refine_labels(softmax_teacher)\n",
    "print(label_mask)\n",
    "print(hard_labels_pseudo)\n",
    "active_loss = label_mask.view(-1) & att_mask.view(-1)\n",
    "print(active_loss.bool())\n",
    "active_loss = active_loss.bool()\n",
    "active_labels = torch.where( # just append -100 for the padded tokens so its ignored when computing loss , no need now\n",
    "        active_loss,             # since its handled in preprocessing only\n",
    "        hard_labels_pseudo.view(-1),\n",
    "        torch.tensor(-100).type_as(hard_labels_pseudo)    \n",
    "    )\n",
    "print(active_labels)\n",
    "active_logits = logits_st.view(-1,2)\n",
    "# active_logits = logits_st.view(-1, 2)[active_loss]\n",
    "# active_labels = hard_labels_pseudo.view(-1, 2)[active_loss]\n",
    "print(active_logits)\n",
    "# print(active_labels)\n",
    "loss = lfn(active_logits,active_labels)\n",
    "print(loss.item())\n",
    "# max_probs, targets_u = torch.max(pseudo_label, dim=-1)\n",
    "# mask = max_probs.ge(0.7).float()\n",
    "# print(pseudo_label)\n",
    "# targets_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, optimizer,scheduler, student_model, teacher_model , global_step,with_const_cost, epoch):\n",
    "    \n",
    "    student_model.train() # put student model in training mode\n",
    "    teacher_model.train()\n",
    "    total_train_loss = 0\n",
    "    consistency_cst = 0\n",
    "    classification_cst_student=0\n",
    "    classification_cst_teacher=0\n",
    "    classification_cst_lst = []\n",
    "    consistency_cst_lst = []\n",
    "    overall_cst_lst = []\n",
    "#     global_step = 0\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(train_dataloader, total = len(train_dataloader),position = 0 , leave = True)):\n",
    "\n",
    "            \n",
    "        b_input_ids = batch[0].cuda()\n",
    "        b_input_mask = batch[1].cuda()\n",
    "        \n",
    "     \n",
    "        \n",
    "        output_student_softmax, output_student_logit = student_model( b_input_ids, attention_mask = b_input_mask )\n",
    "        \n",
    "        # make teacher's weights ema of student's weights.\n",
    "        update_teacher_params(student_model , teacher_model , config.alpha,global_step)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "                output_teacher_softmax, output_teacher_logit = teacher_model( b_input_ids, attention_mask = b_input_mask )\n",
    "          \n",
    "        # get hard labels and mask for confident labels \n",
    "        label_masks,hard_labels_teacher_pseudo = refine_labels(output_teacher_softmax)\n",
    "        # classification cose between student's logits and teacher's hard pseudo labels (only confident ones)\n",
    "        \n",
    "        classification_cost_student =  ClassificationCost(output_student_logit,hard_labels_teacher_pseudo,b_input_mask,label_masks)\n",
    "        classification_cst_student+=classification_cost_student.item()\n",
    "        \n",
    "#         classification_cost_teacher =  ClassificationCost(output_teacher_logit,b_labels,b_input_mask)\n",
    "#         classification_cst_teacher+=classification_cost_teacher.item()\n",
    "        \n",
    "        writer.add_scalar('TrainingLoss/Classification', classification_cost_student.item(), global_step)\n",
    "        \n",
    "        consistency_cost = ConsistencyCost(output_student_softmax,output_teacher_softmax.detach(),b_input_mask,scale=10)\n",
    "        consistency_cst+=consistency_cost.item()\n",
    "        \n",
    "        writer.add_scalar('TrainingLoss/Consistency', consistency_cost.item(), global_step)\n",
    "        \n",
    "#         overall_cost = (config.ratio * classification_cost) + ((1 - config.ratio) * consistency_cost)\n",
    "        \n",
    "        if with_const_cost:\n",
    "            overall_cost =  classification_cost_student + get_consistency_weight(global_step) * consistency_cost\n",
    "        else:\n",
    "            overall_cost =  classification_cost_student\n",
    "        \n",
    "        writer.add_scalar('TrainingLoss/Overall', overall_cost.item(), global_step)\n",
    "        \n",
    "        total_train_loss+=overall_cost.item()\n",
    "\n",
    "        overall_cost.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "#         update_teacher_params(student_model , teacher_model , config.alpha,global_step)\n",
    "\n",
    "        \n",
    "        if step % 50 == 0 and step!=0:\n",
    "            print ('train loss : ', total_train_loss/step)\n",
    "            print('Consistency Cost :', consistency_cst/step)\n",
    "            print('Classification Cost :', classification_cst_student/step)\n",
    "            print('Consistency Weight is:', get_consistency_weight(epoch))\n",
    "    \n",
    "        \n",
    "        global_step+=1\n",
    "        \n",
    "    return (consistency_cst/len(train_dataloader), classification_cst_student/len(train_dataloader), total_train_loss/len(train_dataloader),global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def soft_frequency(logits, power=2, probs=False):\n",
    "#     \"\"\"\n",
    "#     Unsupervised Deep Embedding for Clustering Analysis\n",
    "#     https://arxiv.org/abs/1511.06335\n",
    "#     \"\"\"\n",
    "#     if not probs:\n",
    "#         softmax = torch.nn.Softmax(dim=1)\n",
    "#         y = softmax(logits.view(-1, logits.shape[-1])).view(logits.shape)\n",
    "#     else:\n",
    "#         y = logits\n",
    "#     f = torch.sum(y, dim=(0, 1))\n",
    "#     t = y**power / f\n",
    "#     p = t/torch.sum(t, dim=2, keepdim=True)\n",
    "\n",
    "#     return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits = torch.tensor([[[0.3,0.7] , [0.2,0.8] , [0.5569,0.5]]])\n",
    "# f = torch.sum(logits, dim=(0,1))\n",
    "# print(f)\n",
    "# new_logits = soft_frequency(logits,probs = True)\n",
    "# # t = logits**2 / f\n",
    "# # print(t.shape)\n",
    "# # p = t/torch.sum(t, dim=2, keepdim=True)\n",
    "# # p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "# softmax = torch.nn.Softmax(dim=1)\n",
    "# y = softmax(new_logits.view(-1, new_logits.shape[-1])).view(new_logits.shape)\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _confidence = y.max(dim=-1)[0]\n",
    "# _confidence[0]\n",
    "# # torch.where(_confidence[0]>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test( model, test_loader):\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    lst_active_preds = []\n",
    "    lst_active_labels = []\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in tqdm(test_loader,total = len(test_loader),position = 0 , leave = True):\n",
    "            \n",
    "            b_input_ids_eval = batch[0].cuda()\n",
    "            b_input_mask_eval = batch[1].cuda()\n",
    "            b_labels_eval = batch[2].cuda()\n",
    "            \n",
    "            _, output= model(b_input_ids_eval,attention_mask = b_input_mask_eval)\n",
    "            \n",
    "            classification_cost =  ClassificationCost_eval(output,b_labels_eval,b_input_mask_eval)\n",
    "            test_loss+=classification_cost\n",
    "            \n",
    "            labels = b_labels_eval.view(-1) \n",
    "            active_logits = output.view(-1, 2)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "            active_accuracy = labels.view(-1) != -100\n",
    "            labels_tmp = torch.masked_select(labels, active_accuracy) \n",
    "            pred_tmp = torch.masked_select(flattened_predictions, active_accuracy) \n",
    "            lst_active_labels.extend(labels_tmp.tolist())\n",
    "            lst_active_preds.extend(pred_tmp.tolist())\n",
    "            \n",
    "    avg_f1_score_0=f1_score(lst_active_labels,lst_active_preds,average='binary',pos_label = 0)\n",
    "    avg_f1_score_1=f1_score(lst_active_labels,lst_active_preds,average='binary',pos_label = 1)\n",
    "    avg_accuracy_score=accuracy_score(lst_active_labels,lst_active_preds)\n",
    "    avg_mcc_score = matthews_corrcoef(lst_active_labels,lst_active_preds)\n",
    "    \n",
    "    test_loss /= len(test_loader)\n",
    "    \n",
    "    print('Overall validation loss:', test_loss)\n",
    "    print('Average F1 Validation score for whole sentence class 0 :' ,avg_f1_score_0)\n",
    "    print('Average F1 Validation score for whole sentence class 1 :' ,avg_f1_score_1)\n",
    "    print('Average Accuracy Validation score whole sentence  :' ,avg_accuracy_score)\n",
    "    print('Average mcc Validation score whole sentence :' ,avg_mcc_score)\n",
    "    print('Classification Report :'+'\\n', classification_report(lst_active_labels,lst_active_preds))\n",
    "\n",
    "    return (test_loss, avg_f1_score_0 , avg_f1_score_1, avg_accuracy_score, avg_mcc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_MeanTeacher(train_dataloader, val_dataloader,len_labelled_data ,len_unlabelled_data,exp_name, model_name, early_stopping,writer,with_const_cost=True ,dropout_layer = True, noise_layer=True):\n",
    "    \n",
    "    exp_name = exp_name\n",
    "    model_name = model_name\n",
    "    \n",
    "    global_step = 0\n",
    "    best_mcc_teacher = -1\n",
    "    best_mcc_student = -1\n",
    "    # train losses\n",
    "    epochs_consistency_lst =[]\n",
    "    epochs_classification_lst = []\n",
    "    epochs_overall_lst = []\n",
    "    \n",
    "    #test metrices for student\n",
    "    epochs_f1_score_0_lst_student = []\n",
    "    epochs_f1_score_1_lst_student = []\n",
    "    epochs_accuracy_lst_student = []\n",
    "    epochs_mcc_lst_student = []\n",
    "    epochs_cost_lst_student=[]\n",
    "    \n",
    "    #test metrices for teacher\n",
    "    epochs_f1_score_0_lst_teacher= []\n",
    "    epochs_f1_score_1_lst_teacher = []\n",
    "    epochs_accuracy_lst_teacher = []\n",
    "    epochs_mcc_lst_teacher = []\n",
    "    epochs_cost_lst_teacher=[]\n",
    "    \n",
    "    set_seed()\n",
    "    #initialaize models with pretrained model \n",
    "    if with_const_cost:\n",
    "        noise_layer = True\n",
    "    else:\n",
    "        noise_layer = False\n",
    "        \n",
    "    student = EntityModel(std_gaussian=config.gaussian_noise_std_student, with_noise_layer=noise_layer,dropout_layer=dropout_layer) \n",
    "    teacher = EntityModel(std_gaussian=config.gaussian_noise_std_teacher, with_noise_layer=noise_layer)\n",
    "#     Thesis/src/code/models/training_data/supervised_with_250_labeled_data.bin\n",
    "    student.load_state_dict(torch.load(f'../models/training_data/supervised_with_{len_labelled_data}_labeled_data.bin'))\n",
    "    teacher.load_state_dict(torch.load(f'../models/training_data/supervised_with_{len_labelled_data}_labeled_data.bin'))\n",
    "    student.cuda() # take model to gpu\n",
    "    teacher.cuda()\n",
    "#     teacher.eval()\n",
    "    param_optimizer_student = list(student.named_parameters())\n",
    "    param_teacher = list(teacher.named_parameters())\n",
    "    \n",
    "    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer_student if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer_student if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "    optimizer = AdamW(optimizer_parameters, lr=config.lr)\n",
    "    num_train_steps = int(len(train_dataloader) * config.EPOCHS)\n",
    "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "#         optimizer, T_max=num_train_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n",
    "    set_seed() # setting seed again before training\n",
    "    \n",
    "    with open(f'../Logs/{exp_name}.txt', 'w') as f:\n",
    "        f.write(f'{exp_name}'+'\\n')\n",
    "        for epoch in range(0,config.EPOCHS):\n",
    "            print(f'Current epoch is {epoch+1} of {config.EPOCHS}')\n",
    "\n",
    "            consistency_cost , classification_cost , overall_cost, global_step = train(train_dataloader, optimizer,scheduler,student,teacher,global_step,with_const_cost,epoch)\n",
    "\n",
    "            writer.add_scalar('TrainingLoss/Consistency_epoch :', consistency_cost,epoch )\n",
    "            writer.add_scalar('TrainingLoss/Classification_epoch', classification_cost,epoch)\n",
    "            writer.add_scalar('TrainingLoss/Overall_epoch',overall_cost,epoch)\n",
    "\n",
    "            epochs_consistency_lst.append(consistency_cost)\n",
    "            epochs_classification_lst.append(classification_cost)\n",
    "            epochs_overall_lst.append(overall_cost)\n",
    "\n",
    "\n",
    "            print('---------Running validation for student -------------')\n",
    "            test_loss_student, avg_f1_score_0_student, avg_f1_score_1_student, avg_accuracy_score_student, avg_mcc_score_student = test(student,val_dataloader)\n",
    "\n",
    "            epochs_f1_score_0_lst_student.append(avg_f1_score_0_student)\n",
    "            epochs_f1_score_1_lst_student.append(avg_f1_score_1_student)\n",
    "            epochs_accuracy_lst_student.append(avg_accuracy_score_student)\n",
    "            epochs_mcc_lst_student.append(avg_mcc_score_student)\n",
    "            epochs_cost_lst_student.append(test_loss_student)\n",
    "\n",
    "            writer.add_scalar('mcc_score/Student',avg_mcc_score_student,epoch)\n",
    "            writer.add_scalar('ValidationLoss/Student',test_loss_student,epoch)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            if float(\"{:.2f}\".format(avg_mcc_score_student)) >  best_mcc_student :\n",
    "                    torch.save(student.state_dict(), f'../models/pseudolabeling/StudentModels/studentModel_{model_name}.bin')\n",
    "                    best_mcc_student = float(\"{:.3f}\".format(avg_mcc_score_student))\n",
    "\n",
    "            print('---------Running validation for teacher -------------')\n",
    "\n",
    "            test_loss_teacher, avg_f1_score_0_teacher, avg_f1_score_1_teacher, avg_accuracy_score_teacher, avg_mcc_score_teacher=test(teacher,val_dataloader)\n",
    "\n",
    "            epochs_f1_score_0_lst_teacher.append(avg_f1_score_1_teacher)\n",
    "            epochs_f1_score_1_lst_teacher.append(avg_f1_score_0_teacher)\n",
    "            epochs_accuracy_lst_teacher.append(avg_accuracy_score_teacher)\n",
    "            epochs_mcc_lst_teacher.append(avg_mcc_score_teacher)\n",
    "            epochs_cost_lst_teacher.append(test_loss_teacher)\n",
    "\n",
    "            writer.add_scalar('mcc_score/Teacher',avg_mcc_score_teacher,epoch)\n",
    "            writer.add_scalar('ValidationLoss/Teacher',test_loss_teacher,epoch)\n",
    "\n",
    "            f.write(f\"Consistency_loss {epoch+1} : {str(consistency_cost)}\" + '\\n')\n",
    "            f.write(f\"Classification_loss {epoch+1} : {str(classification_cost)}\" + '\\n')\n",
    "            f.write(f\"Overall_loss {epoch+1} : {str(overall_cost)}\" + '\\n')\n",
    "            f.write(f\"'mcc_score/Teacher {epoch+1} : {str(avg_mcc_score_teacher)}\" + '\\n')\n",
    "            f.write(f\"ValidationLoss/Teacher {epoch+1} : {str(test_loss_teacher)}\" + '\\n')\n",
    "            f.write(f\"'mcc_score/Student {epoch+1} : {str(avg_mcc_score_student)}\" + '\\n')\n",
    "            f.write(f\"ValidationLoss/Student {epoch+1} : {str(test_loss_student)}\" + '\\n')\n",
    "\n",
    "            \n",
    "\n",
    "            if float(\"{:.2f}\".format(avg_mcc_score_teacher)) >  best_mcc_teacher :\n",
    "                    torch.save(teacher.state_dict(), f'../models/pseudolabeling/TeacherModels/teacherModel_{model_name}.bin')\n",
    "                    best_mcc_teacher = float(\"{:.3f}\".format(avg_mcc_score_teacher))        \n",
    "\n",
    "\n",
    "            if early_stopping.step(float(\"{:.2f}\".format(avg_mcc_score_teacher))): #mcc score for early stopping \"{:.2f}\".format(a_float)\n",
    "                      break \n",
    "\n",
    "#             if epoch %5 == 0 :\n",
    "#                 writer.add_hparams(\n",
    "#                     { \"lr\": float(config.lr), \n",
    "#                      \"consistency_ratio\": float(get_consistency_weight(epoch)) , \n",
    "#                      \"alpha\":config.alpha, \n",
    "#                      \"teacher_noise_gaussian_std\":config.gaussian_noise_std_teacher,\n",
    "#                      \"student_noise_gaussian_std\":config.gaussian_noise_std_student,\n",
    "#                      \"epoch_current\":epoch+1,\n",
    "#                      \"labelled_data\": len_labelled_data, \n",
    "#                      \"unlabelled_data\":len_unlabelled_data \n",
    "\n",
    "#                     },\n",
    "#                     {\n",
    "#                     \"mcc_score_teacher\": float(avg_mcc_score_teacher),\n",
    "#                     \"loss_teacher\": float(test_loss_teacher),\n",
    "#                     \"mcc_score_student\" : float(avg_mcc_score_student),\n",
    "#                     \"loss_student\" : float(test_loss_student)\n",
    "#                     },\n",
    "#                 )\n",
    "\n",
    "#     writer.flush()  \n",
    "#     writer.close()    \n",
    "    return (epochs_consistency_lst,epochs_classification_lst,epochs_overall_lst,epochs_f1_score_0_lst_student,epochs_f1_score_1_lst_student,\n",
    "           epochs_accuracy_lst_student,epochs_mcc_lst_student,epochs_cost_lst_student,epochs_f1_score_0_lst_teacher,epochs_f1_score_1_lst_teacher,\n",
    "            epochs_accuracy_lst_teacher,epochs_mcc_lst_teacher,epochs_cost_lst_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MeanTeacher_initWithsuptrainedmodel_withConsistencyRampup_for_5_epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b9cb4a2c4e11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMeanTeacher_initWithsuptrainedmodel_withConsistencyRampup_for_5_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mMeanTeacher_withConsistencyRampup_for_1500_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mteacherModel_v1_rampup_const_cost_1500_steps_withDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mv1_initSupModel_rampup_const_cost_5_epochs_withDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mMeanTeacher_withConsistencyRampup_for_1500_steps_to_1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MeanTeacher_initWithsuptrainedmodel_withConsistencyRampup_for_5_epochs' is not defined"
     ]
    }
   ],
   "source": [
    "MeanTeacher_initWithsuptrainedmodel_withConsistencyRampup_for_5_epochs\n",
    "MeanTeacher_withConsistencyRampup_for_1500_steps\n",
    "teacherModel_v1_rampup_const_cost_1500_steps_withDropout\n",
    "v1_initSupModel_rampup_const_cost_5_epochs_withDropout\n",
    "MeanTeacher_withConsistencyRampup_for_1500_steps_to_1\n",
    "v1_rampup_const_cost_1500_steps_to_1_withDropout\n",
    "pseudolabeling_750_label_1250_unlabel_samples_confidence_60_wo_constcost\n",
    "v1_750_label_1250_unlabel_pseudolabeling_confidence_60_wo_constcost\n",
    "pseudolabeling_750_label_1250_unlabel_samples_confidence_80\n",
    "v1_750_label_1250_unlabel_pseudolabeling_confidence_80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(f\"runs/AugSupervised_and_PseudoLabelingTraining/pseudo_label_{label_data_required}_labeled_data_{unlabel_data_required}_unlabel_data_confidence_80_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_text('text', 'Ramup from 0 to 1 in 1200 steps. Batch size was 8 so total steps in 2 epochs were 1200. Also, noise used in teacher is more than student 0.5 and 0.3 respectively for teacher and student models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudolabeling_1750_label_250_unlabel_samples_confidence_0.6_wo_conscost\n",
      "v1_1750_label_250_unlabel_pseudolabeling_confidence_0.6_wo_conscost\n"
     ]
    }
   ],
   "source": [
    "exp_name = f'pseudolabeling_{len_labelled_data}_label_{len_unlabelled_data}_unlabel_samples_confidence_{config.threshold}_wo_conscost'\n",
    "model_name = f'v1_{len_labelled_data}_label_{len_unlabelled_data}_unlabel_pseudolabeling_confidence_{config.threshold}_wo_conscost'\n",
    "print(exp_name)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudolabeling_1250_label_750_unlabel_samples_confidence_0.8_final\n",
      "v1_1250_label_750_unlabel_pseudolabeling_confidence_0.8_final\n"
     ]
    }
   ],
   "source": [
    "exp_name = f'pseudolabeling_{len_labelled_data}_label_{len_unlabelled_data}_unlabel_samples_confidence_{config.threshold}_final'\n",
    "model_name = f'v1_{len_labelled_data}_label_{len_unlabelled_data}_unlabel_pseudolabeling_confidence_{config.threshold}_final'\n",
    "print(exp_name)\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/opt/conda/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 1 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:17<00:14,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1155849552154541\n",
      "Consistency Cost : 0.48893072485923766\n",
      "Classification Cost : 0.10314843080937862\n",
      "Consistency Weight is: 0.006737946999085467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:31<00:00,  2.99it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.9728, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4449859418931583\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8577741486142466\n",
      "Average Accuracy Validation score whole sentence  : 0.7735719201651755\n",
      "Average mcc Validation score whole sentence : 0.35814110817141154\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.68      0.44      1734\n",
      "           1       0.94      0.79      0.86     11343\n",
      "\n",
      "    accuracy                           0.77     13077\n",
      "   macro avg       0.64      0.74      0.65     13077\n",
      "weighted avg       0.86      0.77      0.80     13077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.8469, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.44824840764331214\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8688121154756271\n",
      "Average Accuracy Validation score whole sentence  : 0.7880247763248451\n",
      "Average mcc Validation score whole sentence : 0.35841623574245784\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.65      0.45      1734\n",
      "           1       0.94      0.81      0.87     11343\n",
      "\n",
      "    accuracy                           0.79     13077\n",
      "   macro avg       0.64      0.73      0.66     13077\n",
      "weighted avg       0.86      0.79      0.81     13077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 2 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:17<00:14,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.19372933730483055\n",
      "Consistency Cost : 0.26012911289930346\n",
      "Classification Cost : 0.0814528714865446\n",
      "Consistency Weight is: 0.007082523558272816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:31<00:00,  2.94it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 16.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.9477, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4507866813025979\n",
      "Average F1 Validation score for whole sentence class 1 : 0.854891724671307\n",
      "Average Accuracy Validation score whole sentence  : 0.7704366444903266\n",
      "Average mcc Validation score whole sentence : 0.3680518022775964\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.71      0.45      1734\n",
      "           1       0.95      0.78      0.85     11343\n",
      "\n",
      "    accuracy                           0.77     13077\n",
      "   macro avg       0.64      0.75      0.65     13077\n",
      "weighted avg       0.86      0.77      0.80     13077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.8412, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4459639126305793\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8603571257599694\n",
      "Average Accuracy Validation score whole sentence  : 0.7769366062552573\n",
      "Average mcc Validation score whole sentence : 0.35845683314039667\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.68      0.45      1734\n",
      "           1       0.94      0.79      0.86     11343\n",
      "\n",
      "    accuracy                           0.78     13077\n",
      "   macro avg       0.64      0.73      0.65     13077\n",
      "weighted avg       0.86      0.78      0.81     13077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 3 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:17<00:14,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.24137018412351607\n",
      "Consistency Cost : 0.1775081790983677\n",
      "Classification Cost : 0.06415333874523639\n",
      "Consistency Weight is: 0.007442860710056644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:32<00:00,  2.90it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 16.35it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.0059, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4396284829721363\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8510864830857088\n",
      "Average Accuracy Validation score whole sentence  : 0.7647013841095053\n",
      "Average mcc Validation score whole sentence : 0.35320750163936127\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.70      0.44      1734\n",
      "           1       0.94      0.78      0.85     11343\n",
      "\n",
      "    accuracy                           0.76     13077\n",
      "   macro avg       0.63      0.74      0.65     13077\n",
      "weighted avg       0.86      0.76      0.80     13077\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.9078, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.44806741161384867\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8544092776032857\n",
      "Average Accuracy Validation score whole sentence  : 0.7695954729678061\n",
      "Average mcc Validation score whole sentence : 0.3642270563827071\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.71      0.45      1734\n",
      "           1       0.95      0.78      0.85     11343\n",
      "\n",
      "    accuracy                           0.77     13077\n",
      "   macro avg       0.64      0.74      0.65     13077\n",
      "weighted avg       0.86      0.77      0.80     13077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 4 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:17<00:14,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.18493743166327475\n",
      "Consistency Cost : 0.13541962042450906\n",
      "Classification Cost : 0.04951781060546637\n",
      "Consistency Weight is: 0.007819575576520875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:32<00:00,  2.87it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 16.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1178, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.44716746581424255\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8483165229254982\n",
      "Average Accuracy Validation score whole sentence  : 0.761948459126711\n",
      "Average mcc Validation score whole sentence : 0.36592292279281097\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.73      0.45      1734\n",
      "           1       0.95      0.77      0.85     11343\n",
      "\n",
      "    accuracy                           0.76     13077\n",
      "   macro avg       0.64      0.75      0.65     13077\n",
      "weighted avg       0.87      0.76      0.80     13077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(0.9936, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.44723796033994334\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8477518774992685\n",
      "Average Accuracy Validation score whole sentence  : 0.7612602278810124\n",
      "Average mcc Validation score whole sentence : 0.3663255212148768\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.73      0.45      1734\n",
      "           1       0.95      0.77      0.85     11343\n",
      "\n",
      "    accuracy                           0.76     13077\n",
      "   macro avg       0.64      0.75      0.65     13077\n",
      "weighted avg       0.87      0.76      0.79     13077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 5 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:17<00:14,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.14575214445590973\n",
      "Consistency Cost : 0.10449989274144172\n",
      "Classification Cost : 0.041252251975238324\n",
      "Consistency Weight is: 0.00821330400344857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:32<00:00,  2.86it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.99it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1980, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.440054963929921\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8396616171552232\n",
      "Average Accuracy Validation score whole sentence  : 0.7507073487803013\n",
      "Average mcc Validation score whole sentence : 0.3594300270986601\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.74      0.44      1734\n",
      "           1       0.95      0.75      0.84     11343\n",
      "\n",
      "    accuracy                           0.75     13077\n",
      "   macro avg       0.63      0.75      0.64     13077\n",
      "weighted avg       0.87      0.75      0.79     13077\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.0746, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4458041958041958\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8448663991386904\n",
      "Average Accuracy Validation score whole sentence  : 0.7575896612372869\n",
      "Average mcc Validation score whole sentence : 0.3656380548630886\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.74      0.45      1734\n",
      "           1       0.95      0.76      0.84     11343\n",
      "\n",
      "    accuracy                           0.76     13077\n",
      "   macro avg       0.63      0.75      0.65     13077\n",
      "weighted avg       0.87      0.76      0.79     13077\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch is 6 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:17<00:15,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.1306381780654192\n",
      "Consistency Cost : 0.09511009491980076\n",
      "Classification Cost : 0.035528083238750695\n",
      "Consistency Weight is: 0.008624700856245927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:33<00:00,  2.84it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.88it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.2504, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4333931777378815\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8466770307034591\n",
      "Average Accuracy Validation score whole sentence  : 0.7586602431750401\n",
      "Average mcc Validation score whole sentence : 0.3458546237561865\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.70      0.43      1734\n",
      "           1       0.94      0.77      0.85     11343\n",
      "\n",
      "    accuracy                           0.76     13077\n",
      "   macro avg       0.63      0.73      0.64     13077\n",
      "weighted avg       0.86      0.76      0.79     13077\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.88it/s]\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1477, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.44205039096437887\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8425903230550517\n",
      "Average Accuracy Validation score whole sentence  : 0.7544543855624378\n",
      "Average mcc Validation score whole sentence : 0.36101242611169915\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.73      0.44      1734\n",
      "           1       0.95      0.76      0.84     11343\n",
      "\n",
      "    accuracy                           0.75     13077\n",
      "   macro avg       0.63      0.75      0.64     13077\n",
      "weighted avg       0.87      0.75      0.79     13077\n",
      "\n",
      "Current epoch is 7 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:18<00:15,  2.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.11981005154550076\n",
      "Consistency Cost : 0.08770662605762482\n",
      "Classification Cost : 0.032103424966335295\n",
      "Consistency Weight is: 0.009054440306439586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:33<00:00,  2.81it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.59it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.3069, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.43682370567671047\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8320841812676826\n",
      "Average Accuracy Validation score whole sentence  : 0.7413015217557544\n",
      "Average mcc Validation score whole sentence : 0.3583476779059531\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.76      0.44      1734\n",
      "           1       0.95      0.74      0.83     11343\n",
      "\n",
      "    accuracy                           0.74     13077\n",
      "   macro avg       0.63      0.75      0.63     13077\n",
      "weighted avg       0.87      0.74      0.78     13077\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.61it/s]\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.1943, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4415539368713146\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8420639591916813\n",
      "Average Accuracy Validation score whole sentence  : 0.7537661543167393\n",
      "Average mcc Validation score whole sentence : 0.3605148782845303\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.73      0.44      1734\n",
      "           1       0.95      0.76      0.84     11343\n",
      "\n",
      "    accuracy                           0.75     13077\n",
      "   macro avg       0.63      0.75      0.64     13077\n",
      "weighted avg       0.87      0.75      0.79     13077\n",
      "\n",
      "Current epoch is 8 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:18<00:15,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09653495118021965\n",
      "Consistency Cost : 0.07241613168269395\n",
      "Classification Cost : 0.02411881921812892\n",
      "Consistency Weight is: 0.009503216107832583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:33<00:00,  2.78it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.57it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.3262, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4335148427893905\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8423830702311715\n",
      "Average Accuracy Validation score whole sentence  : 0.7533838036246846\n",
      "Average mcc Validation score whole sentence : 0.3479746538648094\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.71      0.43      1734\n",
      "           1       0.95      0.76      0.84     11343\n",
      "\n",
      "    accuracy                           0.75     13077\n",
      "   macro avg       0.63      0.74      0.64     13077\n",
      "weighted avg       0.86      0.75      0.79     13077\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.41it/s]\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.3403, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.44116638078902226\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8396969100570755\n",
      "Average Accuracy Validation score whole sentence  : 0.7508602890571232\n",
      "Average mcc Validation score whole sentence : 0.36115381825847387\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.74      0.44      1734\n",
      "           1       0.95      0.75      0.84     11343\n",
      "\n",
      "    accuracy                           0.75     13077\n",
      "   macro avg       0.63      0.75      0.64     13077\n",
      "weighted avg       0.87      0.75      0.79     13077\n",
      "\n",
      "Current epoch is 9 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:18<00:15,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.08637350667268037\n",
      "Consistency Cost : 0.06212010556831956\n",
      "Classification Cost : 0.024253401132300498\n",
      "Consistency Weight is: 0.009971741861376466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:34<00:00,  2.74it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.54it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.4830, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4363134276838108\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8395874263261297\n",
      "Average Accuracy Validation score whole sentence  : 0.7502485279498355\n",
      "Average mcc Validation score whole sentence : 0.3536315979228131\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.73      0.44      1734\n",
      "           1       0.95      0.75      0.84     11343\n",
      "\n",
      "    accuracy                           0.75     13077\n",
      "   macro avg       0.63      0.74      0.64     13077\n",
      "weighted avg       0.86      0.75      0.79     13077\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.39it/s]\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.4134, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4373825388689561\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8377912418107483\n",
      "Average Accuracy Validation score whole sentence  : 0.7481838342127399\n",
      "Average mcc Validation score whole sentence : 0.3562131818619401\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.74      0.44      1734\n",
      "           1       0.95      0.75      0.84     11343\n",
      "\n",
      "    accuracy                           0.75     13077\n",
      "   macro avg       0.63      0.74      0.64     13077\n",
      "weighted avg       0.86      0.75      0.78     13077\n",
      "\n",
      "Current epoch is 10 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:18<00:15,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.09765802275389433\n",
      "Consistency Cost : 0.07178324535489082\n",
      "Classification Cost : 0.02587477695196867\n",
      "Consistency Weight is: 0.010460751267790308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:34<00:00,  2.74it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.47it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.4554, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.441820076415422\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8424200823690919\n",
      "Average Accuracy Validation score whole sentence  : 0.754224975147205\n",
      "Average mcc Validation score whole sentence : 0.3607432805348324\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.73      0.44      1734\n",
      "           1       0.95      0.76      0.84     11343\n",
      "\n",
      "    accuracy                           0.75     13077\n",
      "   macro avg       0.63      0.75      0.64     13077\n",
      "weighted avg       0.87      0.75      0.79     13077\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.56it/s]\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.3733, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.43853708093464283\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8362307388384037\n",
      "Average Accuracy Validation score whole sentence  : 0.7464250210292881\n",
      "Average mcc Validation score whole sentence : 0.3588517084453833\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.75      0.44      1734\n",
      "           1       0.95      0.75      0.84     11343\n",
      "\n",
      "    accuracy                           0.75     13077\n",
      "   macro avg       0.63      0.75      0.64     13077\n",
      "weighted avg       0.87      0.75      0.78     13077\n",
      "\n",
      "Current epoch is 11 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:18<00:15,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.07117638397961855\n",
      "Consistency Cost : 0.05203591473400593\n",
      "Classification Cost : 0.019140468938276173\n",
      "Consistency Weight is: 0.010970998366931477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:34<00:00,  2.74it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.20it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.5878, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4406143344709898\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8384744259387011\n",
      "Average Accuracy Validation score whole sentence  : 0.7493308862889042\n",
      "Average mcc Validation score whole sentence : 0.36093684796403463\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.74      0.44      1734\n",
      "           1       0.95      0.75      0.84     11343\n",
      "\n",
      "    accuracy                           0.75     13077\n",
      "   macro avg       0.63      0.75      0.64     13077\n",
      "weighted avg       0.87      0.75      0.79     13077\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.56it/s]\n",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.5211, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4389996620479893\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8359359557224748\n",
      "Average Accuracy Validation score whole sentence  : 0.7461191404756443\n",
      "Average mcc Validation score whole sentence : 0.35974281683447257\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.75      0.44      1734\n",
      "           1       0.95      0.75      0.84     11343\n",
      "\n",
      "    accuracy                           0.75     13077\n",
      "   macro avg       0.63      0.75      0.64     13077\n",
      "weighted avg       0.87      0.75      0.78     13077\n",
      "\n",
      "Current epoch is 12 of 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 51/94 [00:18<00:15,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss :  0.0635950330644846\n",
      "Consistency Cost : 0.047895537447184326\n",
      "Classification Cost : 0.01569949616678059\n",
      "Consistency Weight is: 0.011503257762897217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:34<00:00,  2.73it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Running validation for student -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.48it/s]\n",
      "  0%|          | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.5444, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4338712360672102\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8310579357593209\n",
      "Average Accuracy Validation score whole sentence  : 0.7397721189875354\n",
      "Average mcc Validation score whole sentence : 0.3541615207345221\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.75      0.43      1734\n",
      "           1       0.95      0.74      0.83     11343\n",
      "\n",
      "    accuracy                           0.74     13077\n",
      "   macro avg       0.63      0.74      0.63     13077\n",
      "weighted avg       0.87      0.74      0.78     13077\n",
      "\n",
      "---------Running validation for teacher -------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [00:01<00:00, 15.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall validation loss: tensor(1.5215, device='cuda:0')\n",
      "Average F1 Validation score for whole sentence class 0 : 0.4381815131689314\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8341504481751101\n",
      "Average Accuracy Validation score whole sentence  : 0.7439015064617267\n",
      "Average mcc Validation score whole sentence : 0.3594026738792964\n",
      "Classification Report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.75      0.44      1734\n",
      "           1       0.95      0.74      0.83     11343\n",
      "\n",
      "    accuracy                           0.74     13077\n",
      "   macro avg       0.63      0.75      0.64     13077\n",
      "weighted avg       0.87      0.74      0.78     13077\n",
      "\n",
      "terminating because of early stopping!\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=8)\n",
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data, exp_name , model_name, early_stopping,writer,with_const_cost =True, dropout_layer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 125/125 [00:07<00:00, 15.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.4252788104089219\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8465854758682906\n",
      "Average Accuracy Validation score whole sentence  : 0.7578182853887782\n",
      "Average mcc Validation score whole sentence : 0.3352138147070163\n",
      "Average F1 Validation score for source sentence class 0 : 0.4078263527973097\n",
      "Average F1 Validation score for source sentence class 1 : 0.7995653973509934\n",
      "Average Accuracy Validation score source sentence  : 0.700502512562814\n",
      "Average mcc Validation score source sentence : 0.2942978208502161\n",
      "Average F1 Validation score for target sentence class 0 : 0.45156065042676474\n",
      "Average F1 Validation score for target sentence class 1 : 0.7707731166835925\n",
      "Average Accuracy Validation score target sentence  : 0.6766812355382524\n",
      "Average mcc Validation score target sentence : 0.3102254926852018\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.0\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9865348761504543\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9734275535829002\n",
      "Average mcc Validation score gaps in target sentence : 0.0\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.4391130498000727\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8717621963044021\n",
      "Average Accuracy Validation score whole target sentence  : 0.7912514092446449\n",
      "Average mcc Validation score whole target sentence : 0.36078351664625147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "# model = EntityModel() \n",
    "# model.cuda()\n",
    "\n",
    "model.load_state_dict(torch.load(f'../models/pseudolabeling/StudentModels/studentModel_{model_name}.bin'))\n",
    "model.eval() # for 1k, 1.0 k data- teacher model -- less seq len\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "student_mcc_test = test_metrics[4]# student\n",
    "\n",
    "# Thesis/src/code/models/pseudolabeling/TeacherModels/.6.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v1_1750_label_250_unlabel_pseudolabeling_confidence_0.6_wo_conscost'"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 125/125 [00:07<00:00, 16.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.4258900541046023\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8444315734221435\n",
      "Average Accuracy Validation score whole sentence  : 0.7551979493021931\n",
      "Average mcc Validation score whole sentence : 0.3370006778784989\n",
      "Average F1 Validation score for source sentence class 0 : 0.40930444006667677\n",
      "Average F1 Validation score for source sentence class 1 : 0.7977271547921748\n",
      "Average Accuracy Validation score source sentence  : 0.6986470815616544\n",
      "Average mcc Validation score source sentence : 0.2971520842612885\n",
      "Average F1 Validation score for target sentence class 0 : 0.4512247529007306\n",
      "Average F1 Validation score for target sentence class 1 : 0.7657801650727107\n",
      "Average Accuracy Validation score target sentence  : 0.6716861938516914\n",
      "Average mcc Validation score target sentence : 0.3107029903585249\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.0\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9865348761504543\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9734275535829002\n",
      "Average mcc Validation score gaps in target sentence : 0.0\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.4389632107023411\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.8694479959975541\n",
      "Average Accuracy Validation score whole target sentence  : 0.788184892897407\n",
      "Average mcc Validation score whole target sentence : 0.36171574565080356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/_classification.py:873: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load(f'../models/pseudolabeling/TeacherModels/teacherModel_{model_name}.bin'))\n",
    "model.eval() # for 1k, 1.0 k data- teacher model -- less seq len\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "# Thesis/src/code/models/pseudolabeling/TeacherModels/.bin\n",
    "teacher_mcc_test = test_metrics[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]/root/Thesis/src/code/code_files/engine.py:409: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  np_arr_labels = np.array(tar_labels)\n",
      "100%|██████████| 125/125 [00:07<00:00, 17.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for whole sentence class 0 : 0.4397887777443867\n",
      "Average F1 Validation score for whole sentence class 1 : 0.8886100369621074\n",
      "Average Accuracy Validation score whole sentence  : 0.8141697522073483\n",
      "Average mcc Validation score whole sentence : 0.34438902232277757\n",
      "Average F1 Validation score for source sentence class 0 : 0.42148843784711704\n",
      "Average F1 Validation score for source sentence class 1 : 0.8630637952052012\n",
      "Average Accuracy Validation score source sentence  : 0.7785465790490916\n",
      "Average mcc Validation score source sentence : 0.3048245354117049\n",
      "Average F1 Validation score for target sentence class 0 : 0.4694508894044857\n",
      "Average F1 Validation score for target sentence class 1 : 0.834794335805799\n",
      "Average Accuracy Validation score target sentence  : 0.7480442208102251\n",
      "Average mcc Validation score target sentence : 0.33087824908257835\n",
      "Average F1 Validation score for gaps in target sentence class 0 : 0.0\n",
      "Average F1 Validation score for gaps in target sentence class 1 : 0.9863848931510093\n",
      "Average Accuracy Validation score gaps in target sentence  : 0.9731355486772177\n",
      "Average mcc Validation score gaps in target sentence : -0.0028237252905523326\n",
      "Average F1 Validation score for whole target sentence class 0 : 0.45332337565347275\n",
      "Average F1 Validation score for whole target sentence class 1 : 0.9028017527552782\n",
      "Average Accuracy Validation score whole target sentence  : 0.8349492671927846\n",
      "Average mcc Validation score whole target sentence : 0.36954462263497856\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(f'../models/MeanTeacher_models/TeacherModels/teacherModel_v1_with_1250_labeled_750_unlabeled_data_withdropout_alpha_0.99_noises_changed_t_0.5_s_0.3.bin'))\n",
    "model.eval() # for 1k, 1.0 k data- teacher model -- less seq len\n",
    "test_metrics = engine.eval_fn(test_dataloader, model)\n",
    "# Thesis/src/code/models/MeanTeacher_models/TeacherModels/teacherModel_v1_with_1250_labeled_750_unlabeled_data_withdropout_alpha_0.99_noises_changed_t_0.5_s_0.3.binteacher_mcc_test = test_metrics[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_hparams(\n",
    "                    { \"lr\": float(config.lr),  \n",
    "                     \"labelled_data\": len_labelled_data, \n",
    "                     \"validation_data\":len(eval_data_ssl),\n",
    "                     \"alpha\":config.alpha, \n",
    "                     \"teacher_noise_gaussian_std\":config.gaussian_noise_std_teacher,\n",
    "                     \"student_noise_gaussian_std\":config.gaussian_noise_std_student,\n",
    "                     \"unlabelled_data\":len_unlabelled_data, \n",
    "                    },\n",
    "                    {\n",
    "                    \"mcc_score_test\" : float(0),\n",
    "                    \"mcc_score_teacher\": float(teacher_mcc_test) ,\n",
    "                    \"mcc_score_student\" : float(student_mcc_test),\n",
    "                    },\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-161-e5dcf95232ff>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-161-e5dcf95232ff>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    fail hoga ya pe\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "fail hoga ya pe\n",
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer, early_stopping,dropout_layer=True, noise_layer=True) # alpha = 0.995 and full data w/o noise and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # model= EntityModel()\n",
    "# optimizer_parameters_model = list(model.named_parameters())\n",
    "  \n",
    "# no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "# optimizer_parameters = [\n",
    "# {\n",
    "#     \"params\": [\n",
    "#         p for n, p in optimizer_parameters_model if not any(nd in n for nd in no_decay)\n",
    "#     ],\n",
    "#     \"weight_decay\": 0.001,\n",
    "# },\n",
    "# {\n",
    "#     \"params\": [\n",
    "#         p for n, p in optimizer_parameters_model if any(nd in n for nd in no_decay)\n",
    "#     ],\n",
    "#     \"weight_decay\": 0.0,\n",
    "# }]\n",
    "# optimizer = AdamW(optimizer_parameters, lr=config.lr)\n",
    "# num_train_steps = int(len(train_dataloader) * config.EPOCHS)\n",
    "# #     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "# #         optimizer, T_max=num_train_steps)\n",
    "# scheduler = get_linear_schedule_with_warmup(\n",
    "# optimizer, num_warmup_steps=0, num_training_steps=num_train_steps)\n",
    "# float(scheduler.get_last_lr()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        for item in items :\n",
    "            new_lst.append(float(item))\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensors_to_lst(lst):\n",
    "    new_lst = []\n",
    "    for items in lst:\n",
    "        new_lst.append(items.item())\n",
    "    return new_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_against_epochs(matrix1,matrix2,label1 , label2 ,y_label , title):\n",
    "    \n",
    "    epochs = np.arange(1,config.EPOCHS+1)\n",
    "    # print(epochs)\n",
    "    plt.plot(epochs,matrix1,label=label1)\n",
    "    if matrix2 is not None :\n",
    "        plt.plot(epochs,matrix2,label=label2)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Running without Noise embeddings and dropout </h2> -- <h4> No weighted Loss </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,noise_layer=False) # alpha = 0.995 and full data w/o noise and dropout\n",
    "\n",
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Plotting</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_epochs(test_cost_teacher,test_cost_student,label1 = 'ValidationLoss_teacher', \n",
    "                    label2 = 'ValidationLoss_student', y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(mcc_cost_teacher,mcc_cost_student,label1 = 'mcc_teacher', \n",
    "                    label2 = 'mcc_student', y_label = 'mcc_score_test', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(classification_cost_lst,None,label1 = 'classification_cost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(consistency_cost_lst,None,label1 = 'Consistency_lost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    if 'classifier' not in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer.add_text('Text','The Labelled data used in this experiment was 3200 and unlabelled used was 6400')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter(\"runs/MeanTeacherTraining/alpha_0.995_trail1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrices = train_MeanTeacher(train_dataloader,val_dataloader,len_labelled_data,len_unlabelled_data,writer, noise_layer=True) # alpha = 0.995 and full data w/o noise and dropout\n",
    "\n",
    "consistency_cost_lst = get_items(metrices[0])\n",
    "classification_cost_lst = get_items(metrices[1])\n",
    "overall_cost_lst = get_items(metrices[2])\n",
    "f1_class0_student_test = metrices[3]\n",
    "f1_class1_student_test= metrices[4]\n",
    "accuracy_student = metrices[5]\n",
    "mcc_cost_student = metrices[6]\n",
    "test_cost_student = tensors_to_lst(metrices[7])\n",
    "f1_class1_teacher_test=metrices[8]\n",
    "f1_class0_teacher_test = metrices[9]\n",
    "accuracy_teacher = metrices[10]\n",
    "mcc_cost_teacher = metrices[11]\n",
    "test_cost_teacher=tensors_to_lst(metrices[12])\n",
    "\n",
    "print('Consistency_lost_train :',consistency_cost_lst,'\\n',\n",
    "      'Classificataion_lost_train : ',classification_cost_lst,'\\n',\n",
    "      'Overall_loss_train :',overall_cost_lst,'\\n',\n",
    "      'f1_class0_student_test :',f1_class0_student_test,'\\n',\n",
    "      'f1_class1_student_test :',f1_class1_student_test,'\\n',\n",
    "      'accuracy_student :',accuracy_student,'\\n',\n",
    "      'mcc_cost_student :',mcc_cost_student,'\\n',\n",
    "      'test_cost_student :',test_cost_student,'\\n',\n",
    "      'f1_class0_teacher_test :',f1_class0_teacher_test,'\\n',\n",
    "      'f1_class1_teacher_test :',f1_class1_teacher_test,'\\n',\n",
    "    'accuracy_teacher :', accuracy_teacher,'\\n',\n",
    "      'mcc_cost_teacher',mcc_cost_teacher,'\\n',\n",
    "      'test_cost_teacher',test_cost_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_against_epochs(test_cost_teacher,test_cost_student,label1 = 'ValidationLoss_teacher', \n",
    "                    label2 = 'ValidationLoss_student', y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(mcc_cost_teacher,mcc_cost_student,label1 = 'mcc_teacher', \n",
    "                    label2 = 'mcc_student', y_label = 'mcc_score_test', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(classification_cost_lst,None,label1 = 'classification_cost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )\n",
    "plot_against_epochs(consistency_cost_lst,None,label1 = 'Consistency_lost_train', \n",
    "                    label2 = None, y_label = 'loss', title ='Meanteacher_XLMRoberta' )"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
