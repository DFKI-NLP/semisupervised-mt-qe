{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2022.1.18-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (748 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "Collecting tokenizers!=0.11.3,>=0.10.1\n",
      "  Using cached tokenizers-0.11.5-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from transformers) (4.4.0)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers) (1.19.1)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers) (1.16.0)\n",
      "Installing collected packages: regex, filelock, tokenizers, sacremoses, huggingface-hub, transformers\n",
      "Successfully installed filelock-3.4.1 huggingface-hub-0.4.0 regex-2022.1.18 sacremoses-0.0.47 tokenizers-0.11.5 transformers-4.16.2\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.96-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from nltk) (4.51.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.6/site-packages (from nltk) (2022.1.18)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from nltk) (7.1.2)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.6.7\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-7.6.5-py2.py3-none-any.whl (121 kB)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Using cached jupyterlab_widgets-1.0.2-py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (7.16.3)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (5.5.6)\n",
      "Collecting widgetsnbextension~=3.5.0\n",
      "  Using cached widgetsnbextension-3.5.2-py2.py3-none-any.whl (1.6 MB)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.6/site-packages (from ipywidgets) (0.2.0)\n",
      "Collecting nbformat>=4.2.0\n",
      "  Using cached nbformat-5.1.3-py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (7.1.2)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (59.3.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: pexpect in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (3.0.26)\n",
      "Collecting jedi<=0.17.2,>=0.10\n",
      "  Using cached jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.6/site-packages (from ipython>=4.0.0->ipywidgets) (0.2.0)\n",
      "Collecting parso<0.8.0,>=0.7.0\n",
      "  Using cached parso-0.7.1-py2.py3-none-any.whl (109 kB)\n",
      "Collecting jsonschema!=2.5.0,>=2.4\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets) (4.9.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (21.2.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (4.4.0)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Using cached pyrsistent-0.18.0-cp36-cp36m-manylinux1_x86_64.whl (117 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (1.16.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.6/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets) (0.2.5)\n",
      "Collecting notebook>=4.4.1\n",
      "  Using cached notebook-6.4.8-py3-none-any.whl (9.9 MB)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.0.1)\n",
      "Collecting terminado>=0.8.3\n",
      "  Using cached terminado-0.12.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (22.1.0)\n",
      "Collecting Send2Trash>=1.8.0\n",
      "  Using cached Send2Trash-1.8.0-py3-none-any.whl (18 kB)\n",
      "Collecting prometheus-client\n",
      "  Using cached prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
      "Collecting nbconvert\n",
      "  Using cached nbconvert-6.0.7-py3-none-any.whl (552 kB)\n",
      "Collecting argon2-cffi\n",
      "  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.6/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (0.3)\n",
      "Requirement already satisfied: ptyprocess in /opt/conda/lib/python3.6/site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.10.0.0)\n",
      "Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8)\n",
      "Collecting argon2-cffi-bindings\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /opt/conda/lib/python3.6/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.20)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata->jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (3.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.0.1)\n",
      "Collecting nbclient<0.6.0,>=0.5.0\n",
      "  Using cached nbclient-0.5.9-py3-none-any.whl (69 kB)\n",
      "Collecting jupyterlab-pygments\n",
      "  Using cached jupyterlab_pygments-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
      "Collecting testpath\n",
      "  Using cached testpath-0.5.0-py3-none-any.whl (84 kB)\n",
      "Collecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting bleach\n",
      "  Using cached bleach-4.1.0-py2.py3-none-any.whl (157 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting async-generator\n",
      "  Using cached async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.9)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n",
      "Installing collected packages: pyrsistent, parso, jsonschema, webencodings, nbformat, jedi, async-generator, testpath, pandocfilters, nbclient, mistune, jupyterlab-pygments, defusedxml, bleach, argon2-cffi-bindings, terminado, Send2Trash, prometheus-client, nbconvert, argon2-cffi, notebook, widgetsnbextension, jupyterlab-widgets, ipywidgets\n",
      "  Attempting uninstall: parso\n",
      "    Found existing installation: parso 0.8.0\n",
      "    Uninstalling parso-0.8.0:\n",
      "      Successfully uninstalled parso-0.8.0\n",
      "  Attempting uninstall: jedi\n",
      "    Found existing installation: jedi 0.18.0\n",
      "    Uninstalling jedi-0.18.0:\n",
      "      Successfully uninstalled jedi-0.18.0\n",
      "Successfully installed Send2Trash-1.8.0 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 async-generator-1.10 bleach-4.1.0 defusedxml-0.7.1 ipywidgets-7.6.5 jedi-0.17.2 jsonschema-3.2.0 jupyterlab-pygments-0.1.2 jupyterlab-widgets-1.0.2 mistune-0.8.4 nbclient-0.5.9 nbconvert-6.0.7 nbformat-5.1.3 notebook-6.4.8 pandocfilters-1.5.0 parso-0.7.1 prometheus-client-0.13.1 pyrsistent-0.18.0 terminado-0.12.1 testpath-0.5.0 webencodings-0.5.1 widgetsnbextension-3.5.2\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece\n",
    "!pip install nltk\n",
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import joblib\n",
    "import torch\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection\n",
    "# from DataAugmentation \n",
    "from DataAugmentation import DataAugmentation\n",
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from importlib import reload\n",
    "import config\n",
    "from transformers import XLMRobertaForTokenClassification, XLMRobertaConfig ,BertModel, XLMRobertaTokenizer, XLMRobertaModel, BertForTokenClassification\n",
    "from data_utils import loadDatafromFile,createTokenizedDf,CompDataset,createkfoldData,createDataloaders\n",
    "from seqeval.metrics import accuracy_score\n",
    "from sklearn.metrics import matthews_corrcoef,classification_report,f1_score\n",
    "import engine\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "def process_data(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags,model_type):\n",
    "    \n",
    "    dataObj = loadDatafromFile(filePath_src,filePath_tar, filePath_srcTags,filePath_tarTags)\n",
    "    df= dataObj.createDf() # get dataframe from files\n",
    "    obj_tokenized = createTokenizedDf(df,model_type)\n",
    "    df_new= obj_tokenized.convertDf()\n",
    "#     enc_label = preprocessing.LabelEncoder()\n",
    "#     df_new['labels']= enc_label.fit_transform(df_new['labels'])\n",
    "    train_data = CompDataset(df_new,model_type)\n",
    "    return train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if loading of the non augmented (noise-free) data is needed, then run this\n",
    "dataset_train = process_data(config.filePath_src,config.filePath_tar, config.filePath_srcTags,config.filePath_tarTags,model_type = 'xlm')\n",
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dev/eval data\n",
    "dataset_eval = process_data(config.filePath_src_eval,config.filePath_tar_eval, config.filePath_srcTags_eval,config.filePath_tarTags_eval,model_type = 'xlm')\n",
    "len(dataset_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([     0,  17151,  12426,   2765,    113,    527, 110896,  36997,     71,\n",
       "          20387,   2189,    141,     99, 183124,     23,  58020,      6,      5,\n",
       "              2,      2,    656,  58020,    656, 138438,     13,    656,  17151,\n",
       "            656,  12426,   2765,    656,    113,    656,    527, 110896,    656,\n",
       "          20387,   2189,    141,    656,     23,    656, 183124,    656,      6,\n",
       "              5,    656,      2,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "              1,      1,      1,      1]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([-100,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1, -100, -100,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "            1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def random_deletion(dataframe, p):\n",
    "    \n",
    "#     source_sentences  = list(dataframe.source)\n",
    "#     target_sentences = list(dataframe.target)\n",
    "#     labels_src = list(dataframe.src_tokens)\n",
    "#     labels_tar = list(dataframe.tar_tokens)\n",
    "#     senetences_temp=[]\n",
    "#     labels_temp= []\n",
    "#     #randomly delete words with probability p\n",
    "#     i=0\n",
    "#     for sentences, labels in zip(source_sentences,labels_src):\n",
    "            \n",
    "#         sentences = sentences.split()\n",
    "#         labels = labels.split() \n",
    "        \n",
    "        \n",
    "        \n",
    "#         if len(sentences) == 1:\n",
    "#             i+=1\n",
    "#             continue\n",
    "            \n",
    "        \n",
    "               \n",
    "#         for _ in range(5):\n",
    "            \n",
    "#             source_sentences_temp=[]\n",
    "#             labels_sec_temp=[]\n",
    "#             for word,label in zip(sentences,labels):\n",
    "#                 r = random.uniform(0, 1)\n",
    "#                 if r > p:\n",
    "#                     source_sentences_temp.append(word)\n",
    "#                     labels_sec_temp.append(label)\n",
    "#             if len(source_sentences_temp) == 0: #if you end up deleting all words, just return a random word\n",
    "#                 rand_int = random.randint(0, len(source_sentences_temp)-1)\n",
    "#                 source_sentences_temp.append(sentences[rand_int])\n",
    "#                 labels_sec_temp.append(labels[rand_int])\n",
    "#             assert(len(source_sentences_temp) == len(labels_sec_temp))\n",
    "#             sentences_str = ' '.join(source_sentences_temp)\n",
    "#             labels_str = ' '.join(labels_sec_temp)\n",
    "#             senetences_temp.append(sentences_str)\n",
    "#             labels_temp.append(labels_str)\n",
    "#             target_sentences.append(target_sentences[i])\n",
    "#             labels_tar.append(labels_tar[i])\n",
    "# #         break\n",
    "#         i+=1\n",
    "#     source_sentences.extend(senetences_temp)\n",
    "#     labels_src.extend(labels_temp)    \n",
    "#     column_names = [\"source\",\"target\",\"src_tokens\",\"tar_tokens\"]\n",
    "#     df = pd.DataFrame(columns=column_names,dtype=object)\n",
    "#     df = df.assign(source=source_sentences)\n",
    "#     df = df.assign(target = target_sentences)\n",
    "#     df = df.assign(src_tokens = labels_src)\n",
    "#     df = df.assign(tar_tokens = labels_tar)  \n",
    "\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "875"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataloaders\n",
    "loader_obj = createDataloaders(dataset_train,config.TRAIN_BATCH_SIZE)\n",
    "train_dataloader = loader_obj.createDataloaders()\n",
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_obj = createDataloaders(dataset_eval,config.VALID_BATCH_SIZE)\n",
    "val_dataloader = loader_obj.createDataloaders()\n",
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-02-23 14:06:50.613 pytorch-1-6-gpu-p-ml-g4dn-12xlarge-5c3490cc3803aef3e3308aaea43f:31 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2022-02-23 14:06:50.645 pytorch-1-6-gpu-p-ml-g4dn-12xlarge-5c3490cc3803aef3e3308aaea43f:31 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([     0, 101044,  25958,      6,      4, 148113,    242,   5117,  17669,\n",
       "         51521,  49953,  19175,  44978,  12126,   5501,  55741,  74918,   2822,\n",
       "            98,  20414,    427,      6,      4,  45604,      6,      5,      2,\n",
       "             2,    656,  36630,     19,   9370,    656,  67271,    656,   3657,\n",
       "         40255,     67,    656,    833,    656, 148113,    656,    242,    656,\n",
       "         26431,    656, 168614,     13,    656,  49953,    656,  19175,    656,\n",
       "         44978,  12126,    656,  10142,  55741,    656,    444,    656,   5035,\n",
       "           656,  19838,    656,  45604,    656,      6,      5,    656,      2,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(val_dataloader))\n",
    "batch[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(output,target,mask):\n",
    "    lfn = nn.CrossEntropyLoss()\n",
    "    active_loss = mask.view(-1) == 1 #loss calculation for non padded tokens only (mask =1)\n",
    "    active_logits = output.view(-1,2)\n",
    "    active_labels = torch.where(\n",
    "        active_loss,\n",
    "        target.view(-1),\n",
    "        torch.tensor(lfn.ignore_index).type_as(target)    \n",
    "    )\n",
    "    loss = lfn(active_logits,active_labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityModel(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(EntityModel, self).__init__()\n",
    "        self.bert = XLMRobertaForTokenClassification.from_pretrained(config.BASE_MODEL_LARGE,output_attentions = False, output_hidden_states = False)\n",
    "#         self.bert_drop_1 = nn.Dropout(0.3)\n",
    "#         self.out_tag = nn.Linear(768, 2)\n",
    "    \n",
    "    def forward(self, ids, attention_mask, labels):\n",
    "        \n",
    "        outputs = self.bert(ids,\n",
    "                                attention_mask = attention_mask,\n",
    "                                labels = labels,return_dict=False)\n",
    "#         bo_tag = self.bert_drop_1(output_1)\n",
    "        \n",
    "#         tag = self.out_tag(bo_tag)  \n",
    "        \n",
    "#         loss_tag = loss_fn(outputs[1],labels,attention_mask)\n",
    "        \n",
    "#         return bo_tag,loss\n",
    "        return outputs[0], outputs[1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b_input_ids = batch[0].cuda()\n",
    "# b_input_mask = batch[1].cuda()\n",
    "# b_labels = batch[2].cuda()\n",
    "# outputs = model(b_input_ids, \n",
    "#                 b_input_mask,\n",
    "#                 labels=b_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaForTokenClassification: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = EntityModel()\n",
    "model.cuda()\n",
    "model = nn.DataParallel(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataParallel(\n",
      "  (module): EntityModel(\n",
      "    (bert): XLMRobertaForTokenClassification(\n",
      "      (roberta): RobertaModel(\n",
      "        (embeddings): RobertaEmbeddings(\n",
      "          (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
      "          (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
      "          (token_type_embeddings): Embedding(1, 1024)\n",
      "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): RobertaEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (12): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (13): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (14): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (15): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (16): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (17): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (18): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (19): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (20): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (21): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (22): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (23): RobertaLayer(\n",
      "              (attention): RobertaAttention(\n",
      "                (self): RobertaSelfAttention(\n",
      "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): RobertaSelfOutput(\n",
      "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): RobertaIntermediate(\n",
      "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              )\n",
      "              (output): RobertaOutput(\n",
      "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "      (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.memory_summary(device=None, abbreviated=False)\n",
    "# torch.cuda.empty_cache()\n",
    "# outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping(object):\n",
    "    def __init__(self, mode='max', min_delta=0, patience=10, percentage=False):\n",
    "        self.mode = mode\n",
    "        self.min_delta = min_delta\n",
    "        self.patience = patience\n",
    "        self.best = 0\n",
    "        self.num_bad_epochs = 0\n",
    "        self.is_better = None\n",
    "        self._init_is_better(mode, min_delta, percentage)\n",
    "\n",
    "        if patience == 0:\n",
    "            self.is_better = lambda a, b: True\n",
    "            self.step = lambda a: False\n",
    "\n",
    "    def step(self, metrics):\n",
    "        if self.best is None:\n",
    "            self.best = metrics\n",
    "            return False\n",
    "\n",
    "        if np.isnan(metrics):\n",
    "            return True\n",
    "\n",
    "        if self.is_better(metrics, self.best):\n",
    "            self.num_bad_epochs = 0\n",
    "            self.best = metrics\n",
    "        else:\n",
    "            self.num_bad_epochs += 1\n",
    "\n",
    "        if self.num_bad_epochs >= self.patience:\n",
    "            print('terminating because of early stopping!')\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _init_is_better(self, mode, min_delta, percentage):\n",
    "        if mode not in {'min', 'max'}:\n",
    "            raise ValueError('mode ' + mode + ' is unknown!')\n",
    "        if not percentage:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best \n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best \n",
    "        else:\n",
    "            if mode == 'min':\n",
    "                self.is_better = lambda a, best: a < best - (\n",
    "                            best * min_delta / 100)\n",
    "            if mode == 'max':\n",
    "                self.is_better = lambda a, best: a > best + (\n",
    "                            best * min_delta / 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n",
    "optimizer_parameters = [\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.001,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [\n",
    "            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "        ],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "num_train_steps = int(len(dataset_train) / config.TRAIN_BATCH_SIZE * config.EPOCHS) #10 is the batchsize\n",
    "optimizer = AdamW(optimizer_parameters, lr=2e-5) # used 3e-5\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n",
    ")\n",
    "early_stopping = EarlyStopping(patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 125/125 [01:20<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for class 0 : 0.23301044061663717\n",
      "Average F1 Validation score for class 1 : 3.276056937869581e-05\n",
      "Average Accuracy Validation score  : 0.13188094594786764\n",
      "Average mcc Validation score  : -0.00580211431471599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      1.00      0.23      9274\n",
      "           1       0.50      0.00      0.00     61047\n",
      "\n",
      "    accuracy                           0.13     70321\n",
      "   macro avg       0.32      0.50      0.12     70321\n",
      "weighted avg       0.45      0.13      0.03     70321\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_test,f1_score_0_test, f1_score_1_test, accuracy_score_test, mcc_score_test,labels_test,preds_test = engine.eval_fn(val_dataloader, model)\n",
    "print(classification_report(labels_test,preds_test)) # validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/438 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 438/438 [04:24<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for class 0 : 0.22455437859639002\n",
      "Average F1 Validation score for class 1 : 4.677082529459773e-05\n",
      "Average Accuracy Validation score  : 0.12649560078362637\n",
      "Average mcc Validation score  : 0.000507264119834074\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      1.00      0.22     61913\n",
      "           1       0.91      0.00      0.00    427606\n",
      "\n",
      "    accuracy                           0.13    489519\n",
      "   macro avg       0.52      0.50      0.11    489519\n",
      "weighted avg       0.81      0.13      0.03    489519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loss_test,f1_score_0_test, f1_score_1_test, accuracy_score_test, mcc_score_test,labels_test,preds_test = engine.eval_fn(train_dataloader, model)\n",
    "print(classification_report(labels_test,preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = reload(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,param in model.named_parameters():\n",
    "    if 'classifier' not in name:\n",
    "        param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/438 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 438/438 [11:53<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.37535994579639775\n",
      "Average F1 Training score for class 1 : 0.9378820258219416\n",
      "Average Accuracy Training score  : 0.8870013217055926\n",
      "Average mcc Training score  : 0.3589792236332131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.27      0.38     61913\n",
      "           1       0.90      0.98      0.94    427606\n",
      "\n",
      "    accuracy                           0.89    489519\n",
      "   macro avg       0.76      0.62      0.66    489519\n",
      "weighted avg       0.87      0.89      0.87    489519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 125/125 [01:05<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for class 0 : 0.27272727272727276\n",
      "Average F1 Validation score for class 1 : 0.9350651362361944\n",
      "Average Accuracy Validation score  : 0.8807753018301787\n",
      "Average mcc Validation score  : 0.30415558843079243\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.17      0.27      9274\n",
      "           1       0.89      0.99      0.94     61047\n",
      "\n",
      "    accuracy                           0.88     70321\n",
      "   macro avg       0.79      0.58      0.60     70321\n",
      "weighted avg       0.86      0.88      0.85     70321\n",
      "\n",
      "Train Loss = 0.27961182083985575 Valid Loss = 0.2967816752195358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/438 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 438/438 [11:52<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.5480623907223928\n",
      "Average F1 Training score for class 1 : 0.9478802239677376\n",
      "Average Accuracy Training score  : 0.906538867745685\n",
      "Average mcc Training score  : 0.5148384740744265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.45      0.55     61913\n",
      "           1       0.92      0.97      0.95    427606\n",
      "\n",
      "    accuracy                           0.91    489519\n",
      "   macro avg       0.81      0.71      0.75    489519\n",
      "weighted avg       0.90      0.91      0.90    489519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 125/125 [01:06<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for class 0 : 0.4032105071141919\n",
      "Average F1 Validation score for class 1 : 0.9355664621032481\n",
      "Average Accuracy Validation score  : 0.8836905049700658\n",
      "Average mcc Validation score  : 0.376828101111444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.30      0.40      9274\n",
      "           1       0.90      0.97      0.94     61047\n",
      "\n",
      "    accuracy                           0.88     70321\n",
      "   macro avg       0.76      0.64      0.67     70321\n",
      "weighted avg       0.86      0.88      0.87     70321\n",
      "\n",
      "Train Loss = 0.23332608504790694 Valid Loss = 0.32736343014240266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/438 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 438/438 [11:51<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.6644658463609163\n",
      "Average F1 Training score for class 1 : 0.9575470124119903\n",
      "Average Accuracy Training score  : 0.9246300960739011\n",
      "Average mcc Training score  : 0.6291273661273619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.59      0.66     61913\n",
      "           1       0.94      0.97      0.96    427606\n",
      "\n",
      "    accuracy                           0.92    489519\n",
      "   macro avg       0.85      0.78      0.81    489519\n",
      "weighted avg       0.92      0.92      0.92    489519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 125/125 [01:05<00:00,  1.89it/s]\n",
      "  0%|          | 0/438 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for class 0 : 0.38631200996556014\n",
      "Average F1 Validation score for class 1 : 0.9340525217528248\n",
      "Average Accuracy Validation score  : 0.8809032863582713\n",
      "Average mcc Validation score  : 0.35838114469332516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.28      0.39      9274\n",
      "           1       0.90      0.97      0.93     61047\n",
      "\n",
      "    accuracy                           0.88     70321\n",
      "   macro avg       0.75      0.63      0.66     70321\n",
      "weighted avg       0.86      0.88      0.86     70321\n",
      "\n",
      "Train Loss = 0.190123463755465 Valid Loss = 0.40511770701408384\n",
      "Epoch 4 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 438/438 [11:54<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.7367988386126317\n",
      "Average F1 Training score for class 1 : 0.965194543259334\n",
      "Average Accuracy Training score  : 0.9385192403154934\n",
      "Average mcc Training score  : 0.705372919477165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.68      0.74     61913\n",
      "           1       0.95      0.98      0.97    427606\n",
      "\n",
      "    accuracy                           0.94    489519\n",
      "   macro avg       0.88      0.83      0.85    489519\n",
      "weighted avg       0.94      0.94      0.94    489519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 125/125 [01:05<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for class 0 : 0.42512277789306213\n",
      "Average F1 Validation score for class 1 : 0.9341363870507587\n",
      "Average Accuracy Validation score  : 0.881813398558041\n",
      "Average mcc Validation score  : 0.38433635897142127\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.33      0.43      9274\n",
      "           1       0.90      0.97      0.93     61047\n",
      "\n",
      "    accuracy                           0.88     70321\n",
      "   macro avg       0.75      0.65      0.68     70321\n",
      "weighted avg       0.86      0.88      0.87     70321\n",
      "\n",
      "Train Loss = 0.15697740817859293 Valid Loss = 0.43211398339271545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/438 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 438/438 [11:53<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.7865732923034724\n",
      "Average F1 Training score for class 1 : 0.9711274097695317\n",
      "Average Accuracy Training score  : 0.9491357843107213\n",
      "Average mcc Training score  : 0.7596701191533913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.79     61913\n",
      "           1       0.96      0.98      0.97    427606\n",
      "\n",
      "    accuracy                           0.95    489519\n",
      "   macro avg       0.90      0.86      0.88    489519\n",
      "weighted avg       0.95      0.95      0.95    489519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 125/125 [01:06<00:00,  1.89it/s]\n",
      "  0%|          | 0/438 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for class 0 : 0.3759104903506795\n",
      "Average F1 Validation score for class 1 : 0.9347260946397015\n",
      "Average Accuracy Validation score  : 0.881813398558041\n",
      "Average mcc Validation score  : 0.3556362894918728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.27      0.38      9274\n",
      "           1       0.90      0.97      0.93     61047\n",
      "\n",
      "    accuracy                           0.88     70321\n",
      "   macro avg       0.76      0.62      0.66     70321\n",
      "weighted avg       0.86      0.88      0.86     70321\n",
      "\n",
      "Train Loss = 0.13109237617349515 Valid Loss = 0.5359024628400803\n",
      "Epoch 6 of 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 438/438 [11:54<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Training score for class 0 : 0.8194411754816583\n",
      "Average F1 Training score for class 1 : 0.9750254047907505\n",
      "Average Accuracy Training score  : 0.9561201914532429\n",
      "Average mcc Training score  : 0.7953748553471507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82     61913\n",
      "           1       0.97      0.98      0.98    427606\n",
      "\n",
      "    accuracy                           0.96    489519\n",
      "   macro avg       0.91      0.88      0.90    489519\n",
      "weighted avg       0.95      0.96      0.96    489519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/torch/nn/parallel/_functions.py:61: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 125/125 [01:05<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Validation score for class 0 : 0.40324684736918387\n",
      "Average F1 Validation score for class 1 : 0.9350856169783357\n",
      "Average Accuracy Validation score  : 0.8829083772983888\n",
      "Average mcc Validation score  : 0.3743519337564019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.30      0.40      9274\n",
      "           1       0.90      0.97      0.94     61047\n",
      "\n",
      "    accuracy                           0.88     70321\n",
      "   macro avg       0.76      0.64      0.67     70321\n",
      "weighted avg       0.86      0.88      0.86     70321\n",
      "\n",
      "Train Loss = 0.1117737358606093 Valid Loss = 0.5453287327289581\n",
      "terminating because of early stopping!\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = -1\n",
    "train_loss_lst = []\n",
    "val_loss_lst = []\n",
    "with open('metrics_xlmroberta_large_earlyStopping.txt', 'w') as f:\n",
    "    for epoch in range(config.EPOCHS):\n",
    "            print(f'Epoch {epoch+1} of {config.EPOCHS}')\n",
    "            train_metrics = engine.train_fn(train_dataloader, model, optimizer, scheduler)\n",
    "            print(classification_report(train_metrics[5],train_metrics[6]))\n",
    "            test_metrics = engine.eval_fn(val_dataloader, model)\n",
    "            print(classification_report(test_metrics[5],test_metrics[6]))\n",
    "            print(f\"Train Loss = {train_metrics[0]} Valid Loss = {test_metrics[0]}\")\n",
    "            train_loss_lst.append(train_metrics[:-2])\n",
    "            val_loss_lst.append(test_metrics[:-2])\n",
    "            f.write(f\"Train_loss {epoch+1} : {str(train_loss_lst)}\" + '\\n')\n",
    "            f.write(f\"val_loss {epoch+1} : {str(val_loss_lst)}\" + '\\n')\n",
    "            if early_stopping.step(float(\"{:.2f}\".format(test_metrics[4]))): #mcc score for early stopping \"{:.2f}\".format(a_float)\n",
    "                  break  # early stop criterion is met, we can stop now\n",
    "            if test_metrics[4] >  best_accuracy:\n",
    "                torch.save(model.state_dict(), '../models/training_data/model_xlmrobertatokenclassificationmodel_large_TrainData_earlystopping.bin')\n",
    "                best_accuracy = test_metrics[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_train : [0.27961182083985575, 0.23332608504790694, 0.190123463755465, 0.15697740817859293, 0.13109237617349515, 0.1117737358606093] \n",
      " loss_test :  [0.2967816752195358, 0.32736343014240266, 0.40511770701408384, 0.43211398339271545, 0.5359024628400803, 0.5453287327289581] \n",
      " f1_class0_train : [0.37535994579639775, 0.5480623907223928, 0.6644658463609163, 0.7367988386126317, 0.7865732923034724, 0.8194411754816583] \n",
      " f1_class0_test : [0.27272727272727276, 0.4032105071141919, 0.38631200996556014, 0.42512277789306213, 0.3759104903506795, 0.40324684736918387] \n",
      " f1_class1_train : [0.9378820258219416, 0.9478802239677376, 0.9575470124119903, 0.965194543259334, 0.9711274097695317, 0.9750254047907505] \n",
      " f1_class1_test : [0.9350651362361944, 0.9355664621032481, 0.9340525217528248, 0.9341363870507587, 0.9347260946397015, 0.9350856169783357] \n",
      " accuracy_score_train : [0.8870013217055926, 0.906538867745685, 0.9246300960739011, 0.9385192403154934, 0.9491357843107213, 0.9561201914532429] \n",
      " accuracy_score_test : [0.8807753018301787, 0.8836905049700658, 0.8809032863582713, 0.881813398558041, 0.881813398558041, 0.8829083772983888] \n",
      " mcc_score_train : [0.3589792236332131, 0.5148384740744265, 0.6291273661273619, 0.705372919477165, 0.7596701191533913, 0.7953748553471507] \n",
      " mcc_score_test : [0.30415558843079243, 0.376828101111444, 0.35838114469332516, 0.38433635897142127, 0.3556362894918728, 0.3743519337564019]\n"
     ]
    }
   ],
   "source": [
    "train_metrices = np.array(train_loss_lst)\n",
    "test_metrices = np.array(val_loss_lst)\n",
    "loss_train = train_metrices[:,0]\n",
    "loss_test = test_metrices[:,0]\n",
    "f1_class0_train = train_metrices[:,1]\n",
    "f1_class0_test= test_metrices[:,1]\n",
    "f1_class1_train = train_metrices[:,2]\n",
    "f1_class1_test = test_metrices[:,2]\n",
    "accuracy_score_train = train_metrices[:,3]\n",
    "accuracy_score_test = test_metrices[:,3]\n",
    "mcc_score_train = train_metrices[:,4]\n",
    "mcc_score_test = test_metrices[:,4]\n",
    "print('loss_train :',list(loss_train),'\\n','loss_test : ',list(loss_test),'\\n','f1_class0_train :',list(f1_class0_train),'\\n','f1_class0_test :',list(f1_class0_test),'\\n','f1_class1_train :',list(f1_class1_train),'\\n','f1_class1_test :',list(f1_class1_test),'\\n','accuracy_score_train :',list(accuracy_score_train),'\\n','accuracy_score_test :',list(accuracy_score_test),'\\n','mcc_score_train :',list(mcc_score_train),'\\n',\n",
    "    'mcc_score_test :', list(mcc_score_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "epochs = np.arange(1,epoch+1)\n",
    "plt.plot(epochs,loss_train[:-1],label='train_loss')\n",
    "plt.plot(epochs,loss_test[:-1],label='validation_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "# plt.ylim(0.2,0.4)\n",
    "plt.title('XMLRobertaForTokenClassification_earlyStopping')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = np.arange(1,epoch+1)\n",
    "plt.plot(epochs,mcc_score_train[:-1],label='mcc_train')\n",
    "plt.plot(epochs,mcc_score_test[:-1],label='mcc_test')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('mcc_score')\n",
    "plt.title('XMLRobertaForTokenClassification_earlyStopping')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "config = AutoConfig.from_pretrained('xlm-roberta-base')\n",
    "config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max mcc achieved for dev data is 0.38433635897142127 ,in the 4th epoch \n"
     ]
    }
   ],
   "source": [
    "print('Max mcc achieved for dev data is', np.amax(mcc_score_test),f',in the {np.argmax(mcc_score_test)+1}th epoch ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): EntityModel(\n",
       "    (bert): XLMRobertaForTokenClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 1024)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (1): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (2): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (3): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (4): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (5): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (6): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (7): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (8): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (9): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (10): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (11): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (12): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (13): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (14): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (15): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (16): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (17): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (18): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (19): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (20): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (21): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (22): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (23): RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSelfAttention(\n",
       "                  (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): Linear(in_features=1024, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('../models/training_data/model_xlmrobertatokenclassificationmodel_large_TrainData_earlystopping.bin'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 4 threads.INFO:numexpr.utils:NumExpr defaulting to 4 threads.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(val_dataloader))\n",
    "input_ids_b = batch[0].cuda()\n",
    "attention_mask_b = batch[1].cuda()\n",
    "labels_b = batch[2].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for class 0 : 0.46715328467153283\n",
      "f1 score for class 1 : 0.9293320425943853\n",
      "accuracy score : 0.8752136752136752\n",
      "mcc score : 0.5064481131096255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.31      0.47       104\n",
      "           1       0.87      1.00      0.93       481\n",
      "\n",
      "    accuracy                           0.88       585\n",
      "   macro avg       0.92      0.65      0.70       585\n",
      "weighted avg       0.89      0.88      0.85       585\n",
      "\n"
     ]
    }
   ],
   "source": [
    "outputs_pred = model(input_ids_b, attention_mask = attention_mask_b, labels = labels_b )\n",
    "labels = labels_b.view(-1) \n",
    "active_logits = outputs_pred[1].view(-1, 2)\n",
    "flattened_predictions = torch.argmax(active_logits, axis=1)\n",
    "active_accuracy = labels.view(-1) != -100\n",
    "labels_tmp = torch.masked_select(labels, active_accuracy) \n",
    "pred_tmp = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "print('f1 score for class 0 :',f1_score(labels_tmp.tolist(),pred_tmp.tolist(),average='binary',pos_label = 0))\n",
    "print('f1 score for class 1 :',f1_score(labels_tmp.tolist(),pred_tmp.tolist(),average='binary',pos_label = 1) )    \n",
    "print('accuracy score :',accuracy_score(labels_tmp.tolist(),pred_tmp.tolist()))\n",
    "print('mcc score :',matthews_corrcoef(labels_tmp.tolist(),pred_tmp.tolist()))\n",
    "print(classification_report(labels_tmp.tolist(),pred_tmp.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score overall : 0.9293320425943853\n"
     ]
    }
   ],
   "source": [
    "print('f1 score overall :',f1_score(labels_tmp.tolist(),pred_tmp.tolist()) )    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([     0,    241,    147,    538,  12610,      6, 101287,      7,     47,\n",
      "         64372, 176016,     71,    604, 102917,    538,    237,     10,   1926,\n",
      "         87463,    136,  32926,    111,   1926,  23962,      6,      5,      2,\n",
      "             2,    656, 180702,     13,    656,  45445,     39,   4986,    656,\n",
      "           360,  37738,     33,    656,    142,    656,  64372,    656,   3820,\n",
      "         42001,    656,   1329,    656,   1248,    656,  18341,    656,    737,\n",
      "           656,  25357,   1505,     73,    656,    165,    656,  60150,  38982,\n",
      "         45118,    656,    542,    656,  25357,   1505,     19,    656,      6,\n",
      "             5,    656,      2,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1,      1,      1,      1,      1,      1,\n",
      "             1,      1,      1,      1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
      "tensor([-100,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1, -100, -100,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
      "           1,    1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
      "        -100, -100, -100, -100], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(input_ids_b[0])\n",
    "print(attention_mask_b[0])\n",
    "print(labels_b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.0275e-22,  3.0688e-41])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(input_ids_b.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.5755,  2.1431],\n",
       "         [-2.0731,  2.5395],\n",
       "         [-2.0786,  2.6243],\n",
       "         ...,\n",
       "         [-1.2857,  2.2847],\n",
       "         [-1.2857,  2.2847],\n",
       "         [-1.2857,  2.2847]],\n",
       "\n",
       "        [[-0.8680,  1.7539],\n",
       "         [-0.2165,  0.4778],\n",
       "         [-0.6057,  0.5730],\n",
       "         ...,\n",
       "         [-0.8171,  2.1133],\n",
       "         [-0.8171,  2.1133],\n",
       "         [-0.8171,  2.1133]],\n",
       "\n",
       "        [[-2.3140,  3.1032],\n",
       "         [-1.3967,  1.9284],\n",
       "         [-2.1930,  2.8714],\n",
       "         ...,\n",
       "         [-0.7345,  1.8473],\n",
       "         [-0.7345,  1.8473],\n",
       "         [-0.7345,  1.8473]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.8779,  2.5788],\n",
       "         [-1.1160,  1.6957],\n",
       "         [-1.4398,  1.4903],\n",
       "         ...,\n",
       "         [-0.5970,  0.9176],\n",
       "         [-0.5970,  0.9176],\n",
       "         [-0.5970,  0.9176]],\n",
       "\n",
       "        [[-3.4575,  4.1277],\n",
       "         [-4.0676,  4.2741],\n",
       "         [-4.1043,  4.3594],\n",
       "         ...,\n",
       "         [-2.8568,  3.8547],\n",
       "         [-2.8568,  3.8547],\n",
       "         [-2.8568,  3.8547]],\n",
       "\n",
       "        [[-3.2421,  4.1605],\n",
       "         [-4.0004,  4.1854],\n",
       "         [-2.3899,  2.1156],\n",
       "         ...,\n",
       "         [-2.8725,  4.1783],\n",
       "         [-2.8725,  4.1783],\n",
       "         [-2.8725,  4.1783]]], device='cuda:0', grad_fn=<GatherBackward>)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "        1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[     0,  10257,  48461,  ...,      1,      1,      1],\n",
       "        [     0, 136820,     13,  ...,      1,      1,      1],\n",
       "        [     0, 106073,  81887,  ...,      1,      1,      1],\n",
       "        ...,\n",
       "        [     0,    360,    903,  ...,      1,      1,      1],\n",
       "        [     0,   1840,  16145,  ...,      1,      1,      1],\n",
       "        [     0,    360, 159261,  ...,      1,      1,      1]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr = input_ids_b.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([17, 18, 44]),\n",
       " array([14, 15, 41]),\n",
       " array([23, 24, 59]),\n",
       " array([21, 22, 59]),\n",
       " array([36, 37, 95]),\n",
       " array([ 51,  52, 140]),\n",
       " array([ 56,  57, 147]),\n",
       " array([27, 28, 64])]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_labels=[]\n",
    "tar_lables=[]\n",
    "index_labels = []\n",
    "for items in np_arr:\n",
    "#     print(np.where(items==2))\n",
    "    index_labels_tmp=np.where(items==2)\n",
    "    index_labels.append(index_labels_tmp[0])\n",
    "index_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_arr_labels = labels_b.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def div_src_tar(input_id, labels):\n",
    "    \n",
    "    src_labels=[]\n",
    "    tar_labels=[]\n",
    "    src_labels_example = []\n",
    "    tar_labels_example = []\n",
    "    index_labels=[]\n",
    "    input_id_np = input_id.cpu().numpy()\n",
    "    np_arr_labels = labels.cpu().numpy()\n",
    "    \n",
    "    for items in input_id_np:\n",
    "        \n",
    "        index_labels_tmp=np.where(items==2)\n",
    "        index_labels.append(index_labels_tmp[0])\n",
    "    \n",
    "    for i,items in enumerate(index_labels):\n",
    "\n",
    "        src_labels.extend(np_arr_labels[i][:items[1]])\n",
    "        tar_labels.extend(np_arr_labels[i][items[1]:])\n",
    "        src_labels_example.append(np_arr_labels[i][:items[0]])\n",
    "        tar_labels_example.append(np_arr_labels[i][items[1]+1:])\n",
    "    #     (src_labels_tmp)\n",
    "    \n",
    "    #     print(src_labels_tmp,f'{i}th sentence')\n",
    "    # print(src_labels)\n",
    "    # print(tar_labels)\n",
    "    return src_labels, tar_labels,src_labels_example,tar_labels_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2048, 2])"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1822])\n"
     ]
    }
   ],
   "source": [
    "print(torch.Tensor(tar_labels).view(-1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_labels , tar_labels, src_labels_example, tar_labels_example = div_src_tar(input_ids_b,labels_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred=[]\n",
    "for i in range(config.VALID_BATCH_SIZE):\n",
    "        labels_pred.append(flattened_predictions[i*config.MAX_LEN:(i+1)*config.MAX_LEN])\n",
    "#         labels_pred.append(flattened_predictions[])\n",
    "labels_pred_torch = torch.stack(labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_labels_pred, tar_labels_pred , src_labels_pred_example, tar_labels_pred_example = div_src_tar(input_ids_b, labels_pred_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gaps_labels(labels):\n",
    "    gap_labels = []\n",
    "    tar_labels = []\n",
    "    for item in labels:\n",
    "        for j,label in enumerate(item):\n",
    "            if j%2==0:\n",
    "                gap_labels.append(label)\n",
    "            else:\n",
    "                tar_labels.append(label)\n",
    "    return gap_labels, tar_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap_labels, tr_labels = get_gaps_labels(tar_labels_example)\n",
    "gap_labels_pred, tr_labels_pred = get_gaps_labels(tar_labels_pred_example) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "226\n",
      "1822\n",
      "1822\n",
      "909\n",
      "909\n",
      "905\n",
      "905\n"
     ]
    }
   ],
   "source": [
    "print(len(src_labels))\n",
    "print(len(src_labels_pred))\n",
    "print(len(tar_labels))\n",
    "print(len(tar_labels_pred))\n",
    "print(len(gap_labels))\n",
    "print(len(gap_labels_pred))\n",
    "print(len(tr_labels))\n",
    "print(len(tr_labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_src_labels = torch.Tensor(src_labels)\n",
    "tensor_tar_labels = torch.Tensor(tar_labels)\n",
    "tensor_src_labels_pred = torch.Tensor(src_labels_pred)\n",
    "tensor_tar_labels_pred = torch.Tensor(tar_labels_pred)\n",
    "tensor_gap_labels = torch.Tensor(gap_labels)\n",
    "tensor_gap_labels_pred = torch.Tensor(gap_labels_pred)\n",
    "tensor_target_labels = torch.Tensor(tr_labels)\n",
    "tensor_target_labels_pred = torch.Tensor(tr_labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210\n",
      "210\n"
     ]
    }
   ],
   "source": [
    "active_accuracy = tensor_src_labels.view(-1) != -100\n",
    "src_labels_active = torch.masked_select(tensor_src_labels, active_accuracy) \n",
    "src_labels_active_pred = torch.masked_select(tensor_src_labels_pred, active_accuracy)\n",
    "print(len(src_labels_active))\n",
    "print(len(src_labels_active_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC Score for source : 0.4167846642725389\n",
      "F1 Score for source : 0.9100817438692098\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.24      0.38        42\n",
      "         1.0       0.84      0.99      0.91       168\n",
      "\n",
      "    accuracy                           0.84       210\n",
      "   macro avg       0.87      0.62      0.64       210\n",
      "weighted avg       0.85      0.84      0.80       210\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MCC Score for source :',matthews_corrcoef(src_labels_active.tolist(),src_labels_active_pred.tolist()) )\n",
    "print('F1 Score for source :',f1_score(src_labels_active,src_labels_active_pred))\n",
    "print(classification_report(src_labels_active,src_labels_active_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189\n",
      "189\n"
     ]
    }
   ],
   "source": [
    "active_accuracy = tensor_gap_labels.view(-1) != -100\n",
    "gap_labels_active = torch.masked_select(tensor_gap_labels, active_accuracy) \n",
    "gap_labels_active_pred = torch.masked_select(tensor_gap_labels_pred, active_accuracy)\n",
    "print(len(gap_labels_active))\n",
    "print(len(gap_labels_active_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC Score for gap : 0.6264982043070835\n",
      "F1 Score for gap : 0.9457831325301205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.44      0.61        32\n",
      "         1.0       0.90      1.00      0.95       157\n",
      "\n",
      "    accuracy                           0.90       189\n",
      "   macro avg       0.95      0.72      0.78       189\n",
      "weighted avg       0.91      0.90      0.89       189\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MCC Score for gap :',matthews_corrcoef(gap_labels_active,gap_labels_active_pred) )\n",
    "print('F1 Score for gap :',f1_score(gap_labels_active,gap_labels_active_pred))\n",
    "print(classification_report(gap_labels_active,gap_labels_active_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n",
      "375\n"
     ]
    }
   ],
   "source": [
    "active_accuracy = tensor_tar_labels.view(-1) != -100\n",
    "tar_labels_active = torch.masked_select(tensor_tar_labels, active_accuracy) \n",
    "tar_labels_active_pred = torch.masked_select(tensor_tar_labels_pred, active_accuracy)\n",
    "print(len(tar_labels_active))\n",
    "print(len(tar_labels_active_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC Score for tar : 0.5609192074675643\n",
      "F1 Score for tar : 0.93993993993994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.35      0.52        62\n",
      "         1.0       0.89      1.00      0.94       313\n",
      "\n",
      "    accuracy                           0.89       375\n",
      "   macro avg       0.94      0.68      0.73       375\n",
      "weighted avg       0.91      0.89      0.87       375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MCC Score for tar :',matthews_corrcoef(tar_labels_active,tar_labels_active_pred) )\n",
    "print('F1 Score for tar :',f1_score(tar_labels_active,tar_labels_active_pred))\n",
    "print(classification_report(tar_labels_active,tar_labels_active_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186\n",
      "186\n"
     ]
    }
   ],
   "source": [
    "active_accuracy = tensor_target_labels.view(-1) != -100\n",
    "target_labels_active = torch.masked_select(tensor_target_labels, active_accuracy) \n",
    "target_labels_active_pred = torch.masked_select(tensor_target_labels_pred, active_accuracy)\n",
    "print(len(target_labels_active))\n",
    "print(len(target_labels_active_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC Score for tar : 0.4834334133761747\n",
      "F1 Score for tar : 0.9341317365269461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.27      0.42        30\n",
      "         1.0       0.88      1.00      0.93       156\n",
      "\n",
      "    accuracy                           0.88       186\n",
      "   macro avg       0.94      0.63      0.68       186\n",
      "weighted avg       0.90      0.88      0.85       186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('MCC Score for tar :',matthews_corrcoef(target_labels_active,target_labels_active_pred) )\n",
    "print('F1 Score for tar :',f1_score(target_labels_active,target_labels_active_pred))\n",
    "print(classification_report(target_labels_active,target_labels_active_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n",
      "[0, 41, 42, 62, 63, 80, 81, 109, 110, 147, 148, 170, 171, 197, 198, 225]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "pop index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-96edd45bbbba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_labels_rem_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc_labels_rem_ind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msrc_labels_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_labels_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msrc_labels_rem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msrc_labels\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: pop index out of range"
     ]
    }
   ],
   "source": [
    "# print(len(src_labels_pred))\n",
    "# src_labels_rem_ind = [i for i,item in enumerate(src_labels) if item==-100]\n",
    "# print(src_labels_rem_ind)\n",
    "# for item in src_labels_rem_ind:\n",
    "#     src_labels_pred.pop(item)\n",
    "# print(len(src_labels_pred))\n",
    "# src_labels_rem = [item for item in src_labels if item!=-100]\n",
    "# print(len(src_labels_rem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "print(src_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tar_labels[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_labels_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tar_labels_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_logits.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_predictions_np = flattened_predictions.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels_b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tar_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(src_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/pytorch-1.6-gpu-py36-cu110-ubuntu18.04-v3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
